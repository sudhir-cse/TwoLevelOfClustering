Turning CARTwheels:
An Alternating Algorithm for Mining Redescriptions


Naren Ramakrishnan, Deept Kumar, Bud Mishra, Malcolm Potts#, and Richard F. Helm#

Department of Computer Science, Virginia Tech, VA 24061

Courant Institute of Mathematical Sciences, New York University, NY 10003
#
Department of Biochemistry, Virginia Tech, VA 24061
Contact: naren@cs.vt.edu


ABSTRACT
We present an unusual algorithm involving classification trees--
CARTwheels--where two trees are grown in opposite direc-
tions so that they are joined at their leaves. This approach
finds application in a new data mining task we formulate,
called redescription mining. A redescription is a shift-of-
vocabulary, or a different way of communicating information
about a given subset of data; the goal of redescription mining
is to find subsets of data that afford multiple descriptions.
We highlight the importance of this problem in domains
such as bioinformatics, which exhibit an underlying richness
and diversity of data descriptors (e.g., genes can be stud-
ied in a variety of ways). CARTwheels exploits the duality
between class partitions and path partitions in an induced
classification tree to model and mine redescriptions. It helps
integrate multiple forms of characterizing datasets, situates
the knowledge gained from one dataset in the context of
others, and harnesses high-level abstractions for uncovering
cryptic and subtle features of data. Algorithm design deci-
sions, implementation details, and experimental results are
presented.

Categories and Subject Descriptors: H.2.8 [Database
Management]: Database Applications - Data Mining; I.2.6
[Artificial Intelligence]: Learning

General Terms: Algorithms.

Keywords: Classification trees, redescriptions, data min-
ing in biological domains.

1. INTRODUCTION
Classification and regression trees (CART) were among
the earliest proposed approaches for pattern classification
and data mining [3]. While being powerful in terms of accu-
racy and efficiency of induction, their results are also sim-
ple to understand as they mimic the decision-making logic
of human experts. The renewed emphasis on data mining
propagated by the KDD community in the 1990s has fueled
a resurgence of interest in tree-based methods [7, 9].




Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD'04, August 22­25, 2004, Seattle, Washington, USA.
Copyright 2004 ACM 1-58113-888-1/04/0008 ...$5.00.
In this paper we introduce a new data mining task--
redescription mining--and also propose a novel tree-based
algorithm (CARTwheels) for mining redescriptions. A re-
description is a shift-of-vocabulary, or a different way of
communicating information about a given subset of data;
the goal of redescription mining is to find subsets of data
that afford multiple descriptions.
Consider the set of all countries in the world. The ele-
ments of this set can be described in various ways, e.g., ge-
ographical location, political status, scientific capabilities,
and economic prosperity. Such features allow us to define
various subsets of the given (universal) set, called descrip-
tors. Examples of these are shown in Fig. 1.
Redescriptions are equivalences describing a subset in two
ways, for instance:

`Countries with > 200 Nobel prize winners'

`Countries with > 150 billionaires'

Both sides of this redescription refer to the singleton set
{US}. Such relationships can be mined using techniques
from the association rules literature [1], but our view of re-
descriptions is broader in scope and also includes set-theoretic
expressions involving descriptors:
`Countries with defense budget > $30 billion' 
`Countries with declared nuclear arsenals'

`Permanent members of U.N. Security Council' -
`Countries with history of communism'

Here, we have constructed a set intersection on the left and
a set difference on the right, from the given descriptors, and
obtained a redescription for the 3-element set: {US, UK,
France}. A typical approach to mining such patterns would
be to first fix the form of the set-theoretic expressions and
then search within the space of possible instantiations. The
goal of this paper is to present an algorithmic framework
that simultaneously constructs set-theoretic expressions and
searches in the space of possible redescriptions.
Formally, the inputs to redescription mining are the uni-
versal set of objects O (e.g., countries) and two sets (X and
Y ) of subsets of O. The elements of X are the descriptors
Xi, and are assumed to form a covering of O (
S
i
Xi = O).
Similarly
S
i
Yi = O. The only requirement of a descriptor
is that it be a proper subset of O and denote some logical
grouping of the underlying objects (for ease of interpreta-
tion). The goal of redescription mining is to find equiva-
lence relationships of the form E  F that hold at or above
a given Jaccard's coefficient  (i.e.,
|EF|
|EF|
 ), where E and
F are set-theoretic expressions involving Xi's and Yi's, re-



266
Research Track Paper

Countries with > 200 Nobel prize winners
=
{
US}
Countries with > 150 billionaires
=
{
US}
Countries with history of communism
=
{China
Russia
}
Countries with defense budget > $30 billion
=
{
France
Germany
Japan
UK
US}
Permanent members of the U.N. Security Council
=
{China
France
Russia
UK
US}
Countries with declared nuclear arsenals
=
{China
France
India
Israel
Pakistan
Russia
UK
US}


Figure 1: Six descriptors defined over a universal set of countries.


spectively. For tractability purposes, some restrictions on
the length of the allowable set-theoretic expressions (not
their form) is assumed to be provided. Redescription mining
hence involves constructive induction (the task of inventing
new features) and exhibits traits of both unsupervised and
supervised learning. It is unsupervised because it finds con-
ceptual clusters underlying data, and it can be viewed as su-
pervised because clusters defined using descriptors are given
meaningful characterizations (in terms of other descriptors).
Why is this problem relevant? We posit that today's high-
throughput data-driven sciences are drowning in not just the
dimensionality of data, but also in the multitude of descrip-
tors available for characterizing data. Consider gene expres-
sion studies using bioinformatics approaches. The univer-
sal set of genes in a given organism (O) can be studied in
many ways, such as functional categorizations, expression
level quantification using microarrays, protein interactions,
and biological pathway involvement. Each of these method-
ologies provides a different vocabulary to define subsets of
O (e.g., `genes localized in cellular compartment nucleus,'
`genes up-expressed two-fold or more in heat stress,' `genes
encoding for proteins that form the Immunoglobin complex,'
and `genes involved in glucose biosynthesis'). While tradi-
tionally we would custom-build data mining algorithms to
work with each of these vocabularies, redescription mining
provides a uniform way to characterize and analyze the re-
sults from any of them. In addition, it helps bridge diverse
experimental methodologies by uniformly relating subsets
across the corresponding vocabularies.
We further argue that redescription mining serves as a
fundamental building block of many important steps in the
iterative, often unarticulated, knowledge discovery process.
A shift of vocabulary allows a given subset of data to be
interpretable in a different context, and allows us to harness
existing knowledge from this other context. For instance,
if we are able to redescribe results from a new stress ex-
periment onto, say, a heat shock experiment studied ear-
lier, we will be able to study the new results in terms of
known biological knowledge about heat shock. Chains of re-
descriptions allow us to relate diverse vocabularies, through
important intermediaries.
Even redescriptions that hold with Jaccard's coefficient
< 1 find application in many domains. An approximate re-
description implies a common meeting ground for two con-
certed communities of objects. A chain of such approximate
redescriptions can effectively relate two subsets that have
nothing in common! This is especially useful in story telling
and link analysis applications. A query such as `what is the
relationship between people traveling on Flight 847 and the
top 10 wanted list by the FBI?' can be posed in terms of
redescription finding.
While related problems have been studied in the data min-
ing community (most notably, conceptual clustering [5, 12],
niche finding, and profiling classes [19]), we believe that the
above formulation of redescription mining has not been at-
tempted before. Our contributions here are both the intro-
duction of this new data mining problem, as well as a novel
tree-based algorithm for mining redescriptions.


2. REDESCRIPTION MINING AS ALTER-
NATING TREE INDUCTION
We now introduce an approach (CARTwheels) to mining
redescriptions that involves growing two trees in opposite
directions, so that they are matched at their leaves. The de-
cision conditions in the first tree (say, top) are based on set
membership checks in entries from X and the bottom tree is
based on membership checks in entries from Y ; thus match-
ing of leaves corresponds to a potential redescription. This
idea hence uses paths in the classification trees as represen-
tations of boolean expressions involving the descriptors.
The CARTwheels algorithm is an alternating algorithm,
in that the top tree is initially fixed and the bottom tree
is grown to match it. Next, the bottom tree is fixed, and
the top tree is re-grown. This process continues, spouting
redescriptions along the way, until designated stopping cri-
teria are met.

2.1 Working Example
For ease of illustration, consider the artificial example in
Fig. 2 that shows two sets of descriptors for the universal
set O = {o1,o2,o3,o4,o5}. Here, the set X corresponds to
the set of descriptors {X1,X2,X3,X4} and Y corresponds
to {Y1,Y2,Y3,Y4}. The cardinalities of X and Y may not be
the same in the general case. Further, in a realistic applica-
tion, the number of descriptors would far exceed the number
of objects.
To initialize the CARTwheels alternation, we prepare a
traditional dataset for classification tree induction, where
the entries correspond to the objects, the boolean features
are derived from one of X or Y , and the classes are derived
from the other. In the dataset shown in Fig. 3 (left), the
features correspond to set membership in entries of Y and
each object is assigned a unique class, chosen from the Xi's
it participates in. We employed a greedy set covering of the
objects using the entries of X in order to establish the class
labels in Fig. 3 (left). For instance, o2 belongs to both X1
and X3, but the tie is broken in favor of X1. Notice that in
this process, X3 does not receive any representation in the
prepared dataset.
A classification tree can now be grown using any of the
impurity measures studied in the literature (e.g., entropy,
Gini index, misclassification rate). Fig. 3 (right) depicts a
possible tree. The leaves of the tree deterministically predict
a class label from X, typically the majority class. At this
point, the specific details of how the tree was induced are not
important, only that any such tree will induce a partition
of the underlying objects. In this case, the tree induces a
3-partition which mirrors the 3-class partition present in the
original dataset, but is not exactly the same. The left most
path corresponds to the region Y3  Y2, the right most path
corresponds to O-Y3-Y1, and the union of the two middle



267
Research Track Paper

X1
=
{
o2,
o3
}
X2
=
{
o3,
o4
}
X3
=
{
o2,
o4
}
X4
=
{ o1,
o5
}
Y1
=
{ o1,
o2,
}
Y2
=
{
o2,
o3,
o4
}
Y3
=
{
o3,
o5
}
Y4
=
{ o1,
o2,
o5
}

Figure 2: Example data for illustrating operation of CARTwheels algorithm.




object
Y1
Y2
Y3
Y4
class
o1

×
×

X4
o2


×

X1
o3
×


×
X1
o4
×

×
×
X2
o5
×
×


X4
Y3




Y2
Y1
yes
no




X1
X4 X4
X2
yes
no
yes
no




Figure 3: (left) Dataset to initialize CARTwheels algorithm. (right) induced classification tree.




obj.
X1
X2
X3
X4
class
o1
×
×
×

(Y3 - Y2)  (Y1 - Y3)
o2

×

×
(Y3 - Y2)  (Y1 - Y3)
o3


×
×
Y3  Y2
o4
×


×
O - Y3 - Y1
o5
×
×
×

(Y3 - Y2)  (Y1 - Y3)
obj.
Y1
Y2
Y3
Y4
class
o1

×
×

(X3  X1)  (X4 - X3)
o2


×

(X3  X1)  (X4 - X3)
o3
×


×
(O - X3 - X4)
o4
×

×
×
(X3 - X1)
o5
×
×


(X3  X1)  (X4 - X3)

Figure 4: (left) Dataset for second iteration of CARTwheels algorithm. Notice that class labels are now
set-theoretic expressions involving Yi's. (right) Dataset for third iteration of CARTwheels algorithm.




Y3




Y2
Y1
yes
no




yes
no
yes
no




X4
X1




X3
yesno
yesyes
nono
Y1
Y3




noyesyes
no
Y2
yes
no




X4
X1




X3
yesno
yesyes
nono
noyes




noyes
Y4




Y3



·········




Figure 5: Alternating tree growing in the CARTwheels algorithm. The alternation begins with a tree (first
frame) defining set-theoretic expressions to be matched. The bottom tree is then grown to match the top tree
(second frame), which is then fixed, and the top tree is re-grown (third frame). Colored arrows indicate the
matching paths. Redescriptions corresponding to matching paths at every stage are read off and subjected
to evaluation by Jaccard's coefficient.




268
Research Track Paper

paths gives (Y3 - Y2)  (Y1 - Y3). The reader can verify
that these regions do not have a one-to-one correspondence
with the regions X1, X2, and X4 in the original partition.
For instance, only X2 enjoys such a correspondence, with
O - Y3 - Y1. In `reading off' a partition from a tree in this
manner, a conjunction thus results from a path of length
> 1, a disjunction results from multiple paths predicting
the same class, with negations corresponding to following
the `no' branch from a given node. This partition is used as
the starting point for the alternation (Fig. 5, first frame).
We now prepare a dataset with entries from X as the
features and the regions thus formed (involving Yi's) as the
classes, as shown in Fig. 4 (left). Inducing a classification
tree from this dataset really corresponds to growing a second
tree to match the first tree at the leaves, as depicted in Fig. 5
(second frame). In this case, the second tree also learns a 3-
partition and we can evaluate each of these matchings using
the Jaccard's measure. This produces three redescriptions:
(X3  X1)  (X4 - X3)  (Y3 - Y2)  (Y1 - Y3)
(X3 - X1)  (O - Y3 - Y1)
(O - X3 - X4)  (Y3  Y2)


all of which hold at Jaccard's coefficient 1. This need not be
the case in general. The bottom tree might be able to match
only some paths in the top tree, or the matches might not
pass our Jaccard's cutoff. This process is then continued,
now with Yi's as features and the partitions derived from
the bottom tree as classes (see right of Fig. 4). The new
matchings yield the redescriptions:
(X3  X1)  (X4 - X3)  Y4
(O - X3 - X4)  (Y3 - Y4)
(X3 - X1)  (O - Y3 - Y4)


which, fortuitously, also have a Jaccard's coefficient of 1.
Notice that, this time, the root decision node that has been
picked is Y4 (see third frame of Fig. 5) and the tree actu-
ally resembles a decision list (a tree where every internal
node has a leaf on its `yes' branch). The alternation can be
continued (see Sec. 2.4 for ways to configure the search).
If we limit the size of the trees at every iteration, it is
easy to see that the set-expressions constructed cannot get
arbitrarily long. In our running example, we use a depth
limit of 2 so that all expressions on either side of a mined
redescription can involve at most three descriptors. The
longest expressions result from unions of two paths involving
different subtrees.

2.2 Why does CARTwheels work?
The use of trees to mine one-directional implications (rules)
is well understood and is the idea behind algorithms such as
C4.5 [15]. In CARTwheels, we exploit the duality between
class partitions and path partitions to posit the stronger no-
tion of equivalence. In fact, if a tree reduces the entropy
to zero, it is clear that there must be a one-to-one corre-
spondence between its path partitions and class partitions,
which are really path partitions from the other tree. Keep
in mind that different paths are union-ed when they predict
the same class, and this property is crucial to establishing
the duality.
The search for redescriptions in CARTwheels can be viewed
as a problem of identifying (and creating) correlated random
Figure 6: Contour plot depicting best attainable
Jaccard's coefficient, for different set sizes.


variables. We present a simple analysis in the case of one-
level tree (the extension to more levels is beyond the scope
of this paper). A descriptor, e.g., D, can be considered to
be a discrete random variable that takes on values from O.
Every object in D occurs with probability
1
|D|
and other ob-
jects occur with probability zero, to yield total probability
mass of 1. Notice that this makes the self entropy of such
a random variable to be the logarithm of the size of the de-
scriptor. Now consider running a CARTwheels alternation
with a depth limit of 1 for the classification trees. Mining
a redescription with Jaccard's coefficient of 1 is equivalent
to identifying a random variable D whose entropy distance
from D is zero. The entropy distance is given by:

H(D,D ) - I(D;D )

where H(D,D ) is the joint entropy function of {D, D } and
I qualifies the mutual information, in turn given by:

I(D;D ) = H(D) - H(D|D )

where H(D) is the self-entropy of D and H(D|D ) is the
conditional entropy of D given D . In other words, the av-
erage reduction in uncertainty about D due to knowing D is
exactly the self entropy of D, causing an entropy distance of
0. Entropy distance is a true distance measure, unlike mea-
sures such as the Kullback-Leibler (KL) divergence. Smaller
values of entropy distance hence imply higher values of Jac-
card's coefficient.

2.3 Configuring Alternations in CARTwheels
CARTwheels provides a general framework to explore a
space of redescriptions; to configure its alternation, there
are several issues to be considered.
We will begin by observing that the continuation of CART-
wheels alternation, after mining a redescription, is really an
attempt to explore and stay within a relatively small region
of high Jaccard's coefficient. Fig. 6 shows an idealized sce-
nario where descriptors (or expressions derived from them)
occur in all possible sizes, with the best possible overlaps. In
a realistic dataset, the regions of high Jaccard's coefficient
might be disjoint, and a good exploration policy must try
to visit all potential regions.
In contrast to traditional classification tree induction which
is motivated at reducing entropy, CARTwheels must actually
maintain entropy in some form, since impurity drives explo-
ration. However, if the impurity in the underlying datasets
remains constant, some redescriptions are bound to be found
over and over again. The tradeoff here is clearly between ex-



269
Research Track Paper

Input: objects O, descriptor sets {Xi}, {Yi}
Output: redescriptions R
Parameters:
 (Jaccard's coefficient),
d (depth of trees),
 (# of class participations allowed/descriptor), and
 (max. # of consecutive unsuccessful alternations).
Initialization:
set answer set R = {}
set class participation counts for all {Xi}, {Yi} = 0
set feature set F = {Yi}
set classes C = {Xi}
set dataset D = construct dataset(O, F, C)
set tree t = construct tree(D, d)
if (all leaves in t have same class c  C)
set l = random leaf in t having non-zero entropy
impurify(t,l)
C = paths to classes(t)
flag = false; count = 0
Alternation:
G = {Xi}
while (count < )
F = G
if (flag = false)
{Xi} = G; G = {Yi}
else
{Yi} = G; G = {Xi}
endif
D = construct dataset(O,F,C)
t = construct tree(D,d)
if (all leaves in t have same class c  C)
set l = random leaf in t having non-zero entropy
impurify(t,l)
endif
Rnew = eval(t,)
if (Rnew = {})
count = count + 1
else
count = 0
foreach c  C
if c is involved in some r  Rnew
H = descriptors(c)
foreach descriptor g  G  H
increase g's class participation count
if g's class participation count > 
remove g from G
endfor
endif
endfor
end if
R = R  Rnew; flag = not(flag)
C = paths to classes(t)
end while


Table 1: CARTwheels algorithmic framework.

ploration and redundancy: to support sufficient exploration,
we must accept redundancy, and conversely if we desire to
reduce redundancy, we must settle for insufficient coverage
of the redescription space. This tradeoff suggests that a
tunable parameter for CARTwheels alternation is the num-
ber of times that a descriptor is allowed to participate in
redescriptions.

2.4 TheCARTwheelsAlgorithmicFramework
Table 1 describes the CARTwheels algorithmic framework
in detail. The outline follows the example shown previously:
construct dataset prepares a dataset suitable for CART in-
duction as in Fig. 3; construct tree creates the decision tree
of depth d; and paths to classes reads expressions off an in-
duced tree, to be used as classes in the next step for each
object in O. Notice the use of an impurify function in both
the initialization and the alternation steps, which typically
assigns the second-best class label to the chosen leaf l. Addi-
tional impurification steps, to aid exploration, are included
in our implementations of construct tree (e.g., we do not al-
ways branch on the attribute with the best entropy gain and
sometimes perform randomized moves at the root level).
The eval function returns redescriptions satisfying the Jac-
card's threshold . Our implementation of eval requires re-
descriptions to hold in both the mined and complementary
forms, e.g., for the equivalence E1E2  F to be considered
as a redescription, it must hold with Jaccard's coefficient at
least , as must its complement: ¬E1  ¬E2  ¬F. This
ensures that every redescription truly induces a partition
of O × O space. descriptors is a function that analyzes a
set-theoretic expression and returns the set of descriptors
participating in it.
The important tunable parameter in Table 1 is , control-
ling the tradeoff between redundancy and exploration. A
participation count is incremented each time a given descrip-
tor appears in a redescription in its role as part of a class,
and when this reaches , the descriptor is removed from con-
sideration. The parameter  specifies the maximum number
of alternations that CARTwheels can go through without
mining any redescriptions.

2.5 AssessingSignificanceofMinedRedescrip-
tions
There are many ways to assess significance of redescrip-
tions mined by CARTwheels. They vary in their formulation
of the null hypothesis. For instance, given a redescription
X  Y with Jaccard's coefficient  we can ask `how likely is
it that two descriptor expressions of size |X| and |Y | have 
as their Jaccard's coefficient?' or `how significant is it that
expressions having the same syntactic bias as X and Y have
 as their Jaccard's coefficient?' The first approach focuses
on the sizes of the descriptor expressions whereas the second
is concerned with the way expressions are constructed, and
must inherently utilize the distribution of descriptor sizes
(and maybe second order information, such as commonality
or differences). We adopt the first approach in this paper.
Specifically, we assess if the Jaccard's coefficient () can
happen by chance if we had chosen sets X and Y randomly
from the available universal set O, keeping |X| and |Y | fixed.
This yields a simple statistical test giving a p-value based on
the distribution of set overlaps for the given set sizes (details
omitted for space considerations). Keep in mind that one
way to get a strong p-value would be to have very small
sizes for X and Y (which in turn, make the achievement of
a respectable  difficult). On the other hand, if X and Y are
large, the ease with which they could overlap increases, and
hence even high Jaccard coefficients might not correspond to
a strong p-value. Therefore, for interpretation purposes, it is
important to not think of intersection size as a surrogate for
significance of redescriptions. In the experiments reported
here, we have found statistically significant redescriptions
involving as few as 1 object to as large as 80 objects.

2.6 Implementation Details
CARTwheels is implemented in C++ atop a Postgres data-
base providing access to the descriptors. We use an AD-tree
data structure [13] for fast counting purposes and estima-
tion of entropy (this is distinct from the classification tree



270
Research Track Paper

Table 2: Summary of universal sets and descriptors.

G1
G2
G3
# stresses
5
7
7
# expts
7
9
9
# ORFs
74
332
171
GO (biological process) descriptors
210
479
382
GO (cellular component) descriptors
42
112
97
GO (molecular function) descriptors
126
298
204
Expression level range descriptors
224
373
344
k-means clusters
70
270
0
Histone expression range descriptors
152
168
162
# descriptors
824
1700
1189



that combines the descriptors). The AD-tree provides access
to the distributions of `class labels' for every combination
of `features' and, since the definition of features and class
labels change at every iteration, is rebuilt continually. No-
tice that the data structure is expected to provide both the
sizes of descriptors as well as their negations (when we fol-
low the `no' branch) and hence, the depth of the AD-tree is
set to just greater than the allowable depth of the classifica-
tion trees. The CARTwheels algorithm consults the AD-tree
whenever it must make a choice of a decision node (except
when its move is exploratory). After evaluating matchings,
set-expressions read off the trees are subjected to tabular
minimization, in order to arrive at a canonical form.
The implementation allows for configuring the space of
redescriptions that are explored. The depth limit for the
top and bottom trees can be individually specified, and we
can also preferentially include or exclude certain types of
expressions in mined redescriptions. For instance, syntactic
constraints on redescriptions (e.g., only conjunctions are al-
lowed) can be incorporated as biases in the tree construction
phase of CARTwheels.


3. APPLICATIONS IN BIOINFORMATICS
We now present an application of CARTwheels to study-
ing gene expression datasets from microarray experiments
conducted on the budding yeast Saccharomyces cerevisiae.
Bioinformatics is fertile ground for application of CART-
wheels and S. cerevisiae is arguably the most well studied
(and documented) model organism through bioinformatics
techniques. Practically every experimental methodology ap-
plied toward yeast can be viewed as a way to define de-
scriptors. Even the results of other data analysis/mining
algorithms can be used as a source of descriptors! The un-
derlying universal set of objects could be initialized to the
set of genes, proteins, or processes, in S. cerevisiae. CART-
wheels hence brings many computational and experimental
technologies to bear upon redescription mining. It supports
the capture of both similarities and distinctions among de-
scriptors derived from these diverse sources.

3.1 Datasets
The redescription process begins by defining the univer-
sal set of genes (or open reading frames, ORFs) G, which
is dependent on our biological goals. Here, we are inter-
ested in characterizing similarities and differences in yeast
gene expression behavior across related families of stresses.
Gasch et al. ([8]) is an important source for such a study
since it provides results from more than 170 comparisons,
across a variety of environmental stresses. We use three dif-
ferent universal sets, to illustrate diverse ways of using the
CARTwheels framework:

G1: the set of ORFs that show significant change in expres-
sion (more than 1-fold up- or down-regulation) in some time
point in each of the five stresses from (heat shock from 25C
to 37C, hyper-osmotic shock, hypo-osmotic shock, H2O2
exposure, and mild heat shock at variable osmolarity).

G2: the set of ORFs that show more than 4-fold up- or
down-regulation change in expression in some time point
in each of the seven stresses from (heat shock from 25C
to 37C, hyper-osmotic shock, hypo-osmotic shock, H2O2
exposure, mild heat shock at variable osmolarity, heat shock
from 37C to 25C, and heat shock from 29C to 33C).
Notice that two additional stresses are included, from how
G1 was constructed.

G3: the set of ORFs more than 4-fold up- or down-regulation
change in expression in some time point in each of the seven
stresses in G2 and that do not belong to the set of ESR
(Environmental Sress Response) genes as characterized by
Gasch et al. ([8]). The ESR dataset (comprising 868 ORFs)
constitute a characterization of yeast ORFs that show a
marked uniformity of expression across diverse stresses, and
hence have been excluded by many researchers in their anal-
yses ­ see for instance, ([17]).

The choice of the universal set can be viewed as a condi-
tioning context and must be kept in mind when interpreting
any mined redescriptions. It can be viewed as an implicit
descriptor occurring on both sides of every mined redescrip-
tion, e.g., E  F in G1 can be viewed as E G1  F G1.


3.2 Descriptor Definition
We defined descriptors for the genes in the chosen univer-
sal sets in a variety of ways. One class of descriptors was
derived from categories in the GO (Gene Ontology) biologi-
cal process, GO cellular component, and GO molecular func-
tion taxonomies, that have representation among the chosen
genes. The microarray results from the stresses of Gasch et
al. (relevant to each universal set) were bucketed to yield
range descriptors of the form `expression level  [%x, 0] in
time point %y of stress experiment %z' (for negative %x)
and `expression level  [0, %x] in time point %y of stress
experiment %z' (for positive %x). Notice that we are not
constrained to pick descriptors from only the stresses used to
define the universal set, although we have made that choice
here. Further, k-means clustering was performed using the
Genesis software suite ([18]) on each of the stresses individ-
ually, with a setting of 10 clusters for G1 and 10 and 20
clusters for G2. No descriptors based on k-means clustering
were defined for G3. Since heat shock and mild heat shock
at variable osmolarity are actually pairs of experiments, this
step yields (5+2) × 10 = 70 (for G1) and (7+2) × (10 +
20) = 270 (for G2) descriptors, depicting clusters of genes
with similar temporal profiles. It must be kept in mind
that each of these experiments in turn comprise of multiple
time points, different for each stress. Finally, we included
microarray results from a histone depletion experiment con-
ducted by Wyrick et al. ([20]) and created range descriptors
similar to the Gasch stresses; this is to allow us to relate the
effect of histone depletion to that of environmental stresses.



271
Research Track Paper

Table 2 summarizes the number of descriptors of each type
defined for each of the universal sets, and provides count
statistics. Fig. 8 presents frequency plots for the sizes of
the descriptors in each of the universal sets. As expected, a
majority of descriptors in each case have very few number
of ORFs.

3.3 CARTwheels Configuration
To invoke CARTwheels for a particular universal set, we
initialized X to be all descriptors derived from the Gasch et
al. dataset (which includes the range descriptors as well as
the k-means clusters). This ensures that all redescriptions
will involve some aspect of the Gasch et al. experiment
and prevents the possibility of, say, mining a redescription
between two GO taxonomies. Y was initialized to the set
of all descriptors; thus, there is some overlap between X
and Y . In order to prevent obvious redescriptions arising
from this overlap, the algorithm was precluded from utilizing
descriptors in one tree if they are already present in the other
tree.
We employed a Jaccard's threshold  of 0.5 and a depth-
limit d  2 in both the top and bottom tree induction alter-
nations. The limit on the number of allowable alternations
 is set to 10, and  was varied from 1 to 6. Redescriptions
mined by CARTwheels are subjected to a `tightening' step,
akin to rule pruning in packages like C4.5 ([15]). This might
involve attempting to drop terms from both sides of the re-
description, or restricting range descriptors (if they occur
in the redescription), and determining whether this causes
significant degradation of Jaccard's coefficient. If no degra-
dation is observed, then the redescription can be tightened.
A p-value cutoff of 0.001 for significance of redescriptions
was utilized in this paper. We first describe the qualitative
nature of biological results obtained through redescription
and then assess the exploratory behavior of CARTwheels.
3.4 Example Redescriptions
Seven key mined redescriptions (R1­R7) are depicted in
Fig. 7. R1-R3 are defined over universal set G1, R4-R6 over
G2, and R7 over G3. These redescriptions were selected
for both their biological interest as well as for their feature
construction novelties. The proteins encoded by genes in a
redescription may interact with one another or, with other
proteins not included in the redescription. Such analyses
make it possible to uncover cryptic and subtle features of
gene expression and regulation.
R1 is a redescription where both sides involve descriptors
from gene expression bucketing. It relates negatively ex-
pressed ORFs in the histone depletion experiment with sim-
ilarly expressed ORFs in a Gasch comparison (heat shock).
R1 can be read as `of the 74 ORFs in the first universal
set, the ORFs negatively expressed in the histone deple-
tion experiment (6 hours) are also those that are negatively
expressed two-fold or more in the heat shock (10 minutes)
experiment.' This redescription holds with a Jaccard's coef-
ficient of 0.78. Since each side contains a single descriptor,
this redescription does not present any set construction. R1
involves 7 ORFs, three of which are reported to be regulated
by similar mechanisms, according to the work of Segal et
al. ([17]). These ORFs comprise functions related to meta-
bolism, catalytic activity, and are located in the cytoplasm.
The Pearson coefficients for these ORFs in the histone de-
pletion experiments match very strongly, showcasing the use
of redescription in identifying a concerted set of ORFs.
R2 relates a k-means cluster to a set difference of two re-
lated GO cellular component categories. While the 8 ORFs
in R2 appear to be part of different response pathways, 5
of these 8 ORFs are similarly regulated according to the
work of Segal et al.; these genes relate to the cellular hy-
perorganization and membrane dynamics in the regulation
network.
R3 is actually a triangle of redescription relationships that
illustrates the power of CARTwheels. Three different exper-
imental comparisons are involved in this circular chain of
redescriptions, with 10 ORFs being implicated in all three
descriptors. From a biological standpoint, this is a very in-
teresting result ­ the common genes indicate concerted par-
ticipation across stress conditions; whereas the genes par-
ticipating in, say, two of the descriptors, but not the third,
suggest a careful diversification of functionality. 6 of the 10
ORFs are related to cell growth and maintenance. 5 of the
10 ORFs have binding motifs related to the DNA binding
protein REB1. The importance of phosphate and ribosomes
appears to be salient in this redescription. It is important
to note that the circularity of R3 is not directly mined by
CARTwheels, but inferred post-hoc from a linear chain.
The theme in R4 is ribosome assembly/biogenesis and
RNA processing. R4 is a linear chain comprising two re-
descriptions, and uses a GO descriptor as an intermediary
between two expression-based descriptors. It is also inter-
esting that this redescription involves a set of 45 ORFs!
R5 is an even longer chain involving 41 ORFs that are
common to all descriptors. Notice the rather complicated
set construct involving a disjunction of a conjunction and a
difference, involving three different GO biological categories.
Incidentally, this is the most complicated set expression rep-
resentable in a 2-level tree.
R6 is a relationship between two k-means clusters, be-
tween heat shock stresses. The ORFs participating in R6
demonstrate a clear focus on sugar or sugar phosphate meta-
bolism.
R7 is a redescription relating a disjunction of descriptors
to a GO cellular component category. It is also our first ex-
ample of a redescription where a rectangular region is mined
in a 2D space involving two different experimental compar-
isons. Usually such a region would require a 4-level tree, but
since it is bounded by the extremal values specific to each
experiment, it can be captured by a conjunction of merely
two descriptors.


3.5 Effect of  and 
If we view the alternation process as one of information
retrieval, we can adapt traditional precision and recall met-
rics for algorithm assessment. Precision here refers to the
number of unique redescriptions as a fraction of the total
number of redescriptions mined. Recall refers to the num-
ber of unique redescriptions as a fraction of the total number
of redescriptions possible. Unfortunately, the latter metric
is nearly impossible to attain, even for our depth limit of
2. For even the smallest universal set considered here, the
size of the space of possible redescriptions is O(1014)! Our
approach hence is to track precision and the total number
of redescriptions, across various values of . Fig. 9 shows
the monotonic decrease of precision as  is increased, and
Fig. 10 depicts the steady increase in the total number of
redescriptions mined. These graphs indicate that the trade-
off between redundancy and exploration holds across all the



272
Research Track Paper

YCL040W, YDR171W, YER103W, YFL014W,
YFR053C, YGL037C, YGR088W, YGR248W,
YHL021C, YHR104W, YLL026W, YLR178C,
YLR327C, YML100W, YML128C, YMR105C,
YMR250W, YOR173W, YOR374W
Redescription R6
ORF List
Time Point (HS29_TO_33)
5
10
15
20
25
30
Relative
Expression
Level




-4
-2
0
2
4
6




Time Point (HS1)
0
20
40
60
80
Relative
Expression
Level




-4
-2
0
2
4
6
8
0.51
Trend (HS29_TO_33) <=> Trend (HS1)
Time Point (HS2)
5 10 15 20 25 30 35 40 45 50 55 60
Relative
Expression
Level




-4
-3
-2
-1
0
1
2




Time Point (SORB_1M)
0
20
40
60
80
100
120
Relative
Expression
Level




-3
-2
-1
0
1
2




Time Point (SORB_29C_1M_TO_33C_NO)
5
10
15
20
25
30
Relative
Expression
Level




-1
0
1
2
Trend (HS2) <=> Trend (SORB_1M) <=> Trend (SORB_29C_1M_TO_33C_NO) <=> Trend (HS2)




Redescription
R3
ORF List


YAL025C
YBR247C
YCL054W
YGR145W
YHR052W
YML123C
YMR185W
YNL141W
YPL019C
YPR112C
0.82




0.63
0.69
Heat Shock (hs-1), 30 minutes <= -2 <=>
Cellular GO category 5730: nucleolus <=> 0.32
mM H2O2 30 minutes <= -1

Redescription R4
ORF List

YBR247C, YCL059C,
YDL148C, YDL153C,
YDR398W, YGL029W,
YGL078C, YGL171W,
YGR159C, YHR088W,
YHR089C, YHR169W,
YHR196W, YKL078W,
YKL099C, YKL172W,
YKR081C, YLL008W,,
YLL011W, YLR002C,
YLR129W, YLR175W,
YLR197W, YLR222C,
YLR276C, YML093W,
YMR131C, YMR229C,
YMR290C, YNL002C,
YNL061W, YNL110C,
YNL175C, YNL248C,
YNL308C, YOL041C,
YOL077C, YOR145C,
YOR310C, YOR340C,
YPL043W, YPL093W,
YPL126W, YPL211W,
YPL266W
Nucleolus




-1
Heat Shock 30 minutes
hs-1
-2-3-4-5-6
0
-7
-1
0.32 mM H2O2, 30
minutes
-2-3-4-5-6
0-7




0.51




0.56
Heat Shock (hs-1), 10 minutes <= -2 <=>
Histone depletion, 6 hr >= -6


0.78




Redescription R1
ORF List
-1
Heat Shock 10
minutes hs-1
-2-3-4-5-6
0
0

Histone
depletion, 6 hr
-1-2-3-4-5-6




YAL025C, YGL055W,
YGR145W, YML123C
YNL141W, YOR315W,
YPL093W
Redescription
R2
ORF List




Time Point (H2O2)
20
40
60
80
100 120 140
160
Relative
Expression
Level




-3
-2
-1
0
1
2




YDR342C, YGL055W
YHR094C, YHR096C
YML123C, YOL084W
YOL101C, YPL019C
Membrane




Inner
Membrane
0.89
Cellular GO category 16020: membrane AND NOT Cellular GO category 19866: inner membrane<=> Trend (H2O2)




Cellular GO category 5618: cell wall <=> 29C +1M sorbitol to 33C + 1M sorbitol , 15 minutes>= 1 AND 0.32 mM
H2O2, 20 min >= 2 OR 29C +1M sorbitol to 33C + 1M sorbitol , 30 minutes<= -2



Redescription R7
ORF List


YKL096W
YOR382W
YPL130W
0.75
Cell wall
-1
29C +1M sorbitol to
33C + 1M sorbitol,
30 minutes
-2-3-4
0




29C +1M sorbitol to 33C
+ 1M sorbitol , 15 minutes
0.32
mM
H2O2,
20




minutes
6
5
4
3
2
1
7




1
5432
Heat Shock, 15 minutes hs-2 <= -1 <=> (Biological GO category 7010: cytoskeleton organization and biogenesis AND
Biological GO category 80: G1 phase of mitotic cell cycle) OR (Biological GO category 42254: ribosome biogenesis
and assembly AND NOT Biological GO category 7010: cytoskeleton organization and biogenesis)<=> Heat Shock 10
minutes, hs-1<= -2 <=> Biological GO category 7046: ribosome biogenesis <=> Heat Shock 30 minutes hs-1 <= -1




Redescription R5
ORF List
-1
Heat Shock 10
minutes hs-1
-2-3-4-5-6
0
Ribosome
biogenesis
G1 phase of
mitotic cell
cycle
ribosome
biogenesis and
assembly
cytoskeleton
organization
and biogenesis




-1
Heat Shock 15
minutes hs-2
-2-3-4-5-6
0
-1
Heat Shock 30
minutes hs-1
-2-3-4-5-6
0
-7
0.58
0.53




0.55
0.51
YBR247C, YDL014W, YDL148C, YDL153C,
YDR087C, YDR398W, YGL029W, YGL078C,
YGL171W, YGR103W, YHR089C, YHR169W,,
YHR196W, YKL009W, YKL078W, YKL099C,
YKL172W, YKR081C, YLL008W, YLL011W,
YLR002C, YLR009W, YLR129W, YLR175W,
YLR197W, YLR222C, YLR276C, YML093W,
YMR131C, YMR229C, YNL002C, YNL061W,
YNL075W, YNL110C, YNL308C, YOR294W,
YOR310C, YPL043W, YPL126W, YPL211W,
YPL266W




Figure 7: Seven redescriptions mined from gene expression studies on Saccharomyces cerevisiae. Each box gives
a readable statement of the redescription, presents it in graphical form, and identifies the ORFs conforming
to the redescription. R1-R3 are defined over universal set G1, R4-R6 over G2 and R7 over G3. The Jaccard's
coefficient is displayed over the redescription arrow. Notice that some redescriptions (e.g., R7) involve few
ORFs, whereas others such as R5 involve larger numbers.



273
Research Track Paper

0
10
20
30
40
50
60
0
50
100
150
200
250
300
350
400




size of descriptors
frequency
Descriptors defined over G1




0
50
100
150
200
250
0
100
200
300
400
500
600
Descriptors defined over G2




frequency




size of descriptors
0
20
40
60
80
100
120
0
100
200
300
400
500
600




frequency




size of descriptors
Descriptors defined over G3




Figure 8: Frequency plot of descriptor sizes for universal set G1, G2, and G3, respectively.

datasets considered here. A formal characterization is un-
derway.
The effect of  parameter, that controls the number of
unsuccessful consecutive alternations, is as expected: in-
creasing  results in a greater number of (total and unique)
redescriptions mined (not shwon for space considerations).
4. DISCUSSION
This paper is a first exploration into the formulation of
the redescription mining problem and has presented an ap-
proach for mining redescriptions automatically. Redescrip-
tions can be thought of as generalizations of one-directional
implications (e.g., association rules [1], rules in ILP [14]),
where one descriptor is required to be a proper subset of the
other. This generalization coupled with the automatic iden-
tification of set-theoretic constructions makes CARTwheels
a very powerful approach to mining (approximate) equiva-
lence relations. We have demonstrated the effectiveness of
CARTwheels in a domain that exhibits a richness of descrip-
tors, and shown how it captures patterns involving small as
well as large sets of objects.
The work presented here has close connections with ideas
pursued in the schema matching [16], clustering categorical
data [6], and model management [2] literature. The relation-
ships considered in schema matching research are primarily
of the foreign key nature or otherwise operate at the instance
level, whereas we consider more complex set-theoretic rela-
tionships. Clustering categorical data focuses on defining
similarity measures in non-metric spaces and this research
can be fruitfully integrated with our work. However, notice
that we are not merely clustering data but also imposing de-
scribability constraints. Model management is a framework
that recognizes the complex inter-relationships that would
exist in multi-database enterprises and provides union, in-
tersection, and difference operators for reconciliation, inte-
gration, and migration purposes. The relationships here are
assumed to be user provided, and the emphasis is on actually
`executing a redescription.' CARTwheels can thus be use-
fully employed here as a driver for determining what these
relationships should be.
We now outline some directions for future research. The
connection between Jaccard's coefficient and algorithmic dri-
ver parameters (such as entropy) deserves further study.
Other ways of evaluating redescriptions [10, 11] are also per-
tinent here (e.g., Dice coefficient) and some of these could
support more efficient tree-based algorithms than the Jac-
card's coefficient. Ideally, an evaluation metric would obey
some closure properties in the space of redescriptions, which
can be used to configure an exploration strategy. In addi-
tion, it is preferable that an evaluation metric lend itself to
the design of a statistical test of significance for redescrip-
tions.
Thus far, we have assumed a `flat' organization of the
given descriptors and do not recognize any structural rela-
tionships between them. However, some descriptor vocabu-
laries (e.g., derived from GO) enjoy a hierarchical structure,
which can be exploited by the mining algorithm. Specialized
redescription algorithms can thus be designed for targeted
descriptor families.
There are various other formulations of the redescription
mining problem, in particular the question of identifying a
generating set of redescriptions is open. This will avoid hav-
ing to find all redescriptions and instead allow us to exploit
the algebraic structure of descriptors, akin to the strategy
pursued by Zaki for mining a non-redundant set of associa-
tion rules [21].
There is an intrinsic limit to a dataset's potential to re-
veal redescriptions, which can be studied through statistical
analysis of set size distributions and estimates of overlap
potential. Of particular interest here is qualifying the `ex-
pected' results from a CARTwheels alternation before ac-
tually performing the alternation, using notions such as the
entropy rate of the stochastic process underlying the alter-
nation [4].
Our current focus is on using redescriptions to automati-
cally span multiple levels of abstraction (e.g., gene subsets 
pathways  biological processes). This would firmly estab-
lish the importance of redescription in bridging the diverse
levels at which information is created and characterized.

Acknowledgements
NR and DK are supported by NSF grants EIA-9984317 and
EIA-0103660. The work of MP and RH is supported through
the Multidisciplinary University Research Initiative (MURI)
program of the Department of Defense (Biomimetic Cell and
Tissue Stasis; N00014-01-1-0852) and the Metabolic Engi-
neering for Cellular Stasis program of DARPA (N00173-98-
1-G005-P00004 and N00173-02-1-G016). BM is supported
by grants from NSF's ITR, QuBIC, and SGER programs,
DARPA, the US Air Force (AFRL), National Institutes of
Health (NIH), and New York State Office of Science, Tech-
nology & Academic Research (NYSTAR). We thank Chris
Bailey-Kellogg and T.M. Murali for useful comments.


5. REFERENCES

[1] R. Agrawal and R. Srikant. Fast Algorithms for
Mining Association Rules in Large Databases. In
Proceedings of VLDB'94, pages 487­499, Sep 1994.



274
Research Track Paper

Figure 9: Precision for redescriptions mined vs.  for universal set G1, G2, and G3, respectively.




Figure 10: Total number of redescriptions mined vs.  for universal set G1, G2, and G3, respectively.

[2] P.A. Bernstein, R. Pottinger, and A.Y. Halevy. A
Vision for Management of Complex Models. SIGMOD
Record, Vol. 29(4):pages 55­63, Dec 2000.
[3] L. Breiman, J.H. Friedman, R.A. Olshen, and C.J.
Stone. Classification and Regression Trees. Chapman
and Hall/CRC, 1984.
[4] T.M. Cover and J.A. Thomas. Elements of
Information Theory. John Wiley and Sons, 1991.
[5] D.H. Fisher. Knowledge Acquisition via Incremental
Conceptual Clustering. Machine Learning, Vol.
2(2):pages 139­172, 1987.
[6] V. Ganti, J. Gehrke, and R. Ramakrishnan. CACTUS:
Clustering Categorical Data using Summaries. In
Proceedings of KDD'99, pages 73­83, Aug 1999.
[7] V. Ganti, J. Gehrke, and R. Ramakrishnan. Mining
Very Large Databases. IEEE Computer, Vol.
32(8):pages 38­45, Aug 1999.
[8] A.P. Gasch, P.T. Spellman, C.M. Kao,
O. Carmel-Harel, M.B. Eisen, G. Storz, D. Botstein,
and P.O. Brown. Genomic Expression Programs in the
Response of Yeast Cells to Environmental Changes.
Molecular Biology of the Cell, Vol. 11:pages
4241­4257, 2000.
[9] J. Gehrke, R. Ramakrishnan, and V. Ganti.
RainForest: A Framework for Fast Decision Tree
Construction of Large Datasets. Data Mining and
Knowledge Discovery, Vol. 4(2/3):pages 127­162, July
2000.
[10] J.C. Gower and P. Legendre. Metric and Euclidean
Properties of Dissimilarity Coefficients. Journal of
Classification, Vol. 3:pages 5­48, 1986.
[11] W.P. Jones and G.W. Furnas. Pictures of Relevance:
A Geometric Analysis of Similarity Measures. Journal
of the American Society for Information Science, Vol.
38(6):pages 420­442, 1987.
[12] R.S. Michalski. Knowledge Acquisition through
Conceptual Clustering: A Theoretical Framework and
Algorithm for Partitioning Data into Conjunctive
Concepts. International Journal of Policy Analysis
and Information Systems, Vol. 4:pages 219­243, 1980.
[13] A.W. Moore and M.S. Lee. Cached Sufficient
Statistics for Efficient Machine Learning with Large
Datasets. JAIR, Vol. 8:pages 67­91, 1998.
[14] S. Muggleton. Scientific Knowledge Discovery using
Inductive Logic Programming. CACM, Vol.
42(11):pages 42­46, Nov 1999.
[15] J.R. Quinlan. C4.5: Programs for Machine Learning.
Morgan Kaufmann, 1993.
[16] E. Rahm and P.A. Bernstein. A Survey of Approaches
to Automatic Schema Matching. VLDB Journal, Vol.
10(4):pages 334­350, 2001.
[17] E. Segal, M. Shapira, A. Regev, D. Pe'er, D. Botstein,
D. Koller, and N. Friedman. Module Networks:
Identifying Regulatory Modules and their
Condition-Specific Regulators from Gene Expression
Data. Nature Genetics, Vol. 34(2):pages 166­176,
2003.
[18] A. Sturn, J. Quackenbush, and Z. Trajanoski. Genesis:
Cluster Analysis of Microarray Data. Bioinformatics,
Vol. 18(1):pages 207­208, 2002.
[19] R.E. Valdes-Perez, V. Pericliev, and F. Pereira.
Concise, Intelligible, and Approximate Profiling of
Multiple Classes. International Journal of Human
Computer Studies, Vol. 53(3):pages 411­436, 2000.
[20] J.J. Wyrick, F.C. Holstege, E.G. Jennings, H.C.
Causton, D. Shore, M. Grunstein, E.S. Lander, and
R.A. Young. Chromosomal Landscape of
Nucleosome-Dependent Gene Expression and Silencing
in Yeast. Nature, Vol. 402:pages 418­421, 1999.
[21] M. Zaki. Generating Non-Redundant Association
Rules. In Proceedings of KDD'00, pages 34­43, 2000.




275
Research Track Paper

