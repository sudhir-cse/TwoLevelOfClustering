Generating Non-Redundant Association Rules


Mohammed J. Zaki
Computer Science Department, Rensselaer Polytechnic Institute, Troy NY 12180
zaki@cs.rpi.edu, http://www.cs.rpi.edu/ zaki




ABSTRACT
The traditional association rule mining framework produces
many redundant rules. The extent of redundancy is a lot larger
than previously suspected. We present a new framework for
associations based on the concept of closed frequent itemset-
s. The number of non-redundant rules produced by the new
approach is exponentially (in the length of the longest fre-
quent itemset) smaller than the rule set from the traditional
approach. Experiments using several "hard" as well as "easy"
real and synthetic databases confirm the utility of our frame-
work in terms of reduction in the number of rules presented to
the user, and in terms of time.


Categories and Subject Descriptors
H.2.8 [Database Management]: Applications--Data Min-
ing; I.2.6 [Artificial Intelligence]: Learning


1. INTRODUCTION
Association rule discovery, a successful and important mining
task, aims at uncovering all frequent patterns among transac-
tions composed of data attributes or items. Results are present-
ed in the form of rules between different sets of items, along
with metrics like the joint and conditional probabilities of the
antecedent and consequent, to judge a rule's importance.

It is widely recognized that the set of association rules can
rapidly grow to be unwieldy, especially as we lower the fre-
quency requirements. The larger the set of frequent itemsets
the more the number of rules presented to the user, many of
which are redundant. This is true even for sparse datasets, but
for dense datasets it is simply not feasible to mine all possi-
ble frequent itemsets, let alone to generate rules, since they
typically produce an exponential number of frequent itemsets;
finding long itemsets of length 20 or 30 is not uncommon [2].

Prior research has mentioned that the traditional association
rule mining framework produces too many rules, but the ex-
tent of redundancy is a lot larger than previously suspected.
More concretely, the number of redundant rules are exponen-
tial in the length of the longest frequent itemset. We present a
new framework for association rule mining based on the con-
cept of closed frequent itemsets. The set of all closed frequent
itemsets can be orders of magnitude smaller than the set of all
frequent itemsets, especially for real (dense) datasets. At the
same time, we don't loose any information; the closed item-
sets uniquely determine the set of all frequent itemsets and
their exact frequency. Note that using the maximal frequent
itemsets results in loss of information, since subset frequency
is not available. We show that the new framework produces
exponentially (in the length of the longest frequent itemset)
fewer rules than the traditional approach, again without loss
of information. Our framework allows us to mine even dense
datasets, where it is not feasible to find all frequent itemsets.
Finally, the rule set we produce is a generating set, i.e., al-
l possible association rules can be inferred from them using
operations like transitivity and augmentation.

Experiments using several "hard" or dense, as well as sparse
databases confirm the utility of our framework in terms of re-
duction in the number of rules presented to the user, and in
terms of time. We show that closed itemsets can be found
in a fraction of the time it takes to mine all frequent itemsets
(with improvements of more than 100 times), and the number
of rules returned to the user can be smaller by a factor of 3000
or more! (the gap widens for lower frequency values).


1.1 Related Work
There has been a lot of research in developing efficient algo-
rithms for mining frequent itemsets [1, 2, 4, 9, 15, 21]. Most of
these algorithms enumerate all frequent itemsets. Using these
for rule generation produces many redundant rules, as we will
show later. Some methods only generate maximal frequen-
t itemsets [2, 9]. Maximal itemsets cannot be used for rule
generation, since support of subsets is required for confidence
computation. While it is easy to make one more data scan to
gather the supports of all subsets, we still have the problem
of many redundant rules. Further, for all these methods it is
simply not possible to find rules in dense datasets which may
easily have frequent itemsets of length 20 and more [2]. In
contrast the set of closed frequent itemsets can be orders of
magnitude smaller than the set of all frequent itemsets, and it
can be used to generate rules even in dense domains.
Permission to make digital or hard copies of part or all of this work or
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers, or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD 2000, Boston, MA USA
© ACM 2000 1-58113-233-6/00/08 ...$5.00




34

In general, most of the association mining work has concen-
trated on the task of mining frequent itemsets. Rule generation
has received very little attention. There has been some work
in pruning discovered association rules by forming rule cover-
s [17]. Other work addresses the problem of mining interesting
association rules [8, 3, 10, 12]. The approach taken is to incor-
porate user-specified constraints on the kinds of rules generat-
ed or to define objective metrics of interestingness. As such
these works are complimentary to our approach here. Further-
more, they do not address the issue of rule redundancy or of
constructing a generating set.

A preliminary study of the idea of using closed frequent item-
sets to generate rules was presented by us in [20]. This paper
substantially improves on those ideas, and also presents exper-
imental results to support our claims. Independently, Pasquier
et al. have also used closed itemsets for association mining [13,
14]. However, they mainly concentrate on the discovery of
frequent closed itemsets, and do not report any experiments
on rule mining. We on the other hand are specifically inter-
ested in generating a smaller rule set, after mining the fre-
quent closed itemsets. Furthermore, we recently proposed the
CHARM algorithm [19] for mining all closed frequent item-
sets. This algorithm outperforms, by orders of magnitude, the
AClose method proposed by Pasquier et al [14], as well as the
Apriori [1] method for mining all frequent itemsets. In this pa-
per we do not present the CHARM algorithm, since our main
goal is rule generation; we simply use the output it produces.

The notion of closed frequent sets has its origins in the ele-
gant mathematical framework of formal concept analysis (F-
CA). A number of algorithms have been proposed within F-
CA for generating all the closed sets of a binary relation [5].
However, these methods have only been tested on very small
datasets. Further, these algorithms generate all the closed set-
s, and thus have to be adapted to enumerate only the frequent
concepts. The foundations of rule generation (in FCA) were
studied in [11], but no experimentation on large sets was done.
Our characterization of the generating set of association rules
is different, and we also present an experimental verification.
Other work has extended the FCA approach to incorporate in-
cremental rule mining [6], and recent work has addressed the
issue of extracting association rule bases [16].

The rest of the paper is organized as follows. Section 2 de-
scribes the association mining task. Section 3 presents the
notion of closed itemsets. Section 4 looks at the problem of
eliminating redundant rules. We experimentally validate our
approach in Section 5. The proofs for all theorems have been
omitted due to lack of space; these are available in [18].


2. ASSOCIATION RULES
The association mining task can be stated as follows: Let
Á
½ ¾ ¡¡¡
Ñ be a set of items, and let
Ì
½ ¾ ¡¡¡
Ò
be a set of transaction identifiers or tids. The input database
is a binary relation Æ
Á ¢ Ì.
If an item
occurs in a
transaction Ø, we write it as
´
Ø
µ ¾
Æ, or alternately as ÆØ.
Typically the database is arranged as a set of transactions,
where each transaction contains a set of items. For exam-
ple, consider the database shown in Figure 1, used as a run-
ning example in this paper. Here
Á
Ì Ï , and
Ì
½ ¾ ¿
. The second transaction can be repre-
sented as
Æ
¾
Æ
¾
ÏÆ
¾
; all such pairs from all transac-
tions, taken together form the binary relation Æ. A set
Á
is called an itemset, and a set
Ì
is called a tidset. For
convenience we write an itemset
Ï as
Ï, and a
tidset
¾
as
¾
. The support of an itemset
, denoted
´ µ,
is the number of transactions in which it occurs as a
subset. An itemset is frequent if its support
´ µ
minsup,
where minsup is a user-specified minimum support threshold.


An association rule is an expression
Ô
 
, where
and
are itemsets. The support of the rule is
´
µ(i.e.,
the
joint probability of a transaction containing both
and
),
and the confidence Ô
´
µ ´ µ(i.e.,
the conditional
probability that a transaction contains
, given that it contains
). A rule is frequent if the itemset
is frequent. A
rule is confident if Ô
Ñ Ò ÓÒ , where where minconf is a
user-specified minimum threshold.




C D T
A C D T W
A C D W
A C T W
C D W
A C T W
A
C
D
T
W




6
5
3


4
2
1
DATABASE


MINIMUM SUPPORT = 50%
ALL FREQUENT ITEMSETS




C


W, CW

A, D, T, AC, AW
CD, CT, ACW
100% (6)


83% (5)


67% (4)


50% (3)
AT, DW, TW, ACT, ATW
ItemsetsSupport




CTW,CDW,
ACTW
ItemsTranscation
Jane
Austen
Agatha
Christie
Sir Arthur
DISTINCT DATABASE ITEMS


Conan Doyle
P. G.
Wodehouse
Mark
Twain




Figure 1: Generating Frequent Itemsets
Association rule mining consists of two steps [1]: 1) Find all
frequent itemsets, and 2) Generate high confidence rules.

Finding frequent itemsets This step is computationally and
I/O intensive. Consider Figure 1, which shows a bookstore
database with six customers who buy books by different au-
thors. It shows all the frequent itemsets with Ñ Ò×ÙÔ
¼±
(i.e., 3 transactions).
ÌÏ and
Ï are the maximal fre-
quent itemsets (i.e., not a subset of any other frequent itemset).

Let
Á
Ñ be the number of items. The search space for enu-
meration of all frequent itemsets is
¾
Ñ
, which is exponential
in Ñ. One can prove that the problem of finding a frequen-
t set of a certain size is NP-Complete, by reducing it to the
balanced bipartite clique problem, which is known to be NP-
Complete [20]. However, if we assume that there is a bound on
the transaction length, the task of finding all frequent itemsets
is essentially linear in the database size, since the overall com-
plexity in this case is given as Ç
´Ö¡Ò¡¾
Ð
µ,
where
Ì
Ò is the
number of transactions, Ð is the length of the longest frequent
itemset, and Ö is the number of maximal frequent itemsets.

Generating confident rules This step is relatively straightfor-
ward; rules of the form
Ô
 
 
, are generated for all
frequent itemsets
, for all
,
, and provid-
ed Ô
Ñ Ò ÓÒ . For example, from the frequent itemset




35

A
C (4/4)
W (4/4)A
A
CW (4/4)
C (4/4)D
T
C (4/4)
W
C (5/5)
AC
AT
AT
AW
DW
TW
A (3/3)
W (3/3)


C (3/3)
C (4/4)
C (3/3)
W (4/4)
TW
AT
TW
ACT
ATW
CTW
A (3/3)
C (3/3)
W (3/3)
AC (3/3)
CW (3/3)
C (3/3)




AC (4/5) CW
A (4/5)WW (5/6)A (4/5) CW
100% (6)

83% (5)

67% (4)
Support



W, CW
C
Item-Sets
FREQUENT ITEMSET: ACW




POSSIBLE RULES: ACW
A, AC, AW, ACW
ASSOCIATION RULES (conf = 100%)




A
C
W
AC
AW
AC (4/5)
CW (4/4)
AW (4/6)
W (4/4)
C (4/4)
CW
A (4/5)
ASSOCIATION RULES (100% > conf >= 80%)




Figure 2: Generating Confident Rules


Ï we can generate 6 possible rules (all of them have sup-
port of 4):
½ ¼
 
Ï
¼
 
Ï Ï
¼
 
½ ¼
 
Ï Ï
½ ¼
 
, and
Ï
¼
 
. This process is also shown
pictorially in Figure 2. Notice that we need access to the sup-
port of all subsets of
Ï to generate rules from it. To obtain
all possible rules we need to examine each frequent itemset
and repeat the rule generation process shown above for
Ï.
Figure 2 shows the set of all other association rules with con-
fidence above or equal to minconf = 80%.

For an itemset of size
there are
¾  ¾potentially
confident
rules that can be generated. This follows from the fact that
we must consider each subset of the itemset as an antecedent,
except for the empty and the full itemset. The complexity of
the rule generation step is thus Ç
´ ¡¾
Ð
µ,
where is the number
of frequent itemsets, and Ð is the longest frequent itemset.



3. CLOSED FREQUENT ITEMSETS
In this section we describe the concept of closed frequent item-
sets, and show that this set is necessary and sufficient to cap-
ture all the information about frequent itemsets, and has small-
er cardinality than the set of all frequent itemsets.

Let
´È µbe
an ordered set with the binary relation
, and
let Ë be a subset of È. An element Ù
¾È
(Ð
¾È)
is an upper
bound (lower bound) of Ë if ×
Ù (×
Ð) for all ×
¾
Ë.
The least upper bound is called the join of Ë, and is denoted
as
ÏË
, and the greatest lower bound is called the meet of Ë,
and is denoted as
ÎË
. If Ë
Ü Ý , we also write Ü Ý for
the join, and Ü Ý for the meet. An ordered set
´Ä µis
a
lattice, if for any two elements Ü and Ý in Ä, the join Ü Ý
and meet Ü Ý always exist. Ä is a complete lattice if
ÏË
and
ÎË
exist for all Ë Ä. Any finite lattice is complete.

Let
È
denote the power set of Ë (i.e., the set of all subsets
of Ë). The ordered set (
È´Ëµ
) is a complete lattice, where
the meet is given by set intersection, and the join is given by
set union. For example the partial orders
´È´Áµ µ,
the set
of all possible itemsets, and
´È´Ìµ µ,
the set of all possible
AC
AWAT
CD
CT
CW
DW
TW
CTWCDWATWACWACT
ACTW




(CD x 2456)
(CT x 1356)
(CW x 12345)
(ACW x 1345)(ACT x 135)
(ATW x 135)
(ACTW x 135)




(AT x 135)
(AW x 1345)
(DW x 245)
(TW x 135)(AC x 1345)




(C x 123456)
A

(A x 1345)
DC

(D x 2456)
T

(T x 1356)
(W x 12345)
W
(CDW x 245)
(ACTW x 135)




Figure 3: Frequent Itemsets

tidsets are both complete lattices. Figure 3 shows the lattice
1

of all frequent itemsets we found in our example database.

Let the binary relation Æ
Á ¢Ì
be the input database for
association mining. Let
Á,
and
Ì.
The mappings
Ø
Á Ì
Ø
´ µ
Ý
¾Ì
Ü
¾
ÜÆÝ
Ì Á ´ µ
Ü
¾Á
Ý
¾
ÜÆÝ
define a Galois connection between
È´Áµ
and
È´Ìµ.
We
denote a
Ø
´ µ
pair as
¢Ø´ µ,
and a
´ µ
pair as
´ µ¢
. Figure 4 illustrates the two mappings. The map-
ping Ø
´ µ
is the set of all transactions (tidset) which con-
tain the itemset
, similarly
´ µis
the itemset that is con-
tained in all the transactions in
. For example, Ø
´
Ï
µ
½¿
, and
´¾ µ
Ï. In terms of individual elements
Ø
´ µ
Ì
Ü
¾
Ø
´Üµ,
and
´ µ
Ì
Ý
¾
´Ýµ.
For example
Ø
´
Ï
µ
Ø
´ µ
Ø
´ µ
Ø
´Ïµ ½¿ ½¾¿ ½¾¿
½¿
. Also
´¾ µ ´¾µ ´ µ ´ µ
Ï
Ï
ÌÏ
Ï. The Galois connection satisfies the fol-
lowing properties (where
½
¾
¾ È´Áµ
and
½ ¾
-
¾ È´Ìµ):
1)
½
¾
µ
Ø
´
½
µ
Ø
´
¾
µ,
2)
½
¾
µ
´
½
µ ´
¾
µ,
3)
´Ø´ µµand
Ø
´ ´ µµ.
For ex-
ample, for
Ï
ÌÏ, Ø
´
Ï
µ ½¿
½¿
Ø
´
ÌÏ
µ.
For
¾
¾
,
´¾ µ
Ï
´¾ µ.
Also,
´Ø´ µµ ´½¿ µ
Ï.

Let Ë be a set. A function
È´Ëµ È´Ëµ
is a closure
operator on S if, for all
Ë,
satisfies the following
properties: 1) Extension:
´ µ.
2) Monotonicity: if
, then
´ µ ´ µ.
3) Idempotency:
´ ´ µµ
´ µ.
A subset
of Ë is called closed if
´ µ
. Let
Á
and
Ì.
Let
Ø
´ µdenote
the composition of
the two mappings
ÆØ´ µ ´Ø´ µµ.
Dually, let
Ø
´ µ
Ø
Æ ´ µ
Ø
´ ´ µµ.
Then
Ø
È´Áµ È´Áµ
and
Ø
È´Ìµ È´Ìµare
both closure operators.

We define a closed itemset as an itemset
that is that same as
its closure, i.e.,
Ø
´ µ.
For example the itemset
Ï
is closed. A closed tidset is a tidset
Ø
´ µ.
For example,
½Only
meet is defined on frequent sets, while the join may not exist. For exam-
ple,
Ì
Ì
is frequent. But, while
Ì
Ì
Ì
is frequent,
Ï
Ï
is not frequent.




36

i
X




i(Y)
t
TRANSACTIONSITEMS




Y
t(X)




it
ITEMS
TRANSACTIONS



X




C (X) = i(t(X))
t(X)
t




i




Figure 4: A) Galois Connection, B) Closed Itemset: Round-Trip

the tidset
½¿
is closed.

The mappings
Ø
and
Ø
, being closure operators, satisfy the
three properties of extension, monotonicity, and idempotency.
We also call the application of
ÆØor
Ø
Æ
a round-trip. Fig-
ure 4 illustrates this round-trip starting with an itemset
. For
example, let
, then the extension property say that
is a subset of its closure, since
Ø
´ µ ´Ø´ µµ
´½¿ µ
Ï. Since
Ø
´ µ
Ï, we
conclude that
is not closed. On the other hand, the idem-
potency property say that once we map an itemset to the tidset
that contains it, and then map that tidset back to the set of
items common to all tids in the tidset, we obtain a closed item-
set. After this no matter how many such round-trips we make
we cannot extend a closed itemset. For example, after one
round-trip for
we obtain the closed itemset
Ï. If we
perform another round-trip on
Ï, we get
Ø
´
Ï
µ
´Ø´
Ï
µµ ´½¿ µ
Ï.

For any closed itemset
, there exists a closed tidset given by
, with the property that
Ø
´ µ
and
´ µ
(con-
versely, for any closed tidset there exists a closed itemset). We
can see that
is closed by the fact that
´ µ,
then plug-
ging
Ø
´ µ,
we get
´ µ ´Ø´ µµ
Ø
´ µ,
thus
is closed. Dually,
is closed. For example, we have
seen above that for the closed itemset
Ï the associated
closed tidset is
½¿
. Such a closed itemset and closed tidset
pair
¢
is called a concept.

A concept
½
¢
½
is a subconcept of
¾
¢
¾
, denoted as
½
¢
½
¾
¢
¾
, iff
½
¾
(iff
¾
½
). Let
´Æµ
denote the set of all possible concepts in the database. Then
the ordered set
´ ´Æµ µis
a complete lattice, called the Ga-
lois lattice. For example, Figure 5 shows the Galois lattice
for our example database, which has a total of 10 concepts.
The least element is
¢ ½¾¿
and the greatest elemen-
t is
ÌÏ
¢
. The mappings between the closed pairs
of itemsets and tidsets are anti-isomorphic, i.e., concepts with
large cardinality itemsets have small tidsets, and vice versa.

The concept generated by a single item Ü
¾ Á
is called an
item concept, and is given as
´Üµ
Ø
´Üµ¢Ø´Üµ.
Simi-
larly, the concept generated by a single transaction Ý
¾ Ì
is
called a tid concept, and is given as
Ø
´Ýµ ´Ýµ¢
Ø
´Ýµ.
For example, the item concept
´ µ ´Ø´ µµ¢Ø´ µ
´½¿ µ¢½¿
Ï
¢½¿
. Further, the tid concept

Ø
´¾µ ´¾µ¢Ø´ ´¾µµ
Ï
¢Ø´
Ï
µ
Ï
¢¾
.
In Figure 5 if we relabel each node with the item concept or
tid concept that it is equivalent to, then we obtain a lattice with
minimal labelling, with item or tid labels, as shown in the fig-
ure in bold letters. Such a relabelling reduces clutter in the
lattice diagram, which provides an excellent way of visualiz-
ing the structure of the patterns and relationships that exist be-
tween items. We shall see its benefit in the next section when
we talk about high confidence rules extraction.

It is easy to reconstruct the concepts from the minimal label-
ing. Consider the tid concept
Ø
´¾µ
¢
. To obtain
the closed itemset
, we append all item labels reachable be-
low it. Conversely, to obtain the closed tidset
we append
all labels reachable above
Ø
´¾µ.
Since Ï,
and
are all
the labels reachable by a path below it,
Ï forms
the closed itemset. Since and
are the only labels reachable
above
Ø
´¾µ,
¾
; this gives us the concept
Ï
¢¾
,
which matches the concept shown in the figure.


3.1 Frequent Closed Itemsets vs. Frequent
Itemsets
We begin this section by defining the join and meet operation
on the concept lattice (see [5] for the formal proof): The set of
all concepts in the database relation Æ, given by
´ ´Æµ µis
a
(complete) lattice with join and meet given by

join:
´
½
¢
½
µ ´
¾
¢
¾
µ
Ø
´
½
¾
µ¢´
½
¾
µ
meet:
´
½
¢
½
µ ´
¾
¢
¾
µ ´
½
¾
µ¢
Ø
´
½
¾
µ
For the join and meet of multiple concepts, we simply take
the unions and joins over all of them. For example, consider
the join of two concepts,
´
Ï
¢ µ ´
Ì
¢ µ
Ø
´
Ï
Ì
µ¢´
µ
ÌÏ
¢
. On the
other hand their meet is given as,
´
Ï
¢ µ ´
Ì
¢
µ ´
Ï
Ì
µ¢
Ø
´
µ
¢
Ø
´ µ
¢¾
. Similarly, we can perform multiple concept join-
s or meets; for example,
´
Ì
¢½¿ µ ´ ¢¾ µ
´
Ï
¢¾ µ
Ø
´
Ì
Ï
µ¢´½¿ ¾
¾ µ
Ø
´
ÌÏ
µ¢
ÌÏ
¢
.

We define the support of a closed itemset
or a concep-
t
¢
as the cardinality of the closed tidset
Ø
´ µ,
i.e,
´ µ
Ø
´ µ.
A closed itemset or a concept is
frequent if its support is at least minsup. Figure 6 shows all the
frequent concepts with minsup = 50% (i.e., with tidset cardi-
nality at least 3). All frequent itemsets can be determined by
the join operation on the frequent item concepts. For example,
since join of item concepts
and Ì,
´ µ ´Ìµ,
doesn't




37

C
(C x 123456)
(ACTW x 135)
1, 3



A
(ACW x 1345)




W
(CW x 12345)
5
(ACDTW x 5)




4
(ACDW x 45)



2
(CDW x 245)
6
(CDT x 56)




D
(CD x 2456)
T
(CT x 1356)




Figure 5: Galois Lattice of Concepts
C
(C x 123456)
(ACTW x 135)




(ACW x 1345)




W
(CW x 12345)
(CDW x 245)




D
(CD x 2456)
T
(CT x 1356)
21,3



A




Figure 6: Frequent Concepts

exist,
Ì is not frequent. On the other hand,
´ µ ´Ìµ
ÌÏ
¢½¿
, thus Ì is frequent. Furthermore, the support
of Ì is given by the cardinality of the resulting concept's tid-
set, i.e.,
´
Ì
µ
Ø
´
Ì
µ ½¿ ¿.

LEMMA 1. An itemset's ( ) support is equal to the sup-
port of its closure, i.e.,
´ µ ´
Ø
´ µµ.

This theorem (independently reported in [13]) states that al-
l frequent itemsets are uniquely determined by the frequent
closed itemsets (or frequent concepts). Furthermore, the set of
frequent closed itemsets is bounded above by the set of fre-
quent itemsets, and is typically much smaller, especially for
dense datasets. For very sparse datasets, in the worst case,
the two sets may be equal. To illustrate the benefits of closed
itemset mining, contrast Figure 3, showing the set of all fre-
quent itemsets, with Figure 6, showing the set of all closed
frequent itemsets (or concepts). We see that while there are
only 7 closed frequent itemsets, in contrast there are 19 fre-
quent itemsets. This example clearly illustrates the benefits of
mining the closed frequent itemsets.
2




4. RULE GENERATION
Recall that an association rule is of the form
½
Ô
 
¾
,
where
½
¾
Á.
Its support equals Ø
´
½
¾
µ,
and its
confidence is given as Ô È
´
¾ ½
µ
Ø
´
½
¾
µ
Ø
´
½
µ.
We are interested in finding all high support and high confi-
dence rules. It is widely recognized that the set of such associ-
ation rules can rapidly grow to be unwieldy. In this section we
will show how the closed frequent itemsets help us form a gen-
erating set of rules, from which all other association rules can
be inferred. Thus, only a small and easily understandable set
of rules can be presented to the user, who can later selectively
derive other rules of interest.

Before we proceed, we need to formally define what we mean
by a redundant rule. Let Ê denote the rule
½
Ô
 
¾
. We
say that a rule Ê½ is more general than a rule Ê¾, denoted

¾One
possible objection that can be raised to the closed itemset framework is
that a small change in the data can change the number of closed itemsets. How-
ever, the frequency requirement makes the framework robust to small changes,
i.e., while the set of closed itemset can still change, the set of frequent closed
itemsets is resilient to change.
Ê½
Ê¾ provided that Ê¾ can be generated by adding addi-
tional items to either the antecedent or consequent of Ê½, i.e.,
if
½
½
¾
½
and
½
¾
¾
¾
. Now let
Ê
Ê½
¡¡¡
ÊÒ
be a set of rules, such that all their confidences are equal, i.e.,
Ô
Ô
. Then we say that a rule Ê is redundant if there
exists some rule Ê , such that Ê
Ê . The non-redundant
rules in the collection
Êare
those that are most general.

We now show how to eliminate the redundant association rules,
i.e., rules having the same support and confidence as some
more general rule. In the last section, we showed that the sup-
port of an itemset
equals the support of its closure
Ø
´ µ.
Thus it suffices to consider rules only among the frequent con-
cepts. In other words the rule
½
Ô
 
¾
is exactly the same
as the rule
Ø
´
½
µ
Ô
 
Ø
´
¾
µ.

Another observation that follows from the concept lattice is
that it is sufficient to consider rules among adjacent concepts,
since other rules can be inferred by transitivity, that is:

LEMMA 2. Transitivity: Let
½
¾
¿
be frequent closed
itemsets, with
½
¾
¿
. If
½
Ô
 
¾
and
¾
Õ
 
¿
, then
½
ÔÕ
 
¿
.

In the discussion below, we consider two cases of association
rules, those with 100% confidence, i.e., with Ô
½¼,
and
those with Ô
½¼.

4.1 Rules with Confidence
100%
LEMMA 3. An association rule
½
½ ¼
 
¾
has confi-
dence Ô
½¼if
and only if Ø
´
½
µ
Ø
´
¾
µ.

This theorem says that all 100% confidence rules are those
that are directed from a super-concept (
½
¢Ø´
½
µµto
a sub-
concept (
¾
¢Ø´
¾
µ),i.e.,
down-arcs, since it is in precisely
these cases that Ø
´
½
µ
Ø
´
¾
µ(or
½
¾
). Consider the
item concepts
´Ïµ
Ï
¢½¾¿
and
´ µ
¢
½¾¿
. The rule Ï
½ ¼
 
is a 100% confidence rule. Note
that if we take the itemset closure on both sides of the rule,
we obtain
Ï
½ ¼
 
, i.e., a rule between closed itemsets,
but since the antecedent and consequent are not disjoint in this
case, we prefer to write the rule as Ï
½ ¼
 
, although both
rules are exactly the same. Figure 7 shows some of the other
rules among adjacent concepts with 100% confidence.




38

A
CTW


A
W

WAC
A
CW




W
C
1

C
D
1
2


1




1




(C x 123456)
(CD x 2456)
T
(CT x 1356)
(ACTW x 135)
1, 3
(CDW x 245)




1



1
A
(ACW x 1345)




W
(CW x 12345)
1
1
1
1
1



1



1
CT



CD
TW
A

TW
AC




Figure 7: Rules with 100% Confidence

We notice that some down-arcs are labeled with more than one
rule. In such cases, all rules within a box are equivalent, and
we prefer the rule that is most general. For example, consider
the rules ÌÏ
½ ¼
 
ÌÏ
½ ¼
 
, and
ÌÏ
½ ¼
 
.
ÌÏ
½ ¼
 
is more general than the latter two rules. since
the latter two are obtained by adding one (or more) items to
either the antecedent or consequent of ÌÏ
½ ¼
 
. In fact,
we can say that the addition of
to either the antecedent or
the consequent has no effect on the support or confidence of
the rule. Thus, according to our definition, we say that the
other two rules redundant.

THEOREM 1. Let
Ê
Ê½
¡¡¡
ÊÒ be a set of rules
with 100% confidence (Ô
½¼
), such that Á½
Ø
´
½
¾
µ,
and Á¾
Ø
´
¾
µfor
all rules Ê . Let ÊÁ denote the
100% confidence rule Á½
½ ¼
 
Á¾. Then all the rules Ê
ÊÁ
are more specific than ÊÁ, and thus are redundant.

Let's apply this theorem to the three rules we considered above.
For the first rule
Ø
´ÌÏ µ
Ø
´
ÌÏ
µ
ÌÏ.
Similarly for the other two rules we see that
Ø
´ÌÏ
µ
Ø
´
ÌÏ
µ
ÌÏ,and
Ø
´
ÌÏ
µ
Ø
´
ÌÏ
µ
ÌÏ. Thus for these three rules we get the closed itemset
Á½
ÌÏ. By the same process we obtain Á¾
Ï.
All three rules correspond to the arc between the tid concept

Ø
´½ ¿µand
the item concept
´ µ.
Finally ÌÏ
½ ¼
 
is
the most general rule, and so the other two are redundant.

A set of such general rules constitutes a generating set, i.e., a
rule set, from which all other 100% confidence rules can in-
ferred. Note that in this paper we do not address the question
of eliminating self-redundancy within this generating set, i.e.,
there may still exist rules in the generating set that can be de-
rived from other rules in the set. In other words we do not
claim anything about the minimality of the generating set; that
is the topic of a forthcoming paper. See [7, 11, 16] for more
information on generating a base set (or minimal generating
set) of rules.

Figure 7 shows the generating set in bold arcs, which includes
the 5 most general rules ÌÏ
½ ¼
 
½ ¼
 
Ï Ï
½ ¼
 
Ì
½ ¼
 
½ ¼
 
(the down-arcs that have been left out
produce rules that cannot be written with disjoint anteceden-
t and consequent. For example, between
Ø
´¾µ
and
´ µ,
the most general rule is
Ï
½ ¼
 
. Since the antecedent
and consequent are not disjoint, as required by definition, we
discard such rules). All other 100% confidence rules can be
derived from this generating set by application of simple infer-

ence rules. For example, we can obtain the rule
½ ¼
 
by

transitivity from the two rules
½ ¼
 
Ï and Ï
½ ¼
 
. The

rule
Ï
½ ¼
 
can be obtained by augmentation of the two
rules Ï
½ ¼
 
and
½ ¼
 
, etc. One can easily verify that
all the 18 100% confidence rules produced by using frequent
itemsets, as shown in Figure 2, can be generated from this set
of 5 rules, produced using the closed frequent itemsets!


4.2 Rules with Confidence
100%
We now turn to the problem of finding a generating set for
association rules with confidence less than 100%. As before,
we need to consider only the rules between adjacent concepts.
But this time the rules correspond to the up-arcs, instead of
the down-arcs for the 100% confidence rules, i.e., the rules go
from sub-concepts to super-concepts.

Consider Figure 8. The edge between item concepts
´ µ
and
´Ïµcorresponds
to
¼ ¿
 
Ï. Rules between non-
adjacent concepts can be derived by transitivity. For example,
for
Ô
 
we can obtain the value of Ô using the rules
Õ
 
Ï and Ï
Ö
 
. We have Ô ÕÖ
¡
¾ ¿ ¼
.

THEOREM 2. Let
Ê
Ê½
¡¡¡
ÊÒ be a set of rules




39

4/5 = 0.8




4/6
=
0.67
3/4 = 0.75




WC5/6
W
A

A
CW
A
T




ACW
T
AC
TW
A
CT

A
TW
CTWA

AW
T
AW
CT

AC
T




4/5
3/4
A




C
(123456 x C)
2
(245 x CDW)
(135 x ACTW)
1, 3




W
(12345 x CW)
(1345 x ACW)
(1356 x CT)
T
D
(2456 x CD)
3/4
=
0.75




4/6
=
0.67

5/6
=
0.83
3/5
=
0.6
3/4
=
0.75




W
AC




Figure 8: Rules with Confidence
½¼¼±
with confidence Ô
½¼,
such that Á½
Ø
´
½
µ,
and Á¾

Ø
´
½
¾
µfor
all rules Ê . Let ÊÁ denote the rule Á½
Ô
 
Á¾. Then all the rules Ê
ÊÁ are more specific than ÊÁ, and
thus are redundant.

This theorem differs from that of the 100% confidence rules to
account for the up-arcs. Consider the rules produced by the up-
arc between item concepts
´Ïµand ´ µ.
We find that for
all three rules, Á½
Ø
´Ïµ
Ø
´
Ï
µ
Ï, and Á¾
Ø
´Ï µ
Ø
´Ï
µ
Ø
´
Ï
µ
Ï. The
support of the rule is given by Ø
´Á½
Á¾
µ
Ø
´
Ï
µ
,
and the confidence given as Ø
´Á½
Á¾
µ
Ø
´Á½µ
¼
.
Finally, since Ï
¼
 
is the most general rule, the other two
are redundant. Similarly for the up-arc between
´ µ
and

Ø
´½ ¿µ,
we get the general rule
¼
 
Ì. The other 8 rules
in the box are redundant!

The set of all such general rules forms a generating set of rules
from which other rules can be inferred. The two bold arrows
in Figure 8 constitute a generating set for all rules with
¼
Ô
½¼.
Due to the transitivity property, we only have to
consider arcs with confidence at least minconf =
¼
. No other
rules can be confident at this level.

By combining the generating set for rules with Ô
½¼,
shown
in Figure 7 and the generating set for rules with
½¼
Ô
¼
, shown in Figure 8, we obtain a generating set for al-
l association rules with minsup = 50%, and minconf = 80%:
ÌÏ
½ ¼
 
½ ¼
 
Ï Ï
½ ¼
 
Ì
½ ¼
 
½ ¼
 
Ï
¼
 
¼ ¿
 
Ï .

It can be easily verified that all the association rules shown
in Figure 2, for our example database from Figure 1, can be
derived from this set. Using the closed itemset approach we
produce 7 rules versus the 22 rules produced in traditional as-
sociation mining. To see the contrast further, consider the set
of all possible association rules we can mine. With minsup =
50%, the least value of confidence can be 50% (since the max-
imum support of an itemset can be 100%, but any frequent
subset must have at least 50% support; the least confidence
value is thus 50/100 = 0.5). There are 60 possible association
rules versus only 13 in the generating set (5 rules with Ô
½¼
in Figure 7, and 8 rules with Ô
½¼in
Figure 8)


4.3 Complexity of Rule Generation: Tra-
ditional vs. New Framework
The complexity of rule generation in the traditional framework
is Ç
´ ¡¾
Ð
µ,
exponential in the length Ð of the longest frequent
itemset ( is the total number of frequent itemsets). On the
other hand using the closed itemset framework, the number of
non-redundant rules is linear in the number of closed itemsets.
To see how much savings are possible using closed frequen-
t itemsets, lets consider the case where the longest frequent
itemset has length Ð; with all
¾
Ð
subsets also being frequent.

In the traditional association rule framework, we would have
to consider for each frequent itemset all its subsets as rule an-
tecedents. The total number of rules generated in this approach
is given as
ÈÐ
¼
 Ð¡
¡¾
Ð
 
ÈÐ
¼
 Ð¡
¡¾
Ð
¾
Ð
ÈÐ
¼
 Ð¡
¾
Ð
¡¾
Ð
¼´¾¾
Ð
µ.

On the other hand the number of non-redundant rules produced
using closed itemsets is given as follows. Let's consider two
extreme cases: In the best case, there is only one closed item-
set, i.e., all
¾
Ð
subsets have the same support as the longest
frequent itemset. Thus all rules between itemsets must have
100% confidence. The closed itemset approach doesn't pro-
duce any rule; it just lists the closed itemset with its frequency,
with the implicit assumption that all possible rules from this
itemset have 100% confidence. This corresponds to a reduc-
tion in the number of rules by a factor of Ç
´¾¾
Ð
µ.

In the worst case, all
¾
Ð
frequent itemsets are also closed. In
this case there can be no 100% confidence rules and all (




40

100% confidence) rules point upwards, i.e., from subsets to
their immediate supersets. For each subset of length we have
rules from each of its
 ½length
subsets to that set. The
total number of rules generated is thus
ÈÐ
¼
 Ð¡
¡´Ð  µ
ÈÐ
¼
 Ð¡
¡
Ð
Ç
´Ð ¡¾
Ð
µ.
Thus we get a reduction in the
number of rules by of a factor of Ç
´¾
Ð
Ð
µ,
i.e., asymptotically
exponential in the length of the longest frequent itemset.

5. EXPERIMENTAL EVALUATION
All experiments described below were performed on a 400MHz
Pentium PC with 256MB of memory, running RedHat Linux
6.0. Algorithms were coded in C++. Table 1 shows the char-
acteristics of the real and synthetic datasets used in our eval-
uation. The real datasets were obtained from IBM Almaden
(www.almaden.ibm.com/cs/quest/demos.html). All datasets ex-
cept the PUMS (pumsb and pumsb*) sets, are taken from the
UC Irvine Machine Learning Database Repository. The PUM-
S datasets contain census data. pumsb* is the same as pums-
b without items with 80% or more support. The mushroom
database contains characteristics of various species of mush-
rooms. Finally the connect and chess datasets are derived
from their respective game steps. Typically, these real datasets
are very dense, i.e., they produce many long frequent itemsets
even for very high values of support.

Database
# Items
Record Length
# Records
chess
76
37
3,196
connect
130
43
67,557
mushroom
120
23
8,124
pumsb*
7117
50
49,046
pumsb
7117
74
49,046
T20I12D100K
1000
20
100,000
T40I8D100K
1000
40
100,000
T10I4D100K
1000
10
100,000
T20I4D100K
1000
20
100,000

Table 1: Database Characteristics
We also chose a few synthetic datasets (also available from IB-
M Almaden), which have been used as benchmarks for testing
previous association mining algorithms. These datasets mimic
the transactions in a retailing environment. Usually the syn-
thetic datasets are sparse when compared to the real sets. We
used two dense and two sparse (the last two rows in Table 1)
synthetic datasets for our study.

5.1 Traditional vs. Closed Framework
Consider Table 2 and 3, which compare the traditional rule
generation framework with the closed itemset approach pro-
posed in this paper. The tables shows the experimental results
along a number of dimensions: 1) total number of frequent
itemsets vs. closed frequent itemsets, 2) total number of rules
in the traditional vs. new approach, and 3) total time taken
for mining all frequent itemsets (using Apriori) and the closed
frequent itemsets (using CHARM).

Table 2 shows that the number of closed frequent itemsets can
be much smaller than the set of all frequent itemsets. For the
support values we look at here, we got reductions (shown in
the Ratio column) in the cardinality upto a factor of 45. For
lower support values the gap widens rapidly [19]. It is note-
worthy, that CHARM finds these closed sets in a fraction of
the time it takes Apriori to mine all frequent itemsets as shown
in Table 2. The reduction in running time ranges upto a fac-
tor of 145 (again the gap widens with lower support). For the
sparse sets, and for high support values, the closed and all fre-
quent set coincide, but CHARM still runs faster than Apriori.

Table 3 shows that the reduction in the number of rules (with
all possible consequent lengths) generated is drastic, ranging
from a factor of 2 to more than 3000 times! Incidentally, these
ratios are roughly in agreement with the complexity formula
we presented in Section 4.3. For example, consider the mush-
room dataset. At 40% support, the longest frequent itemset
has length 7. The complexity figure predicts a reduction in the
number of rules by a factor of
¾
½¾
½
, which
is close to the ratio of 15 we got empirically. Similarly for
20% support, we expect a reduction of
¾½ ½ ¾½
, and
empirically it is 3343.

We also computed how many single consequent rules are gen-
erated by the traditional approach. We then compared these
with the non-redundant rule set from our approach (with pos-
sibly multiple consequents). The table also shows that even if
we restrict the traditional rule generation to a single item con-
sequent, the reduction with the closed itemset approach is still
substantial, with upto a factor of 66 reduction (once again, the
reduction is more for lower supports). It is worth noting that,
even though for sparse synthetic sets the closed frequent item-
sets is not much smaller than the set of all frequent itemsets,
we still get upto a factor of 5 reduction in the number of rules
generated.

The results above present all possible rules that are obtained by
setting minconf equal to the minsup. Figure 9 shows the effect
of minconf on the number of rules generated. It shows that
most of the rules have very high confidence; as the knee of the
curves show, the vast majority of the rules have confidences
between 95 and 100 percent! This is a particularly distressing
result for the traditional rule generation framework. The new
approach produces a rule set that can be orders of magnitude
smaller. In general it is possible to mine closed sets using
CHARM for low values of support, where it is infeasible to
find all frequent itemsets. Thus, even for dense datasets we
can generate rules, which may not be possible in the traditional
approach.


6. CONCLUSIONS
This paper has demonstrated in a formal way, supported with
experiments on several datasets, the well known fact that the
traditional association rule framework produces too many rules,
most of which are redundant. We proposed a new framework
based on closed itemsets that can drastically reduce the rule
set, and that can be presented to the user in a succinct manner.

This paper opens a lot of interesting directions for future work.
For example we plan to use the concept lattice for interactive
visualization and exploration of a large set of mined associa-
tions. Keep in mind that the frequent concept lattice is a very
concise representation of all the frequent itemsets and the rules
that can be generated from them. Instead of generating all pos-
sible rules, we plan to generate the rules on-demand, based on
the user's interests. Finally, there is the issue of developing a




41

Number of Itemsets
Running Time
Database
Sup
Len
#Freq
#Closed
Ratio
Apriori
CHARM
Ratio
chess
80%
10
8227
5083
1.6
18.54
1.92
9.7
chess
70%
13
48969
23991
2.0
213.03
8.17
26.1
connect
97%
6
487
284
1.7
19.7
4.15
4.7
connect
90%
12
27127
3486
7.8
2084.3
43.8
47.6
mushroom
40%
7
565
140
4.0
1.56
0.28
5.6
mushroom
20%
15
53583
1197
44.7
167.5
1.2
144.4
pumsb*
60%
7
167
68
2.5
11.4
1.0
11.1
pumsb*
40%
13
27354
2610
10.5
847.9
17.1
49.6
pumsb
95%
5
172
110
1.6
19.7
1.7
11.7
pumsb
85%
10
20533
8513
2.4
1379.8
76.1
18.1
T20I12D100K
0.5%
9
2890
2067
1.4
6.3
5.1
1.2
T40I8D100K
1.5%
13
12088
4218
2.9
41.6
15.8
2.6
T10I4D100K
0.5%
5
1073
1073
1
2.0
1.1
1.8
T10I4D100K
0.1%
10
27532
26806
1.03
32.9
8.3
4.0
T20I4D100K
1.0%
6
1327
1327
1
6.7
4.8
2.6
T20I4D100K
0.25%
10
30635
30470
1.01
32.8
10.7
3.1

Table 2: Number of Itemsets and Running Time (Sup=minsup, Len=longest frequent itemset)

All Possible Rules
Rules with one Consequent
Database
Sup
Len
#Traditional
#Closed
Ratio
#Traditional
Ratio
chess
80%
10
552564
27711
20
44637
2
chess
70%
13
8171198
152074
54
318248
2
connect
97%
6
8092
1116
7
1846
1.7
connect
90%
12
3640704
18848
193
170067
9
mushroom
40%
7
7020
475
15
1906
4.0
mushroom
20%
15
19191656
5741
3343
380999
66
pumsb*
60%
7
2358
192
12
556
3
pumsb*
40%
13
5659536
13479
420
179638
13
pumsb
95%
5
1170
267
4
473
2
pumsb
85%
10
1408950
44483
32
113089
3
T20I12D100K
0.5%
9
40356
2642
15
6681
3
T40I8D100K
1.5%
13
1609678
11379
142
63622
6
T10I4D100K
0.5%
5
2216
1231
1.8
1231
1.0
T10I4D100K
0.1%
10
431838
86902
5.0
90350
1.04
T20I4D100K
1.0%
6
2736
1738
1.6
1738
1.0
T20I4D100K
0.25%
10
391512
89963
4.4
90911
1.01

Table 3: Number of Rules (all vs. consequent of length 1) (Sup=minsup, Len=longest itemset)

theory for extracting a base, or a minimal generating set, for
all the rules.


7. REFERENCES
[1] R. Agrawal, H. Mannila, R. Srikant, H. Toivonen, and A. I.
Verkamo. Fast discovery of association rules. In U. Fayyad and
et al, editors, Advances in Knowledge Discovery and Data
Mining, pages 307­328. AAAI Press, Menlo Park, CA, 1996.

[2] R. J. Bayardo. Efficiently mining long patterns from databases.
In ACM SIGMOD Conf. Management of Data, June 1998.

[3] R. J. Bayardo and R. Agrawal. Mining the most interesting
rules. In 5th ACM SIGKDD Intl. Conf. on Knowledge Discovery
and Data Mining, Aug. 1999.

[4] S. Brin, R. Motwani, J. Ullman, and S. Tsur. Dynamic itemset
counting and implication rules for market basket data. In ACM
SIGMOD Conf. Management of Data, May 1997.

[5] B. Ganter and R. Wille. Formal Concept Analysis:
Mathematical Foundations. Springer-Verlag, 1999.

[6] R. Godin and R. Missaoui. An incremental concept formation
approach for learning from databases. Theoretical Computer
Science, 113:387­419, 1994.

[7] J. L. Guigues and V. Duquenne. Familles minimales
d'implications informatives resultant d'un tableau de donnees
binaires. Math. Sci. hum., 24(95):5­18, 1986.

[8] M. Klemettinen, H. Mannila, P. Ronkainen, H. Toivonen, and
A. I. Verkamo. Finding interesting rules from large sets of
discovered association rules. In 3rd Intl. Conf. Information and
Knowledge Management, pages 401­407, Nov. 1994.

[9] D.-I. Lin and Z. M. Kedem. Pincer-search: A new algorithm for
discovering the maximum frequent set. In 6th Intl. Conf.
Extending Database Technology, Mar. 1998.

[10] B. Liu, W. Hsu, and Y. Ma. Pruning and summarizing the
discovered associations. In 5th ACM SIGKDD Intl. Conf. on
Knowledge Discovery and Data Mining, Aug. 1999.

[11] M. Luxenburger. Implications partielles dans un contexte. Math.
Inf. Sci. hum., 29(113):35­55, 1991.

[12] R. T. Ng, L. Lakshmanan, J. Han, and A. Pang. Exploratory
mining and pruning optimizations of constrained association
rules. In ACM SIGMOD Intl. Conf. Management of Data, June
1998.




42

1000
10000
100000
1e+06
1e+07




707580859095100
Number
of
Rules




Minimum Confidence (%)
chess




Traditional-70%
Closed-70%
Traditional-80%
Closed-80%
100
1000
10000
100000
1e+06
1e+07




889092949698100
Number
of
Rules




Minimum Confidence (%)
connect




Traditional-90%
Closed-90%
Traditional-97%
Closed-97%
100
1000
10000
100000
1e+06
1e+07
1e+08




2030405060708090100
Number
of
Rules




Minimum Confidence (%)
mushroom




Traditional-20%
Closed-20%
Traditional-40%
Closed-40%




1
10
100
1000
10000
100000
1e+06
1e+07




8486889092949698100
Number
of
Rules




Minimum Confidence (%)
pumsb




Traditional-85%
Closed-85%
Traditional-95%
Closed-95%
10
100
1000
10000
100000
1e+06
1e+07




405060708090100
Number
of
Rules




Minimum Confidence (%)
pumsb_star




Traditional-40%
Closed-40%
Traditional-60%
Closed-60%




1
10
100
1000
10000
100000
1e+06
1e+07




0102030405060708090100
Number
of
Rules




Minimum Confidence (%)
Synthetic




Traditional-1.5%-T40I8D100K
Closed-1.5%-T40I8D100K
Traditional-0.5%-T20I12D100K
Closed-0.5%-T20I12D100K




1
10
100
1000
10000
100000
1e+06




0102030405060708090100
Number
of
Rules




Minimum Confidence (%)
T10I4D100K




Traditional-0.5%
Closed-0.5%
Traditional-0.1%
Closed-0.1%
1
10
100
1000
10000
100000
1e+06




0102030405060708090100
Number
of
Rules




Minimum Confidence (%)
T20I4D100K




Traditional-1.0%
Closed-1.0%
Traditional-0.25%
Closed-0.25%




Figure 9: Number of Rules: Traditional vs. Closed Itemset Framework

[13] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Discovering
frequent closed itemsets for association rules. In 7th Intl. Conf.
on Database Theory, Jan. 1999.

[14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal. Efficient
mining of association rules using closed itemset lattices.
Information Systems, 24(1):25­46, 1999.

[15] A. Savasere, E. Omiecinski, and S. Navathe. An efficient
algorithm for mining association rules in large databases. In
21st VLDB Conf., 1995.

[16] R. Taouil, Y. Bastide, N. Pasquier, G. Stumme, and L. Lakhal.
Mining bases for association rules based on formal concept
analysis. In 16th IEEE Intl. Conf. on Data Engineering, Feb.
2000.

[17] H. Toivonen, M. Klemettinen, P. Ronkainen, K. H¨at¨onen, and
H. Mannila. Pruning and grouping discovered association rules.
In MLnet Wkshp. on Statistics, Machine Learning, and
Discovery in Databases, Apr. 1995.

[18] M. J. Zaki. Generating non-redundant association rules.
Technical Report 99-12, Computer Science Dept., Rensselaer
Polytechnic Institute, December 1999.

[19] M. J. Zaki and C.-J. Hsiao. CHARM: An efficient algorithm for
closed association rule mining. Technical Report 99-10,
Computer Science Dept., Rensselaer Polytechnic Institute,
October 1999.

[20] M. J. Zaki and M. Ogihara. Theoretical foundations of
association rules. In 3rd ACM SIGMOD Workshop on Research
Issues in Data Mining and Knowledge Discovery, June 1998.

[21] M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li. New
algorithms for fast discovery of association rules. In 3rd Intl.
Conf. on Knowledge Discovery and Data Mining, Aug. 1997.




43

