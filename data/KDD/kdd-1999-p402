Monitoring
a Newsfeed
for Hot Topics
Mark Shewhart
and Mark Wasson
LEXIS-NEXIS, a Division of Reed Elsevier plc
9595 Springboro Pike
Miamisburg, Ohio 45342
(937) 865-6800
{mark.shewhart.3,mark.wasson}@lexis-nexis.com


ABSTRACT
We describe a processthat monitors newsfeedsfor topics that
receive unexpectedly high amountsof coverageon a given day.
An experiment using companies as topics demonstratesthis
processand shows that a high level of interestingness can be
achieved.This work may supportanews alert service.
KEYWORDS
Time-seriesanalysis,text data,controlled vocabularyindexing.

1. INTRODUCTION
The LEXIS-NEXIS archives contain a great deal of information,
most of which is represented as text. Customers generally
retrieve information from the archivesusing Boolean queriesand
other text-based retrieval tools. We add several
thousand
documents to the archives daily. As part of our document
preparationprocesswe reformatandannotatedocumentsin order
to support improved information retrieval. We are beginning to
explore how data mining techniques may be used to exploit
current annotations, and how such techniques may guide future
changesto our documentpreparationprocess.
Some systems in our document preparation process amrotate
news documentswith controlled vocabulary terms. A controlled
vocabulary term is a consistently specified topic indicator that
users can incorporate into their queries in order to find and
retrieve documentsabout the corresponding topic. Our set of
controlled vocabulary terms represents 60,000 topics. General
news subjects and individual companies,people, organizations
and places are among the topics in this set. We have added
controlled vocabulary terms acrossa large volume of archived
news documents, and continue to add them to incoming
documentsdaily. Historical indexing results are now available
for millions of news documents.
Onecandidateuseof this datais to supporta daily news alerting
servicethat notifies customerswhen topics of interest are in the
news. We can of coursenotify customerswhen one of our topics
simply appears in the news. The assignment of a controlled
vocabularyterm to just onedocumentmeetsthat threshold. More


h?&SiOn
to make digital or hard copies ol`all or part ot`this work for
Personal or classroom use is granted without fee provided that copies
are not made or distributed for profit or commercial advantage and that
copies bear this notice and the full citation on the first page. To copy
other\+&
to republish, to post on servers or to redistribute to lists.
requires prior specific permission and/or a fee.
KDD-99 San Diego CA USA
Copyright ACM 1999 I-58113-l43-7/99/08...$5.00
interesting is the possibility of alerting customerswhen a topic
receivesan unusually high amountof coverage.Presumablysuch
coverage indicates that something particularly important or
interesting aboutthe topic occurredthat day.

2. RELATED
WORK
The FACT systemand related work apply data mining to texts
annotatedwith controlled vocabulary terms (keywords in their
work) [2, 1, 31.By combining keywords with information from a
keyword hierarchy and other world knowledge, it is possible to
identify and analyzetrends (e.g., a companyshit& its focus over
time), to identify and explain relationships between companies,
placesor other entities, and to infer information about topics in
the hierarchy that is not explicitly stated.
PatentMiner performs trend analysis on frequency histories of
phrasesextracted from text [7]. Phrasehistories can be queried
to find hot topics, emergingtopics, fading topics and reemerging
topics. Working with patents data, the authors partitioned
historical information into years,although they note that smaller
partitions maybemoreappropriatefor othertypes of data.
We also areperforming trend analysis in order to find hot topics,
exceptthat we areusing controlled vocabulary terms rather than
phrasesextracted from text. Becauseof the nature of news, we
partition time into days. Smaller units could be used in work to
identify breakingnewstopics within a day, but that is beyondthe
scopeof the work describedhere.

3. EXPERIMENT
The purposeof this experiment is to determine whether we can
monitor newsfeedsin order to identify when any topic from a
predefmedlist of topics is a hot topic. A hot topic is one that
receivesan unusually high amount of coveragein the news on a
given day becauseof the importance of the event(s) involving
that topic. In this experiment, we focus on the problem of
identifying hot companiesand company pairs. A hot company
pair occurswhen two companiesappeartogether in an unusually
high number of documentsbecauseof something important or
significant that involves both companies.

4. PREPARING
THE DATA
Proper data preparation is a key task. First, our newsfeed
processesdocumentsfrom thousandsof sources.Not all sources
are equally useful when monitoring news for hot topics, so we
must select an appropriate subset that best helps identify hot
topics. Second,we are using text data as input to our process.
Third, we need a system that identifies relevant documents.
Finally, we needto captureand analyzeinformation abouttopic-
specific relevant documentsovertime.




402

4.1 Selecting Appropriate
Sources
When selecting publications to monitor, we must consider their
value assourcesof hot topics. Wire servicesand newspapersare
the strongestcandidate sourcesbecausethe publication date is
usually close to the event date. Magazines, because of their
publication cycle, may contribute to an ongoing discussion of a
hot topic, but their role more often is to provide analysis rather
than breakingnews.In thosecaseswhere a magazinedoesbreak
a story, ongoing coverage in wire services and newspapers
appears immediately, sometimes before the magazine is
published. A process that monitors news for hot topics thus
shouldtargetwire serviceandnewspapersources.

4.2 Using Text Input
Becausewe are using newsfeeds,we are attempting to identify
hot topics in text data. Problems associatedwith applying data
mining techniques to text have been described elsewhere [9].
Datamining processesgenerally expectstructuredinput, whereas
text is unstructured, so data preparation for text data mining
requires that we impose structure on the text. This could range
from annotating texts with attributes such as controlled
vocabulary terms [l] to performing deep linguistic analysis [S].
For our purposes,this task is especially costly becauseof the
volume of data in the LEXIS-NEXIS archives (over one billion
documentsfrom morethan 20,000 sources).We add asmany as
100,000documentsdaily to our NEWS library. To processand
annotatea subsetof our NEWS library retrospectively can take
months.Any systemwe introduce to annotatetexts in support of
data mining must operate within our document preparation
environment.Systemsmustbe fast,accurateandfully automated.

4.3 Selecting Important
Documents
Before we can determinewhether somecompanyis a hot topic
on a given day,we must first identify whether eachdocumentin
the targeted sourcesprovides substantial information about the
company. We rely on a proprietary system called NEXISE
Indexing to accomplish this. NEXIS@ Indexing is a controlled
vocabulary indexing systemthat we apply acrossmost English
language news sources in the LEXIS-NEXIS archives [8].
NEXlSB Indexing usesa knowledgebasethat containsmachine-
useable definitions for our 60,000 topics, including definitions
for 30,000companies.Eachcompanyis defined by a setof terms
that are applied to documents in a large-scale lookup. Term
frequency,weight andlocation areusedto determinewhether the
documentis aboutthe correspondingcompany,andto calculatea
relevancescore.Scoresare normalized on a O-99scale,where a
relevance score of 90 or more indicates that the document
contains a major reference to the correspondingtopic, that is,
when that documentis substantially aboutthat topic. A document
may also contain minor referencesto sometopics. If the scoreis
at least 50, a controlled vocabularyterm that representsthe topic
is added to a searchablefield in the document along with its
score.Online customerscan use the controlled vocabulary term
and relevance scores in their Boolean queries.
For this
experiment, only documentswith major referencesto companies
were used. Searches that use NEXISE Indexing-assigned
controlled vocabulary terms to retrieve documentsthat contain
majorreferencesaverageabout95%precision and 90%recall.
Using a systemthat distinguishes betweenmajor referencesand
other referencesautomatically is an important part of our data
preparation process for data mining. Counting the number of
documents in which a company is mentioned can be
accomplishedeasily through our existing Boolean searchengine
or other means,but such approachesdo not reliably distinguish
between major and minor references. For example, Microsoft
Corp. is frequently mentioned in the news. In some articles,
Microsoft is the primary focus. In other articles, Microsoft is
mentioned in passing, often to note that it is a partner with or
competitor of the companythat is the major focus of the article,
or to note Microsoft's trademarks.There can be an increasein
the number of documentsthat mention Microsoft becauseeither
Microsoft did something newsworthy or because some other
company did something newsworthy and simply mentioned
Microsoft in its pressrelease.Only in those caseswhere it was
Microsoft that did somethingnewsworthy should the companybe
a candidatehot topic.

4.4 Storing Indexing-based
Metadata
NEXISE Indexing adds controlled vocabulary terms and
corresponding relevance scores to searchable tields
in
documents.The controlled vocabularyterms and other document
attributes, including source and date information, are also
captured as document metadata in an indexing metadata
database.This databaseretains the metadata over time, and
provides ausagehistory for eachcontrolled vocabularyterm that
NEXlS@ Indexing assigns.

5. IDENTIFYING
"HOT TOPICS"
Our hot topics identification processis basedon manufacturing
quality control processes.Rather than inspecting batches of
widgets for defectives, we are inspecting batchesof documents
for relevance.In a news"process" a specific topic will tendto get
consistent levels of news coverage(similar to the defectrate in
manufacturing)until someimportant event(the assignablecause)
affectsthe process.Methodsto monitor for this exist [4,6].
Each day, we have a variable sample size: the number of
documentsprocessed.Most topics are rare, appearing less than
once a day. Many companiesin fact are not mentioned in the
news for weeksat a time, although somewell-known companies
canappearin the news severaltimes a day.Information from the
daily sample is compared to information from the historical
sample. A historical sample of 7-10 days is acceptable as
company-relatednews coveragerises andfalls quickly.
To determine whether a given topic is hot on a given day, its
ratio of indexed documentsto all documentsfor that day(ptoduy)
is comparedto an Upper Control Limit (UCL) based on its
historical ratio of indexed documentsto all documentsfor several
immediately precedingdays(whist):
d = # of documentsabouttopic today
n = # of documentsoverall today
D = # of documentsabouttopic overtime
N = # of documentsoverall overtime
ptoday = d I n
phist = D IN
lJCL=phist + 3 * sqrt@hist * (1 - phist) I N)




403

The UCL is equal to the historical ratio for the topic plus three
standard deviations of that ratio. The number of standard
deviations can be increased or decreasedto reduce or increase
the numberof hot topics identified.
If ptoduy for sometopic is greaterthan the UCL for that topic,
the topic is a candidatehot topic. Each candidatehot topic must
passtwo more tests. First, we verify that d is greater than or
equal to somedocument count threshold, typically at least 3-5
documents.Many topics arementionedin the news sorarely that
this threshold preventsthe presenceof only one or two relevant
documentsfrom being consideredhot. Second,we verify that the
d documentswere found in at least someminimum number of
sources,typically 2-3 different publications. This helps us avoid
falsepositive problemsthat canresult when duplicate documents
appear in a single source (a common occurrencein newswire
sourcenewsfeeds).A candidatehot topic is determined to be a
hot topic only if it alsopassesthesetwo additional tests.

6. EVALUATING
INTERESTINGNESS
We use an indexing system and comparisons to historical
information to suggestthat a news topic is hot. Whether a topic
truly is a hot topic, however, is in the eye of the customer.An
evaluation task was conducted to measure how well this
approachflaggedinteresting topics.
Lists of hot companiesand companypairs were generatedover
an eight-week period and turned over to an evaluation team of
five expert NEXIS@ searchers.For eachidentified hot company
or companypair, an evaluator searchedonline for articles that
mentionedthe companyor companieson the correspondingdate.
The evaluatorreadthe retrieved articles and determinedwhether
there was "important" news aboutthe companyor companypair.
The definition of "important" was left undefined, the evaluators
hadto determinefor themselveswhat was important news.
In this test, 1,137companiesand companypairs were identified
ashot topics. Of these,evaluatorsdeterminedthat 1,094(96.2%)
of the identified hot topics did in fact correspondto important
information in NEXISB that day. Another five (0.4%) were
judged as"maybe", and 38 (3.3%) werejudged asnot important.
Hot topic identification errors resulted primarily from mistakes
that the NEXIS@ Indexing system made or because some
evaluators did not regard as important some of the company-
relatedtopics that NEXISB Indexing specifically targets.

7. DISCUSSION
We have presented a process for identifying hot topics in a
newsfeed. This processrelies on a document preparation step
that determineswhich documentscontain important information
about targeted topics, and a monitoring step that determines
when a given topic receives an unusually high amount of
coveragein the news on a given day. Evaluation results suggest
that this processcansuccessfullysupporta newsalert service.
The results also suggestthat further experimentsin this areaare
warranted. For example, in addition to companieswe index for
people, organizations, places and news subjects. We should
verify that the approachworks on these other domains and on
combinationsof index termsfrom multiple domains. The FACT
system [3] and other related work made use of keyword
hierarchies and world knowledge. We have a term hierarchy and
world knowledge about our topics that includes corresponding
industry codes,SIC product codes,financial data and corporate
headquarterslocation information. We have not begun to exploit
suchinformation in our research. We also have relevance scores
available on our indexed documents.Our work to date has only
used indexing results with relevance scores of 90 or above.
Perhapsa lower threshold maybe acceptablefor determining hot
topics. We mayalso fmd that unusual increasesin the number of
passingreferencesto somecompanymay in fact indicate that the
correspondingindustry is a hot topic that day. We hope to use
further research in this area to suggest improvements to our
metadata storage and analysis process and to our controlled
vocabulary indexing system. These in turn may lead to more
sophisticated research into applying knowledge discovery
techniquesto the LEXIS-NEXIS archives.

8. ACKNOWLEDGMENTS
We want to thank colleaguesDavid Schmeer,Afsar Parhizgar,
Paul Zhang andJoeZhou for their supportand suggestions.

9.
111



PI



[31




141


[51




VI


171




PI


PI
REFERENCES
Dagan, I., Feldman, R., and Hirsh, H. Keyword-based
Browsing and Analysis of Large Document Sets. In
Proceedings, Ffth
Annual Symposium on Document
Analysis and Information Retrieval, Las Vegas,1996.
Feldman,R., andDagan,I. Knowledge Discovery in Textual
Databases (KDT). In Proceedings, First International
Conference on Knowledge Discovery and Data Mining,
Montreal, 1995.
Feldman,R., and Hirsh, H. Mining Associations in Text in
the Presenceof Background Knowledge. In Proceedings,
SecondInternational Conferenceon Knowledge Discovery
and Data Mining, Portland, OR, 1996.
Grant, E., and Leavenworth, R. Statistical Quality Control.
McGraw-Hill, New York, 1972.
Hahn, U., and Schnattinger,K. Deep Knowledge Discovery
from Natural Language Texts. In Proceedings, Third
International Conference on Knowledge Discovery and
Data Mining, Newport, CA, 1997.
Ishikawa, K. Guide to Quality Control. Asian Productivity
Organization, 2 ed., 1982.
Lent, B., Agrawal, R., and Srikant, R. Discovering Trends
in Text Databases. In Proceedings, Third International
Conference on Knowledge Discovery and Data Mining,
Newport, CA, 1997.
Schmeer,D., and Sidle, C. Automatic Topical Indexing at
LEXIS-NEXIS. In Proceedings of the 19th National Online
Meeting, New York, 1998.
Weiss,S., & Indurkhya, N. Predictive Data Mining. Morgan
Kautinann, SanFrancisco, 1998.




404

