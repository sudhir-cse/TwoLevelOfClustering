On Detecting Space-Time Clusters


Vijay S. Iyengar
IBM Research Division
Thomas J. Watson Research Center
P.O. Box 218, Yorktown Heights, NY 10598, USA

vsi@us.ibm.com



ABSTRACT
Detection of space-time clusters is an important function in
various domains (e.g., epidemiology and public health). The
pioneering work on the spatial scan statistic is often used
as the basis to detect and evaluate such clusters. State-of-
the-art systems based on this approach detect clusters with
restrictive shapes that cannot model growth and shifts in
location over time. We extend these methods significantly
by using the flexible square pyramid shape to model such ef-
fects. A heuristic search method is developed to detect the
most likely clusters using a randomized algorithm in combi-
nation with geometric shapes processing. The use of Monte
Carlo methods in the original scan statistic formulation is
continued in our work to address the multiple hypothesis
testing issues. Our method is applied to a real data set on
brain cancer occurrences over a 19 year period. The cluster
detected by our method shows both growth and movement
which could not have been modeled with the simpler cylin-
drical shapes used earlier. Our general framework can be
extended quite easily to handle other flexible shapes for the
space-time clusters.

Categories and Subject Descriptors: H.2.8 [Database
Management]: Database Applications - Data Mining

General Terms: Algorithms, Experimentation

Keywords: Clusters, space-time region, spatial scan statis-
tic, search, Monte Carlo


1. INTRODUCTION
Analyses of data to detect space-time clusters is relevant
to many domains. Details on what constitutes a space-time
cluster might vary from one domain to another. We will
use the epidemiology domain to motivate the models and
algorithms presented in this paper.
For example, health
officials often evaluate if an observed excess of disease cases
in a space-time region is a cluster that warrants a thorough
investigation. Such an evaluation would include analyzing
known factors (e.g., population demographics) to determine




Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD'04, August 22­25, 2004, Seattle, Washington, USA.
Copyright 2004 ACM 1-58113-888-1/04/0008 ...$5.00.
if they can explain the excessive cases. The evaluation must
also address the question whether the excessive cases could
have occurred by chance. Detection of a space-time cluster
of excessive cases that is not explained by known factors and
is very unlikely to occur by chance would trigger a thorough
investigation.
The scan statistic is a statistical method widely used to
detect and evaluate such clusters [4]. A comprehensive re-
view of methods to detect spatial clusters is given in [7, 4].
Two important categories in spatial methods are detection
of two dimensional spatial clusters and detection of three
dimensional space-time clusters. We will consider the more
general 3D space-time category in this paper.

1.1 The spatial scan statistic
The spatial scan statistic developed by Martin Kulldorff
[6, 8] is widely referenced and used by epidemiologists. This
powerful method for detecting a significant region with el-
evated disease rate has been developed using a Bernoulli
model and also using a Poisson model for the underlying
phenomenon [6]. For the Poisson model, events are allowed
to be generated by an inhomogeneous Poisson process. For
example, the expected number of disease events in a region
would be proportional to its population assuming no other
contributing factors. We will use the Poisson model in this
paper to illustrate our work and to apply it to a data set
from the epidemiology domain.
These models have been implemented in a system for de-
tecting space-time clusters (SaTScan) [9]. SaTScan detects
space-time clusters using cylindrical windows with a circular
geographic base and with the height of the cylinder corre-
sponding to some interval in time. Geographical locations
are specified discretely (e.g., centers of counties) to SaTScan.
Input data to SaTScan includes the number of cases and
population information at these discrete locations at vari-
ous times. SaTScan evaluates a set of cylindrical windows
by considering all those spatially centered at any point in
a user-specified grid and exhaustively varying the cylinder's
radius and time duration. The evaluation computes the like-
lihood ratio of the alternative hypothesis that there is an
elevated event rate within the cylindrical window and the
null hypothesis that the rate is the same inside and outside
the window. For the Poisson model, this likelihood function
[6] is proportional to

LR = (c/n)
c
([C - c]/[C - n])(C-
c)
I()
(1)

where C is the total number of cases over the entire space
and time, c is the number of cases within the window, and



587
Research Track Poster

n is the expected number of cases within the window un-
der the null hypothesis. The indicator function, I(), is 1
when the window has more cases than expected under the
null hypothesis and is 0 otherwise. The cylindrical window
with the largest value of the likelihood function is the re-
sulting cluster R . The multiple hypothesis testing problem
is overcome in SaTScan by generating synthetic datasets for
the entire space-time region in which the event counts are
independently generated conforming to the Poisson model
for each location and time. Each of these synthetic datasets
is analyzed to determine its most dominant cluster and its
likelihood function value. Using these Monte Carlo experi-
ments one can determine the likelihood that the cluster R
could have occurred by chance under the null hypothesis
(p-value).

1.2 Strengths and Limitations
A key strength of the spatial scan statistic is its prov-
able power in detecting a significant time-space cluster with
elevated counts for the phenomena being modeled [6]. How-
ever, the use of cylindrical windows in current implementa-
tions can limit the fit to the phenomena being modeled. Our
work was motivated by the need to consider space-time clus-
ters that can either grow or shrink over time and that can
also move over time.
Intuitively, we expect clusters with
these characteristics to be very relevant in the epidemiol-
ogy domain and to also extend the applicability of the scan
statistic to other domains. The challenge is allow this flex-
ibility in the scanned regions while keeping the computa-
tion tractable.
The magnitude of this challenge becomes
more apparent when we realize that even for simpler shapes
the computation can be prohibitive if the grid is too fine,
requiring clever algorithms to prune the regions examined
[11]. Our use of the Monte Carlo based approach to deal
with the multiple hypothesis testing problem as advocated
in [6, 7] adds significantly to the computational challenge.
Our choice of a flexible shape for the clusters and our ap-
proach to containing the computational needs are outlined
in Section 2. Section 3 details our new algorithm to de-
tect these flexible clusters. Results of applying our method
to a dataset from the epidemiological domain are given in
Section 4.
The clustering problem solved by the spatial scan statistic
is quite different from the formulation addressed by methods
like CLIQUE [1]. A key difference pointed out in [11] is that
hierarchical methods require the measure defining the clus-
ter to be monotonic so that bottom-up approaches can be
applied. However, the spatial scan statistic is not a mono-
tonic measure. The reader is referred to [11] for a detailed
discussion of this and other differences in the formulations.

2. OUR APPROACH
Our choice for the cluster shape is a pyramid with square
cross sections representing the included geographical area
at each time in an interval. Figure 2 illustrates this cluster
shape using 2D and 3D views. Our pyramid cluster can be
truncated (need not include the apex) and is allowed to ei-
ther grow or shrink from the start to the end of the time
interval. The 3D view in Figure 2 shows a cluster growing
with time. The axis of the pyramid need not be orthogonal
to the two spatial axes allowing the cluster to model move-
ment of the phenomena. This is clearly illustrated by the 2D
view in Figure 2 where the squares represent the geographi-
cal extent at discrete times in the cluster time interval. The
example in Figure 2 clearly illustrates the flexibility of the
cluster shape to model various aspects of real life phenom-
ena.
Typically, input data includes occurrence counts and other
information (e.g., disease counts and population) at discrete
locations at various times. The entire data can be repre-
sented using a set of points P in three dimensional space
where each point corresponds to a discrete location at a
particular time.
We use a subset S of these points P to
represent a candidate cluster, provided that S conforms to
a square pyramid shape. We will denote such a subset S as
legal.


Definition D1 A subset S from a set of points P is legal,
iff there exists a square pyramid that contains all the
points in S and none from P - S.


The total number of legal candidate subsets can be very
large for most datasets. This rules out any exhaustive ap-
proach similar to the one used for cylindrical clusters. In-
stead we use a heuristic search with randomized algorithms
over the space of legal candidate clusters to find the cluster
with the largest likelihood ratio (Equation 1). Our heuristic
search cannot guarantee that we will find the cluster with
the largest likelihood ratio. The impact of using a heuris-
tic approach is discussed in Section 5.
However, we will
demonstrate using a real-life dataset that our approach can
generate useful results and shed greater insights into the
modeled phenomena when compared to clusters restricted
to simple shapes (e.g., cylinder). A similar approach using
simulated annealing has been reported recently for two di-
mensional spatial clusters [2]. As expected, the extension to
three dimensional space-time clusters raises significant new
challenges which are addressed in our work.


3. ALGORITHM DETAILS

3.1 Randomized Search Method
The heuristic search algorithm generates a large number
of legal candidate clusters in a biased random fashion. The
cluster with the largest likelihood function amongst the gen-
erated set of candidates is chosen as the resulting cluster so-
lution. Our randomized search (Figure 1) is fashioned after
earlier works on genetic algorithms [5] and approaches like
simulated annealing [12].
The search algorithm is called for each input data of oc-
currences and expectations for the 3D points representing
locations in time. This implies that the search algorithm
will be called once for each experiment in the Monte Carlo
based hypothesis testing.
The iterative search algorithm
uses and adds to a population of candidate solutions. The
maximum size of this population is one of the parameters
that can be set by the user. Intuitively, a larger population
allows a wider exploration of the solution space reducing
the likelihood of getting stuck in a locally optimal solution
prematurely.
Typical values used in our experiments are
reported in Section 4. Step 1 in the search algorithm in Fig-
ure 1 is to initialize the population of candidate solutions. In
our experiments, we initialized the population to the clusters
containing single points with non-zero occurrences.



588
Research Track Poster

Method Search (Input: Occurrences and expectations for
3D points in space-time
Output: Most significant cluster with
square pyramid shape)
1. Initialize candidate solution population
2. For each iteration
3.
Choose two solutions A1 and A2 from population
4.
Generate multiple candidate solutions
using splits and combinations
5.
Choose solution B from population
6.
Generate multiple candidate solutions
using small changes at boundaries
7.
Evaluate newly generated candidate solutions
8.
Add to candidate solution population based
on likelihood ratio and population size
9. Output most significant cluster based on likelihood ratio

end Search


Figure 1: High level description of search algorithm




The number of iterations of steps 2 to 8 is specified by the
user. In each iteration, new candidate solutions (children)
are generated based on existing solutions in the population
(parents). Our experiments suggest that both transforma-
tions causing large and small changes to parents are useful in
the search process. As reported extensively in the simulated
annealing literature, large changes are more effective earlier
in the iterative process and smaller changes more useful later
[12].
Steps 3 and 4 in Figure 1, generate children using large
changes to the parents. Two parents, A1 and A2, are se-
lected biased towards solutions with higher likelihood ratios.
Both parents are cut by a 3D hyperplane chosen at random
to generate at most four pieces. The pieces are combined
to generate children analogous to the crossover operation
in genetic algorithms [5].
The pieces themselves are also
considered as children of this transformation. Each child,
represented as a set C of points, need not be legal at this
point (Definition D1). The next subsection describes in de-
tail how a legal candidate solution S is generated from a set
C.
Steps 5 and 6 in Figure 1, mutate a single parent B with
small changes at its boundary. Mutations that increase the
size of B and that decrease its size are applied. One of the
six faces of the pyramid corresponding to B is chosen us-
ing heuristics for applying each kind of mutation. Points
close to the chosen face are selected for addition or removal
biased towards larger or smaller likelihood ratios, respec-
tively. Intuitively, if there is a point outside B but close to
its boundary with relatively high occurrence count it will
likely be added to B to form a new candidate solution. Sim-
ilarly, a point in B close to its boundary with relatively low
occurrence count will likely be removed to form a new can-
didate solution.
Step 7 evaluates all the legal candidate solutions by com-
puting their likelihood ratios. They are added to the can-
didate population and the weakest solutions dropped if the
population size limit has been reached (Step 8). The legal
candidate solution with the best likelihood ratio after all it-
erations are completed is output as the result of the search.
3.2 Shapes Processing
Generating a legal candidate solution S from a subset of
points C is the most critical and interesting part of our
search algorithm. We consider the given subset of points
C as the target for the points contained in a legal candidate
S solution derived from it. There are many intuitive for-
mulations for the generation of S and we list three of them
below.

1. Generate the minimum volume legal solution S that
contains all the points in C.

2. Generate the maximum volume legal solution S that
excludes all the points not in C.

3. Generate the legal solution S that is closest to the set
C, where closest could be measured in various ways
(e.g., absolute difference in points between S and C).

Our system framework allows us to explore all such formu-
lations and we have experimented with the first two formu-
lations in the list above. Since the first two formulations
are quite similar, we will describe only the first one in more
detail in this paper.
In the first formulation, given a set of points C we need to
generate a legal solution S corresponding to a square pyra-
mid Q that minimizes the volume over all square pyramids
that include all the points in C. Minimum and maximum
times for Q, tmin and tmax, are determined simply by com-
puting them over the set of points C. Consider the cross-
section of the pyramid at tmin.
The anchor (point with
smallest x and y values) for the cross section at tmin has co-
ordinates (a, b). The side of the square cross-section at tmin
has dimension g. At tmax, the corresponding parameters are
(c, d) and h.
The coordinates of the cross-section anchor (u, v) at any
point t in the time interval [tmin, tmax] can be calculated as
shown in Equation 2 below.

u = a »
tmax - t
tmax - tmin ­
+ c »
t - tmin
tmax - tmin ­
v = b »
tmax - t
tmax - tmin ­
+ d »
t - tmin
tmax - tmin ­
(2)



A similar linear relation can be used to determine the side
w of the cross-section (Equation 3).

u = g
»
tmax - t
tmax - tmin ­
+ h »
t - tmin
tmax - tmin ­
(3)

The cross-sectional parameters of Q computed in Equa-
tions 2 and 3 can be used to derive linear constraints that
have to be satisfied. For each point z in C that has to be
contained in Q, we can derive four linear constraints that
specify that z is within the square cross-section of Q at the
time t corresponding to z.
The objective function for this formulation is the mini-
mization of the volume of Q as specified in Equation 4 be-
low.

volume(Q) =
,,tmax
- tmin
3
« `g2
+ gh + h2´
(4)

The minimum volume square pyramid Q can be deter-
mined by solving the convex quadratic programming prob-
lem of minimizing volume(Q) subject to the four linear con-
straints for each point in C as discussed above [13]. Once



589
Research Track Poster

the parameters of the minimum volume Q have been deter-
mined, we can easily determine the corresponding solution
S expressed as a set of points by determining all points con-
tained in Q.
This intuitive formulation requires significant computa-
tional resources since the quadratic programming solver has
to be invoked for every potentially interesting candidate gen-
erated in the random search algorithm. In a randomized
search setting one can argue that insisting on the minimum
volume solution is overkill for candidates (C) generated by
the heuristics described earlier. To ease the computational
requirement we have also implemented an approximate ver-
sion that evaluates a restricted set of square pyramids and
picks the one with the smallest volume amongst them. In
this approximate approach, we consider three candidates for
each of the four vertical faces of the pyramid. These candi-
dates are combined to generate a set of legal square pyra-
mids containing all the points in C and the minimum volume
pyramid amongst them is chosen. This approximate formu-
lation need not find the solution with the absolute minimum
volume since it does not explore all square pyramids con-
taining the points in C. However, experimental results so
far with the approximate formulation are encouraging since
the generated solutions are comparable to those produced by
the exact formulation but at a fraction of the computational
cost.
The shapes processing described above can be easily ex-
tended to pyramids with other regular polygons for their
cross sections. Regular polygons with many sides could also
be used to approximate cone shaped cluster regions.

3.3 Algorithm Summary
The algorithm in Figure 1 is applied to the data corre-
sponding to the actual occurrences and to the data synthe-
sized for each of the Monte Carlo experiments representing
the null-hypothesis that the occurrences follow the Poisson
process based on the population distributions. The results
produced by our system include the likelihood ratio of the
strongest cluster in the actual occurrence data and its char-
acteristics. The p-value is computed from the rank of this
cluster (based on the likelihood ratios) amongst all the ex-
periments (actual and Monte Carlo). The p-value is used to
determine if the cluster is significant or could have occurred
by chance. Significant clusters would merit more detailed
investigations by domain experts.

4. EXPERIMENTAL RESULTS
We will demonstrate the use of our approach by doing ret-
rospective analysis on a brain cancer data set that has been
analyzed earlier [8, 10]. We will use the condensed version
of this data that is used as a sample dataset in SaTScan [9]
for retrospective analysis using the Poisson model. The data
has counts for occurrences of brain cancer in 32 counties each
year from 1973 to 1991. The data set also includes covari-
ates like age and gender which can be factored out by various
methods [8, 9] in a comprehensive epidemiological investiga-
tion. We will use the method of indirect standardization for
this task following the approach used in the SaTScan sys-
tem [3, 9, 8]. The condensed brain cancer dataset includes
values for two covariates, age (discretized) and gender. We
will give the results for the cylindrical and square pyramid
clusters after factoring out these two covariates.
The population information is provided with gaps of about
10 years requiring that we interpolate to get the values for
the remaining years [9]. There are a total of 1175 occur-
rences of brain cancer in this data set. Since the occurrences
are given annually for each of the 32 counties, there are a
total of 19 × 32 = 608 space-time points to be considered in
our analysis.
First, we will present results for the cylindrical clusters
using the SaTSan system [9].
The default application of
SaTScan (using only the 32 county locations as centroids)
would only search a limited set of cylindrical candidates and
would be inadequate for comparison with our square pyra-
mid clusters.
A better comparison can be done by forc-
ing consideration of a larger set of cylindrical candidates in
SaTScan by providing a fine grid for the centroids.
The
SaTScan results in Table 1 are obtained by using a grid
of size 1 Cartesian unit and a limit of 100 Cartesian units
for the radius and allowing the temporal cluster extent to
reach up to 90% of the total period. The most likely cluster
(with maximum log likelihood ratio) extends for 5 years from
1985 to 1989 and includes 12 counties (centroid and radius
are given in the table). The ratio of number of actual cases
to the expected gives the relative risk value of 1.356. The
p-value was computed using 999 Monte Carlo replications.

Log likelihood ratio
13.69
Number of cases
265 (195.36 expected)
Overall relative risk
1.356
p-value
0.003
Centroid coordinates
(90, 82)
Cross-section radius
50.21
Time frame
1985-1989

Table 1: Cylindrical cluster results using fine grid

Our algorithm (Figure 1) for detecting more flexible clus-
ters was applied to this data using the approximate shapes
processing for square pyramids described in Section 3.2. In
our algorithm, the choices for the maximum number of it-
erations and the upper limit on the population of candidate
solutions are made considering the following tradeoff. In-
creasing the population of candidate solutions expands the
search space improving the chances of finding the global op-
timum but also slows the convergence to any local optimum
by requiring more iterations. The maximum number of iter-
ations in search algorithm was set at 100K and the maximum
size of the population of candidate solutions was set at 10K.

Log likelihood ratio
17.105
Number of cases
292 (211.57 expected)
Overall relative risk
1.38
p-value
0.017
Time frame
1982-1989

Table 2: Square pyramid cluster results

The characteristics of square pyramid cluster detected by
our system are given in Table 2. The p-value of 0.017 es-
timated using 999 Monte Carlo replications is higher than
the 0.003 value in Table 1, but the cluster is significant us-
ing the threshold of 0.05.
The cluster is visualized using
3D and 2D views in Figure 2 and clearly shows the growth
and movement over time. The squares (both with solid and
with dashed lines) represent the cross-sections of the pyra-
mid cluster increasing in size from 1982 to 1989. This cluster



590
Research Track Poster

0
50
100
150
200




0
50
100
150
200
1982
1983
1984
1985
1986
1987
1988
1989




space-x
space-y
time
0
20
40
60
80
100
120
140
160
180
0
20
40
60
80
100
120
140
160
180




space-x
space-y




Figure 2: Detected cluster with a square pyramid
shape (2D and 3D views)



includes only 4 counties at the start but expands to include
16 counties at the end.
The points marked by  in the 2D view represent the loca-
tions of the 32 counties in the data. We have also plotted the
circular cross-section of SaTScan's cylindrical cluster (from
Table 1) in the 2D view of Figure 2. The squares with the
solid lines correspond to the years for which the cylindrical
cluster was active (i.e., 1985-1989). The squares with the
dashed lines represent the portion of the square pyramid
cluster for the years (1982-1984) preceding the cylindrical
cluster. The value of the flexibility in the cluster shape be-
comes clear when we compare the clusters with cylindrical
and the pyramid shapes in Figure 2.
The power of using a more flexible cluster shape comes
with increased computational costs. Our prototype imple-
mentation took 34 hours to perform the 1000 experiments
needed to report the results in Table 2 on an IBM Intellis-
tation M-Pro computer with an Intel P4 processor running
at 2.2 Ghz. In comparison, the SaTScan run to detect the
cylindrical cluster (using the fine grid) took only 2.5 hours
on the same machine.
Good heuristics are clearly important for randomized search
algorithms to have any chance of efficiently finding solutions
close to optimal in the huge space of candidate solutions.
Our current prototype system is practically useful for ret-
rospective analysis provided the total number of space-time
points is kept within limits by grouping along the space or
time axes. The independent Monte Carlo experiments allow
parallelization leading to easily achievable reductions in the
elapsed times for this analysis.


5. DISCUSSION
The importance of having good convergence behavior for
the randomized algorithm can be illustrated by comparing
the two solutions displayed in Figure 3. The solution pre-
sented earlier in Table 2 with a likelihood ratio of 17.105 is
displayed with solid lines in Figure 3. Another solution that
is a local optimum with a slightly smaller likelihood ratio
of 17.061 is displayed with dashed lines in the same figure.
Clearly, the characteristics of these two clusters are different
enough to convey different insights about the phenomenon
to the user. Expanding the solution space by allowing clus-
ters with more flexible shapes also creates many locally op-
timal solutions with high likelihood ratios. Allowing more
flexible cluster shapes also impacts the chance of finding
strong clusters in the random data used for the Monte Carlo
experiments. These factors along with the known character-
istics of the phenomenon being modeled should determine
the cluster shape for the analysis. The two clusters in Fig-
ure 3 with high likelihood ratios also indicate the need to
consider secondary clusters [9].




0
20
40
60
80
100
120
140
160
180
0
20
40
60
80
100
120
140
160
180




space-x
space-y




Figure 3: Comparing two solutions with log likeli-
hood ratios of 17.105 and 17.061

Since the randomized search algorithm does not guaran-
tee that it will converge to the square pyramid cluster with
the highest likelihood ratio in each of the experiments, we
need to consider the impact on the estimated p-value. We
can visualize and partly assess this impact by performing
multiple runs with different starting seeds for the random
search algorithm. Each run will converge to some solution
for each Monte Carlo experiment (with synthesized data).
For our randomized search algorithm, Figure 4 plots the
best () and worst () log likelihood ratios for each Monte
Carlo experiment over 5 runs (with different random seeds).
The experiments are in sorted order along the x-axis by
their mean likelihood ratio (over the 5 runs). The solid line
at 17.1 corresponds to the cluster in the actual data and the



591
Research Track Poster

0
100
200
300
400
500
600
700
800
900
1000
0
5
10
15
15.82
17.1
18.22
20
25




Monte Carlo experiments
Log
likelihood
ratio




Figure 4: Convergence range for the Monte Carlo
experiments



dashed lines at 18.22 and 15.82 correspond to the p-value
thresholds of 0.01 and 0.05, respectively.
This plot gives
some indication that the true p-value is unlikely to be below
the 0.05 threshold.
This visualization does not address any systematic weak-
ness in the randomized search algorithm that may prevent
it from finding solutions close to the optimal. It is useful
only to display the spread due to the randomization in the
search. Our conjecture to explain the convergence behav-
ior is that our algorithm is more effective when there is a
dominant cluster but requires more iterations when there
are many comparable clusters at different parts of the solu-
tion space (as can happen in the Monte Carlo experiments).
While improvements in the search algorithm could make it
more robust, one cannot guarantee finding the optimal solu-
tion for each experiment with heuristic search. Further work
is needed to formally characterize the p-value estimated by
such methods.



6. CONCLUSION
We have presented a novel approach to detecting space-
time clusters that can model growth (or shrinkage) and
movement of the phenomenon over time. This was accom-
plished by extending the formulation of the space-time scan
statistic to clusters with a square pyramid shape. A heuris-
tic search algorithm was developed to detect clusters with
this more flexible shape since exhaustive methods are not
practical. The randomized search algorithm was combined
with geometrical shapes processing functions to determine
the most likely square pyramid clusters. Our approach was
applied to a real brain cancer data set that included co-
variates representing other confounding factors. We detect
stronger clusters with very different characteristics using our
approach compared to earlier results for simpler cylindrical
clusters. The square pyramid cluster detected by our ap-
proach exhibits both growth and movement in the disease,
something that could not be modeled with the cylindrical
geometry. Our framework can be extended quite easily to
handle clusters with other flexible shapes by adding the ap-
propriate geometric modules.
7. ACKNOWLEDGMENTS
We would like to thank Murray Campbell, Jon Lee and
Martin Kulldorff for helpful discussions.
This material is
based upon work supported by the Air Force Research Lab-
oratory (AFRL) / (DARPA) Defence Advanced Research
Projects under AFRL Contract No. F30602-01-C-0184 (Dis-
tribution Statement A: approved for public release, distri-
bution unlimited). Any opinions, findings, conclusions or
recommendations expressed in this material are those of the
author and do not necessarily reflect the views of the AFRL
and/or DARPA.


8. REFERENCES
[1] R. Agrawal, J. Gehrke, D. Gunopulos, and
P. Raghavan. Automatic subspace clustering of high
dimensional data for data mining applications. In
Proceedings of the ACM-SIGMOD International
Conference on Management of Data, pages 94­105,
1998.
[2] L. Duczmal and R. Assuncao. A simulated annealing
strategy for the detection of arbitrary shaped spatial
clusters. Computational Statistics and Data Analysis,
March 2003.
[3] J. Fleiss. Statistical methods for Rates and
Proportions. John Wiley & Sons, 1981.
[4] J. Glaz and N. Balakrishnan. Scan Statistics and
Applications. Birkhauser, 1999.
[5] D. Goldberg. Genetic Algorithms in Search,
Optimization and Machine Learning. Addison-Wesley,
1989.
[6] M. Kulldorff. A spatial scan statistic. Communications
in Statistics: Theory and Methods, 26(6):1481­1496,
1997.
[7] M. Kulldorff. Spatial scan statistics: models,
calculations, and applications. In Scan Statistics and
Applications, edited by Glaz and Balakrishnan, 1999.
[8] M. Kulldorff, W. Athas, E. Feuer, B. Miller, and
C. Key. Evaluating cluster alarms: A space-time scan
statistic and brain cancer in Los Alamos. American
Journal of Public Health, 88:1377­1380, 1998.
[9] M. Kulldorff and Information Management Services
Inc. Satscan v. 3.1: Software for the spatial and
space-time scan statistics. Technical report, 2002.
URL=http://www.satscan.org/.
[10] National Cancer Institute. Brain cancer in New
Mexico. Technical Report Data set (1973-1991),
Division of Cancer Prevention, Biometry Research
Group.
[11] D. Neill and A. Moore. A fast multi-resolution method
for detection of significant spatial overdensities.
Technical Report Carnegie Mellon CSD Technical
Report CMU-CS-03-154 (Abbreviated version to
appear in NIPS 2003), Carnegie Mellon University,
June 2003.
[12] P. van Laarhoven and E. Aarts. Simulated Annealing:
Theory and Applications. D. Reidel Publishing
Company, 1987.
[13] D. Wilson and B. Rudin. Introduction to the IBM
Optimization Subroutine Library. IBM Systems
Journal, 31(1):4­10, 1992.




592
Research Track Poster

