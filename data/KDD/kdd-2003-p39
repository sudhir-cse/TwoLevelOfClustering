Adaptive Duplicate Detection Using Learnable String
Similarity Measures


Mikhail Bilenko and Raymond J. Mooney
Department of Computer Sciences
University of Texas at Austin
Austin, TX 78712
{mbilenko,mooney}@cs.utexas.edu



ABSTRACT
The problem of identifying approximately duplicate records in da-
tabases is an essential step for data cleaning and data integration
processes. Most existing approaches have relied on generic or man-
ually tuned distance metrics for estimating the similarity of poten-
tial duplicates. In this paper, we present a framework for improving
duplicate detection using trainable measures of textual similarity.
We propose to employ learnable text distance functions for each
database field, and show that such measures are capable of adapt-
ing to the specific notion of similarity that is appropriate for the
field's domain. We present two learnable text similarity measures
suitable for this task: an extended variant of learnable string edit
distance, and a novel vector-space based measure that employs a
Support Vector Machine (SVM) for training. Experimental results
on a range of datasets show that our framework can improve dupli-
cate detection accuracy over traditional techniques.

Categories and Subject Descriptors
H.2.8 [Database Management]: Database Applications - Data Min-
ing; I.2.6 [Artificial Intelligence]: Learning

Keywords
Data cleaning, record linkage, distance metric learning, trained sim-
ilarity measures, string edit distance, SVM applications

1. INTRODUCTION
Databases frequently contain field-values and records that refer
to the same entity but are not syntactically identical. Variations
in representation can arise from typographical errors, misspellings,
abbreviations, as well as integration of multiple data sources. Vari-
ations are particularly pronounced in data that is automatically ex-
tracted from unstructured or semi-structured documents or web pa-
ges [16, 3]. Such approximate duplicates can have many deleteri-
ous effects, including preventing data-mining algorithms from dis-
covering important regularities. This problem is typically handled
during a tedious manual data cleaning, or "de-duping", process.
Some previous work has addressed the problem of identifying
duplicate records, where it was referred to as record linkage [18,



Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGKDD '03, August 24-27, 2003, Washington, DC, USA
Copyright 2003 ACM 1-58113-737-0/03/0008 ...$5.00.
25], the merge/purge problem [10], duplicate detection [15, 22],
hardening soft databases [3], reference matching [13], and entity-
name clustering and matching [4]. Typically, standard string simi-
larity metrics such as edit distance [9] or vector-space cosine sim-
ilarity [1] are used to determine whether two values or records are
alike enough to be duplicates. Some more recent work [4, 22, 23]
has investigated the use of pairing functions that combine multiple
standard metrics.
Because an estimate of similarity between strings can vary sig-
nificantly depending on the domain and specific field under consid-
eration, traditional similarity measures may fail to estimate string
similarity correctly. At the token level, certain words can be infor-
mative when comparing two strings for equivalence, while others
are ignorable. For example, ignoring the substring "Street" may
be acceptable when comparing addresses, but not when comparing
names of people (e.g. "Nick Street") or newspapers (e.g. "Wall
Street Journal"). At the character level, certain characters can be
consistently replaced by others or omitted when syntactic varia-
tions are due to systematic typographical or OCR errors. Thus,
accurate similarity computations require adapting string similarity
metrics for each field of the database with respect to the particular
data domain.
Rather than hand-tuning a distance metric for each field, we pro-
pose to use trainable similarity measures that can be learned from
small corpora of labeled examples, and thus adapt to different do-
mains. We present two such string similarity measures. The first
one utilizes the Expectation-Maximization (EM) algorithm for es-
timating the parameters of a generative model based on string edit
distance with affine gaps. The other string similarity measure em-
ploys a Support Vector Machine (SVM) [24] to obtain a similarity
estimate based on the vector-space model of text. The character-
based distance is best suited for shorter strings with minor vari-
ations, while the measure based on vector-space representation is
more appropriate for fields that contain longer strings with more
global variations.
Our overall system, MARLIN (Multiply Adaptive Record Link-
age with INduction), employs a two-level learning approach. First,
string similarity measures are trained for every database field so
that they can provide accurate estimates of string distance between
values for that field. Next, a final predicate for detecting duplicate
records is learned from similarity metrics applied to each of the in-
dividual fields. We again utilize Support Vector Machines for this
task, and show that they outperform decision trees, the classifier
used in prior work [23, 22]. We evaluate our approach on sev-
eral real-world data sets containing duplicate records and show that
MARLIN can lead to improved duplicate detection accuracy over
traditional techniques.



39

2. LEARNABLE STRING DISTANCE

2.1 Background
Most traditional methods for calculating string similarity can be
roughly separated into two groups: character-based techniques and
vector-space based techniques. The former rely on character edit
operations, such as deletions, insertions, substitutions and subse-
quence comparison, while the latter transform strings into vector
representation on which similarity computations are conducted.
The best-known character-based string similarity metric is Lev-
enshtein distance, defined as the minimum number of insertions,
deletions or substitutions necessary to transform one string into
another. Needleman and Wunsch [17] extended the model to al-
low contiguous sequences of mismatched characters, or gaps, in
the alignment of two strings, and described a general dynamic pro-
gramming method for computing edit distance. Most commonly
the gap penalty is calculated using the affine model: cost(g) =
s + e × l, where s is the cost of opening a gap, e is the cost of
extending a gap, and l is the length of a gap in the alignment of two
strings, assuming that all characters have a unit cost. Usually e is
set to a value lower than s, thus decreasing the penalty for contigu-
ous mismatched substrings. Since differences between duplicate
records often arise because of abbreviations or whole-word inser-
tions and deletions, this model produces a more sensitive similarity
estimate than Levenshtein distance.
String distance with affine gaps between two strings of lengths
l1 and l2 can be computed using a dynamic programming algo-
rithm that constructs three matrices in O(l1l2) computational time .
The following recurrences are used to construct the matrices, where
c(xi, yj) denotes the cost of the edit operation that aligns i-th char-
acter of string x to j-th character of string y, while c(xi, ) and
c( , yj) are insertion and deletion costs for the respective charac-
ters. Matrix M represents a minimum-cost string alignment that
ends with matched characters, while matrices I and D represent
alignments that end with a gap in one of the two strings [9]:


Mi,j = min
8
>
<

>
:
Mi
-1,j-1
+ c(xi, yj)
Ii
-1,j-1
+ c(xi, yj)
Di
-1,j-1
+ c(xi, yj)


Di,j = min
(
Mi
-1,j
+ s + c(xi, )
Di
-1,j
+ e + c(xi, )
(1)


Ii,j = min
(
Mi,j
-1
+ s + c( , yj)
Ii,j
-1
+ e + c( , yj)

S(xT , yV ) = min(IT,V , DT,V , MT,V )


While character-based metrics work well for estimating distance
between strings that differ due to typographical errors or abbrevi-
ations, they become computationally expensive and less accurate
for larger strings. When differences between equivalent strings are
expressed by multiple words that are added, deleted or transposed,
character-based metrics may assign high cost to non-matching string
segments, producing low similarity scores for strings with a few
word-level differences. The vector-space model of text [1] avoids
this problem by viewing strings as "bags of tokens" and disregard-
ing the order in which the tokens occur in the strings. Given a
vocabulary of n possible tokens in a corpus, strings are represented
as sparse n-dimensional vectors of real numbers, where every non-
zero component corresponds to a token present in a string. TF-IDF
is the most popular method for computing the weights of the vec-
tor representation; it takes into account token frequencies within
a particular string and over the entire corpus. Similarity between
two strings x and y is then computed as normalized dot product
between their vector-space representations x and y (cosine of the
angle between them):

Sim(x, y) =
x · y
x
y
=
Pd
i=1
xiyi
x
y
(2)


Because vectors representing the strings are highly sparse, vector-
space cosine similarity is very efficient when implemented prop-
erly, and provides a reasonable off-the-shelf metric for larger strings
and text documents.1

2.2 Learnable Distance Metrics

2.2.1 LearnableStringEditDistancewithAffineGaps
Different edit operations have varying significance in different
domains. For example, a digit substitution makes a major differ-
ence in a street address since it effectively changes the house num-
ber, while a single letter substitution is semantically insignificant
because it is more likely to be caused by a typo or an abbrevia-
tion. Therefore, adapting string edit distance to a particular domain
requires assigning different weights to different edit operations.
In prior work, Ristad and Yianilos [21] have developed a gen-
erative model for Levenshtein distance along with an Expectation-
Maximization algorithm that learns model parameters using a train-
ing set consisting of matched strings. We propose a similar stochas-
tic model for the edit distance with affine gaps. The distance be-
tween two strings corresponds to a particular alignment of the
strings' characters, which may include non-matching regions. An
alignment can be viewed as a sequence of pairs xi, yj , xi,
,
, yj ,
where xi and yj are the corresponding strings' characters, and
is indicates a gap. Each character pair then represents an edit
operation: a substitution or an insertion/deletion denoting a gap
(matched characters can be thought of as a special case of substi-
tution). The overall alignment represents a sequence of edit op-
erations that transform one string into another with an associated
cost.
The affine-gap alignment can be modeled by a simple stochastic
transducer shown in Fig.1 below. The three matrices of the original
model (1) correspond to accumulated forward probabilities for an
alignment that ends in one of the three states. A particular align-
ment of two strings is generated by this model as a sequence of
traversals along the edges. Each traversal is accompanied by an
emission of a character pair sampled from a probability distribu-
tion of the state that is reached via each traversal.








µ
M
D


#



I
µ



I
D
D
D




I
I


I
D




Figure 1: Generative model for string distance with affine gaps

1
While string edit distance with affine gaps obeys the triangle in-
equality [9], and is therefore a metric in the strict mathematical
sense, this is not true for normalized dot product. However, be-
cause the process of duplicate detection only requires a measure
that accurately ranks pairs of strings with respect to their relative
similarities, measures that do not satisfy the triangle inequality are
satisfactory. Therefore, we will not restrict our discussion to mea-
sures that obey the triangle inequality and will use the term "met-
ric" as a synonym of "measure".


40

Given an alphabet of symbols A = A S{ }, the full set of edit
operations is E = Es
S Ed S Ei,
where Es = { a, b | a, b  A}
is the set of all substitution and matching operations a, b ; and
Ei = { , a
| a  A} and Ed = { a,
| a  A} are sets of
insertion and deletion operations respectively.
The production starts in state M and terminates when the spe-
cial state # is reached. Transitions D and I from the matching
state M to either the deletion state D or the insertion state I cor-
respond to a gap in the alignment of the strings. A gap is ended
when the edge D (or I) is traversed back to the matching state.
Remaining in state M by taking edge µ corresponds to a sequence
of substitutions or exact matches, while remaining in states I and
D is analogous to extending a gap in either the first or the second
string. The sum of transition probabilities must be normalized in
each state for the model to be complete.
Edit operations emitted in each state correspond to aligned pairs
of characters: substitutions a, b and exact matches a, a in state
M; deletions from the first string a,
in state D; and insertions of
characters from the second string into the first string
, a in state
I. Each edit operation e  E is assigned a probability p(e) such
that
P
eEs
p(e) = 1,
P
eEd
p(e) = 1, and
P
eEi
p(e) = 1.
Edit operations with higher probabilities produce character pairs
that are likely to be aligned in a given domain, such as substitution
/, - for phone numbers, or deletion .,
for addresses.
This generative model is similar to one given for amino-acid se-
quences in [6] with two important differences: (1) transition proba-
bilities are distinct for states D and I, and (2) every transition has a
probability parameter associated with it, instead of being expressed
through other transitions that are outgoing from the same state.
Given two strings, xT of length T and yV of length V , proba-
bilities of generating the pair of prefixes (xT1...t, yV
1...v
) and suffixes
(xTt
+1...T
, yV
v+1...V
) can be computed using dynamic programming
in standard forward and backward algorithms in O(TV ) time [20].
Then, given a corpus of n matched strings corresponding to pairs
of duplicates, C = {(xT1, yV1), . . . , (xTn, yVn)}, this model can
be trained using a variant of the Baum-Welch algorithm, shown in
Fig.2, which is an Expectation-Maximization procedure for learn-
ing parameters of generative models [20]. The training procedure
iterates between two steps, where in the first step the expected num-
ber of occurrences for each state transition and edit operation emis-
sion is accumulated for a given pair of strings (xT , yV ) from the
training corpus. This is achieved by accumulating the posterior
probabilities for every possible state transition and an accompa-
nying character pair emission. In the MAXIMIZATION procedure
all model parameters are updated using the collected expectations.
Pseudo-code for the algorithms can be found in [2].
It can be proved that this training procedure is guaranteed to con-
verge to a local maximum of likelihood of observing the training
corpus C. The trained model can be used for estimating distance
between two strings by computing the probability of generating the
aligned pair of strings summed across all possible paths as cal-
culated by the forward and backward algorithms: d(xT , yV ) =
-log p(xT,yV ), and then obtaining the posterior probability. Nu-
merical underflow may occur when these computation are performed
for long strings; this problem can be resolved by mapping all com-
putations into logarithmic space or by periodic scaling of all values
in matrices M, D and I [21].


2.2.2 Practical Considerations
Because the order of strings being aligned does not matter when
similarity of database records is being estimated, insertion and dele-
tion operations as well as transitions for states I and D can be rep-
resented by a single set of parameters: p( a,
) = p(
, a ) for all
Input: A set of equivalent strings S = {(xTi, yVi), xTi  yVi}
Output: A set of parameters for edit distance with
affine gaps that minimizes distance for each (x, y)  S
Method:
until convergence
for each (xTi, yVi)  S
Expectation-step: Use forward and backward algorithms
to accumulate the expected number of occurrences E[ xj, yk ]
for each edit operation used to align xTi and yVi,
as well as E[µ], E[I], E[D], E[I], E[D], E[I], E[D].
end
Maximization-step: Update all transition and emission
probabilities using the expected numbers of occurrences
and re-normalize.
end


Figure 2: Training algorithm for generative string distance
with affine gaps


symbols a  A;  =I =D;  =I =D;  =I =D;  =I =
D.
The generative model of Fig.1 suffers from two drawbacks that
impede its utility for computing similarity between strings in a
database. One problem lies in the fact that the model assigns a
probability less than one to strings that are exact duplicates. Be-
cause the probability of an alignment monotonically decreases as
more matching characters are appended to the strings, longer ex-
act duplicates are penalized even more severely than shorter exact
duplicates, which is counter-intuitive and exacerbates the problem
further.
The second difficulty lies in the fact that due to the large size
of the edit operation set, probabilities of individual operations are
significantly smaller than transition probabilities. If only a rela-
tively small number of training examples is available, probabilities
of some edit operations may be underestimated, and distances as-
signed to strings will vary significantly with minor character varia-
tions. Two steps are taken to address these issues. First, the prob-
ability distribution over the set of edit operations, E, is smoothed
by bounding each edit operation probability by some reasonable
minimum value . Second, learned parameters of the generative
distance model are mapped to operation costs of the additive model
(1) by taking the negative logarithm of each probability. Distance
can then be calculated analogously to Eq.(1) with the addition of
supplemental costs g = - log  for ending a gap and m = - log µ
for continuing to substitute/match characters. This is equivalent to
calculating the cost of the most likely (Viterbi) alignment of the two
strings by the generative model in log-space. To solve the "non-
zero exact match" problem and decrease high variance in distances
due to edit operation costs c(a, b) compared to transition costs s, e,
g and m, the cost of producing matching pairs of characters is set to
zero. The overall distance obtained from the model is normalized
by the sum of string lengths to correct for the "increasing distance
for longer exact duplicates" problem. The resulting metric can be
viewed as a hybrid between the generative model and the original
fixed-cost model.

2.2.3 Learnable Vector-space Similarity
The TF-IDF weighting scheme is useful for similarity compu-
tations because it attempts to give tokens weights that are propor-
tional to the tokens' relative importance. However, the true contri-
bution of each token to similarity is domain-specific. For example,
suppose that duplicate detection is conducted on a database that
contains street addresses. If there are several records of addresses
from the same street, the street name token (for example, `34th')


41

will have a lower weight due to its many occurrences across the
corpus resulting in a lower IDF value. At the same time, some
addresses may contain the token `Square', which then will be
assigned approximately the same weight as `34th' since it may
be as common. While two addresses on the same street are more
similar than two addresses that are both on squares, the generic TF-
IDF cosine similarity is incapable of making the distinction.
If training data in the form of labeled pairs of duplicate and non-
duplicate strings is available, it can be used to learn a similarity
function that will give more weight to those tokens that are good
indicators of actual similarity. Let us rewrite Eq.(2) in the following
form:
Sim(x, y) =
d
X

i=1
xiyi
x
y
(3)


Every component
xiyi
x
y
of the sum corresponds to an i-th token
in the vocabulary. This expression can be thought of as the i-th
component of a d-dimensional vector that is being classified. Then
the vector space similarity computation between two strings can be
viewed as two consecutive steps:
(i) A d-dimensional pair vector p(x,y
)
=
xiyi
x
y
is created, each
component of which corresponds to the product of weights for the
corresponding token in the vocabulary;
(ii) The summation is performed, which is equivalent to the pair
instance p(x,y
)
being classified by a perceptron with unit weights
as either belonging to the equivalent-string class (output is 1), or
different-string class (output is 0). The perceptron output value
corresponds to the confidence of the prediction.
Provided training data in the form of equivalent-string pairs S =
{(x,y), x  y} and different-string pairs D = {(x,y), x  y},
it becomes possible to train a classifier for step (ii) to produce out-
puts that correspond to the desired categorization of string pairs.
The trained classifier would be able to distinguish between features
that are informative for similarity judgments, and those that are not,
adapting the computation to the domain-specific notion of similar-
ity that is contained in the training data.
A classifier appropriate for this task should be able to learn well
from limited training sets of high-dimensional data. It also must
produce meaningful confidence estimates that correspond to rela-
tive likelihood of belonging to equivalent-string or different-string
classes for different string pairs. Another key requirement is that
the the hypothesis learned by the classifier must be independent of
the relative sizes of the positive and negative training sets, since the
proportion of duplicate pairs in the training set is likely to be much
higher than in the actual database where duplicates are detected.
Support vector machines [24] satisfy all of these requirements.
SVMs classify input vectors p(x,y
)
by implicitly mapping them
via the "kernel trick" to a high-dimensional space where the two
classes (S, equivalent-string pairs, and D, different-string pairs)
are separated by a hyperplane. The output of the classifier is the
distance between (p(x,y
)
), the image of the pair vector in high-
dimensional space, and the separating hyperplane. This distance
provides an intuitive measure of similarity: those pair vectors that
are classified with a large margin as belonging to S correspond to
pairs of strings that are highly similar, while those classified with a
large margin as belonging to D represent dissimilar pairs of strings.
The output of an SVM has the form f(x) =
Pl
i=1
iyiK(pi, x)+
b, where K(x, y) is a kernel function, and i is the Lagrangian
coefficient corresponding to i-th training pair vector pi, obtained
from the solution to the quadratic optimization problem. Because
SVM training algorithms are independent of the dimensionality of
the feature space (only the margin on the training data affects hy-
pothesis choice), they are guaranteed not to overfit the solution to
the training pairs.
Methods for obtaining calibrated posterior probabilities from the
SVM output [19] could be used to obtain a probabilistically mean-
ingful similarity function at this point. Because in the deduping
framework we are only concerned with obtaining a correct rank-
ing of pairs with respect to their true similarities, the distance from
the hyperplane provides this without additional model fitting. The
SVM output function f(x) is bounded; the specific range of output
values depends on the choice of kernel function K and the train-
ing set. For example, for radial basis function kernels K(x, xi) =
exp(-
x-xi
2
22
) (a very loose) bound is |f(x)| 
Pl
i=1
i + b.
Given upper and lower bounds fmin  f(x)  fmax for a particu-
lar kernel function and training set, it is trivial to obtain a similarity
value in the [0; 1] range from the SVM output:


Sim(s1, s2) =
f(p(s1s2)) - fmin
fmax - fmin
(4)


The overall approach for obtaining a similarity value based on
vector space using SVMs is shown on Fig.3, and the training al-
gorithm is presented on Fig.4. When similarity between strings x
and y needs to be computed, they are transformed to vector-space
representations, and the pair vector p(x,y
)
is formed from individ-
ual components of their individual vector representations. The pair
vector is then classified by the trained SVM, and the final similarity
value is obtained from the SVM prediction f(p(x,y
)
) using Eq.(4).




is created
The pair instance




x
y
.




.




.

.
is obtained from the SVM output
Similarity between strings
is classified by the SVM
The pair instance
"piedmont"


"rd"
"ne"




"road"
"3130"
y:
"3130 Piedmont Rd. NE"
x:
"3130 Piedmont Road"


Each string is converted to
vector-space representation




S




(p(x,y
)
)
f (p(x,y
)
)
D
p(x,y
)
x1


x2

x3


x4
x5
y1


y2

y3


y4
y5
x1y1


x2y2

x3y3


x4y4
x5y5




Sim(x, y) =
f(p(x,y
)
)-fmin
fmax-fmin


Figure 3: String similarity calculation for the SVM-based
learnable vector-space model




42

Input: Sets of equivalent strings S = {(x, y), x  y}
and non-equivalent strings D = {(x, y), x  y}
Output: A string similarity function Sim(x, y)
Method:
1. Convert all strings in S and D to vector representation
2. Create positive and negative training sets Sp and Dp
by constructing pair instances p(
x,y)
=
xiyi
x
y
:
Sp = {p(
x,y)
, (x, y)  S}; Dp = {p(
x,y)
, (x, y)  D}
3. Train an SVM on Sp and Dp to obtain the classification
function f(x) =
l
i=1
iyiK(pi, x) + b, fmin  f (x)  fmax
4. Return Sim(x, y) =
f (p(x,y
)
)-fmin
fmax-fmin


Figure 4: Training algorithm for SVM-based vector space sim-
ilarity


3. RECORD-LEVEL SIMILARITY

3.1 Combiningsimilarityacrossmultiplefields
When the distance between records composed of multiple fields
is calculated, it is necessary to combine similarity estimates from
individual fields in a meaningful manner. Because correspondence
between overall record similarity and single-field similarity can
vary greatly depending on how informative the fields are, it is nec-
essary to weight fields according to their contribution to the true
distance between records.
While statistical aspects of combining similarity scores for indi-
vidual fields have been addressed in previous work on record link-
age [25], availability of labeled duplicates allows a more direct ap-
proach that uses a binary classifier that computes a "pairing func-
tion" [4]. Given a database that contains records composed of k dif-
ferent fields and a set D = {d1(·, ·), . . . , dm(·, ·)} of distance met-
rics, we can represent any pair of records by an mk-dimensional
vector. Each component of the vector represents similarity between
two field values of the records that is calculated using one of the m
distance metrics.
Matched pairs of duplicate records can be used to construct a
training set of such feature vectors by assigning them a positive
class label. Pairs of records that are not labeled as duplicates im-
plicitly form the complementary set of negative examples. If the
transitive closure of matched pairs contains disjoint sets of dupli-
cate records, this approach will result in noisy negative examples.
Next, a binary classifier is trained using these training vectors to
discriminate between pairs of records corresponding to duplicates
and non-duplicates. Overall, this approach follows the same frame-
work that is used for learnable vector-space string similarity in the
previous section. Following the same reasoning, SVMs are a good
classifier choice due to their resilience to noise and ability to handle
correlated features well. The distance from the hyperplane provides
a measure of confidence in the pair of records being a duplicate; it
can be transformed to an actual similarity value using Eq.(4). Fig.5
illustrates this process of computing record similarity using mul-
tiple similarity measures over each field and a binary classifier to
categorize the resulting feature vector as belonging to the class of
duplicates or non-duplicates, resulting in a distance estimate. For
each field of the database, two learnable distance measures, d1 and
d2, are trained and used to compute similarity for that field. The
values computed by these measures form the feature vector that is
then classified by a support vector machine, producing a confidence
value that represents similarity between the database records.

3.2 Theoverallduplicatedetectionframework
An overall view of our system, MARLIN, is presented in Fig.6.
Fenix at the Argyle
8358 Sunset Blvd.
W. Hollywood
French (new)
8358 Sunset Blvd. WestFenix
Hollywood
American
Name
Address
City
Cuisine




SVM
Learned
distance
measures




Distance

Duplicate records
Non-duplicate records
T
Feature vector
d2n
d1n
d2a
d1a
d1cu
d2cu
d1c
d2c



d1n
d1a
d1c
d1cu d2cu
d2n
d2c
d2a




Figure 5: Computation of record similarity from individual
field similarities



The training phase consists of two steps. First, the learnable dis-
tance metrics are trained for each record field. The training corpus
of paired field-level duplicates and non-duplicates is obtained by
taking pairs of values for each field from the set of paired duplicate
records. Because duplicate records may contain individual fields
that are not equivalent, training data can be noisy. For example, if
one record describing a restaurant contains `Asian' in the Cui-
sine field, and a duplicate record contains `Seafood', a noisy
training pair is formed that implies equivalence between these two
descriptors. However, this issue does not pose a serious problem for
our approach for two reasons. First, particularly noisy fields that
are unhelpful for identifying record-level duplicates will be con-
sidered irrelevant by the classifier that combines similarities from
different fields. Second, the presence of such pairs in the database
indicates that there is a degree of similarity between such values,
and using them in training allows the learnable metric to capture
that likelihood.
After individual similarity metrics are learned, they are used to
compute distances for each field of duplicate and non-duplicate
record pairs to obtain training data for the binary classifier in the
form of vectors composed of distance features.
The duplicate detection phase starts with generation of potential
duplicate pairs. Given a large database, producing all possible pairs
of records and computing similarity between them is too expensive
since it would require O(n2) distance computations. MARLIN uti-
lizes the canopies clustering method [13] using Jaccard similarity,
a computationally inexpensive metric based on an inverted index,
to separate records into overlapping clusters ("canopies") of poten-
tial duplicates. Pairs of records that fall in each cluster then become
candidates for a full similarity comparison shown in Fig.5.
Learned distance metrics are then used to calculate distances for
each field of each pair of potential duplicate records, thus creat-
ing distance feature vectors for the classifier. Confidence estimates
for belonging to the class of duplicates are produced by the binary
classifier for each candidate pair, and pairs are sorted by increasing
confidence.
The problem of finding a similarity threshold for separating du-
plicates from non-duplicates arises at this point. A trivial solu-
tion would be to use the binary classification results to label some
records as duplicates, and others as non-duplicates. A traditional
approach to this problem [25], however, requires assigning two
thresholds: one that separates pairs of records that are high-confi-
dence duplicates, and another for possible duplicates that should be
reviewed by a human expert. Since relative costs of labeling a non-
duplicate as a duplicate (false positives) and overlooking true dupli-


43

Table 1: Sample duplicate records from the Cora database
authors
title
venue
address
year
pages

Yoav Freund, H. Sebastian Se-
ung, Eli Shamir, and Naftali
Tishby
Information,
prediction,
and query by committee
Advances in Neural Infor-
mation Processing System
San Mateo, CA
1993
pages 483-490



Freund, Y., Seung, H. S.,
Shamir, E., & Tishby, N.
Information,
prediction,
and query by committee
Advances in Neural In-
formation Processing Sys-
tems
San Mateo, CA.
­
(pp. 483-490).




Table 2: Sample duplicate records from the Restaurant database
name
address
city
phone
cuisine

fenix
8358 sunset blvd. west
hollywood
213/848-6677
american
fenix at the argyle
8358 sunset blvd.
w. hollywood
213-848-6677
french(new)


Table 3: Sample duplicate records from the Reasoning database
L. P. Kaelbling. An architecture for intelligent reactive systems. In Reasoning
About Actions and Plans: Proceedings of the 1986 Workshop. Morgan Kaufmann, 1986
Kaelbling, L. P., 1987. An architecture for intelligent reactive systems. In
M. P. Georgeff & A. L. Lansky, eds., Reasoning about Actions and Plans, Morgan
Kaufmann, Los Altos, CA, 395 410




Labeled
duplicate pairs
Distance


Learner
Metric




Database
records
duplicates
Potential

Distance
Learned


Metrics



Binary classifier




Identified
duplicates
Distance
Metrics
Learned
Binary classifier




Duplicate Detection:

Candidate pair extractor
non-duplicate
Duplicate and



distance features




Distance features
Learned
parameters
Record training
data extractor
Training:

Field training data extractor


Field duplicates




Record duplicates

and non-duplicates




Figure 6: MARLIN overview



cates (false negatives) can vary from database to database, there is
no "silver bullet" solution to this problem. Availability of labeled
data, however, allows us to provide precision-recall estimates for
any threshold value and thus offer a way to control the trade-off be-
tween false and unidentified duplicates by selecting threshold val-
ues that are appropriate for a particular database.
It is possible that several identified duplicate pairs will contain
the same record. Since the "duplicate of" relation is transitive, it
is necessary to compute the transitive closure of equivalent pairs
to complete the identification process. Following [15], MARLIN
utilizes the union-find data structure to store all database records in
this step, which allows updating the transitive closure of identified
duplicates incrementally in an efficient manner.

4. EXPERIMENTAL EVALUATION
4.1 Datasets
Our experiments were conducted on six datasets. Restaurant is a
database of 864 restaurant names and addresses containing 112 du-
plicates obtained by integrating records from Fodor's and Zagat's
guidebooks. Cora is a collection of 1295 distinct citations to 122
Computer Science research papers from the Cora Computer Sci-
ence research paper search engine. The citations were segmented
into multiple fields such as author, title, venue, etc. by an in-
formation extraction system, resulting in some crossover noise be-
tween the fields. Reasoning, Face, Reinforcement and Constraint
are single-field datasets containing unsegmented citations to com-
puter science papers in corresponding areas from the Citeseer sci-
entific literature digital library.2 Reasoning contains 514 citation
records that represent 196 unique papers, Face contains 349 cita-
tions to 242 papers, Reinforcement contains 406 citations to 148
papers, and Constraint contains 295 citations to 199 papers. Tables
1­3 contain sample duplicate records from the Restaurant, Cora,
and Reasoning datasets.
4.2 Experimental Methodology
Every dataset was randomly split into 2 folds for cross-validation
for each experimental run. A larger number of folds is impractical
since it would result in few duplicate records per fold. To create
the folds, duplicate records were grouped together, and the result-
ing clusters were randomly assigned to the folds, which resulted in
uneven folds in some of the trials. All results are reported over 20
random splits, where for each split the two folds were used alter-
nately for training and testing.
During each trial, duplicate detection was performed as described
in Section 3.2. At each iteration, the pair of records with the high-
est similarity was labeled a duplicate, and the transitive closure of
groups of duplicates was updated. Precision, recall and F-measure
defined over pairs of duplicates were computed after each itera-
tion, where precision is the fraction of identified duplicate pairs
that are correct, recall is the fraction of actual duplicate pairs that
were identified, and F-measure is the harmonic mean of precision
and recall:

2
http://citeseer.nj.nec.com/


44

P recision =
#ofCorrectlyIdentifiedDuplicateP airs
#ofIdentifiedDuplicateP airs


Recall =
#ofCorrectlyIdentifiedDuplicateP airs
#ofT rueDuplicateP airs


F -measure =
2 × P recision × Recall
P recision + Recall


As more pairs with lower similarity are labeled as duplicates,
recall increases, while precision begins to decrease because the
number of non-duplicate pairs erroneously labeled as duplicates
increases. Precision was interpolated at 20 standard recall levels
following the traditional procedure in information retrieval [1].

4.3 Results
4.3.1 Detecting duplicate field values
To evaluate the usefulness of adapting string similarity measures
to a specific domain, we compared learned distance metrics with
their fixed-cost equivalents for the task of identifying equivalent
field values. Along with the four single-field Citeseer datasets we
chose two most meaningful fields from the Restaurant dataset -
name and address.
We have compared four string similarity measures:
· Edit distance with affine gaps [9] using substitution cost of
2, gap opening cost of 3, gap extension cost of 1, and match
cost of -1, which are commonly used parameters;
· Learned edit distance with affine gaps described in Section
2.2.1, trained using the EM algorithm shown in Fig.2 with
edit operation probabilities smoothed at  = 10-
5
and con-
verted to the additive cost model as described in Section
2.2.2;
· Normalized dot product in vector space (cosine similarity),
computed using TF-IDF weights after stemming and stop-
word removal;
· Learnable vector-space SVM-based similarity described in
Section 2.2.3, implemented over TF-IDF representations af-
ter stemming and stopword removal. SVM implementation
with the radial basis function kernel from the SVMlight pack-
age was used as the classifier [11] with  = 10.
Results for field-level duplicate detection experiments are summa-
rized in Table 4. Each entry in the table contains the average of
maximum F-measure values over the 40 evaluated folds. Results
for experiments where the difference between the learned and cor-
responding unlearned metric is significant at the 0.05 level using a
1-tailed paired t-test are presented in bold font. Figs. 7 and 8 con-
tain recall-precision curves for the performance of MARLIN on the
name and address fields of the Restaurant dataset respectively.
Relatively low precision of these two experiments is due to the
fact that the duplicates on individual fields are very noisy: for ex-
ample, several restaurants from different cities may have variations
of the same name, and in these trials these variations would be con-
sidered a non-duplicate. However, results in the following section
will show that a combination of individual field estimates provides
an accurate approximation of overall record similarities. The com-
parison of results for learned metrics and the corresponding base-
lines shows that despite the noise, learned edit distance was able
to adjust to the notion of similarity specific for each domain, while
learned vector-space similarity improved over the standard vector-
space similarity for half the domains.
It is peculiar that the learned vector space measure made more
mistakes than unlearned cosine similarity for low recall values on
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Restaurant-name




Recall
Precision
Affine
Learned Affine
Vector space
Learned Vector space




Figure 7: Field duplicate detection results for the name field of
the Restaurant dataset




0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Restaurant-address




Recall
Precision
Affine
Learned Affine
Vector space
Learned Vector space




Figure 8: Field duplicate detection results for the address field
of the Restaurant dataset



the name and address datasets, but has outperformed it for higher
recall. We conjecture that cosine similarity was able to correctly
identify the few duplicates that were transpositions of exact matches
(e.g. `Hotel Bel-Air' and `Bel-Air Hotel', but has
failed to give sufficiently high similarity to more difficult dupli-
cates (e.g. `Art's Deli' and `Art's Delicatessen').
The SVM-trained metric, on other hand, was able to generalize
from the training examples, resulting in better similarity estimates
across a range of more difficult duplicates while penalizing some
of the "obvious" matches.
Overall, results of Table 4 show that learned affine edit distance
outperforms both non-trained edit distance and vector-space cosine
similarity for individual field duplicate detection. Visual inspection
of the learned parameter values reveals that the parameters obtained
by our training algorithm indeed capture certain domain properties
that allow more accurate similarity computations. For example, for
the address field of the Restaurant data, the lowest-cost edit opera-
tions after deleting a space are deleting 'e' and deleting 't' - which
captures the fact that a common cause of street name duplicates are
abbreviations from ``Street'' to ``Str''.

4.3.2 Record-level duplicate detection
Next, we evaluated the performance of MARLIN for multi-field
(record-level) duplicate detection. We again used the SVMlight


45

Table 4: Maximum F-measure for detecting duplicate field values
Distance metric
Restaurant name
Restaurant address
Reasoning
Face
Reinforcement
Constraint

Edit distance
0.290
0.686
0.927
0.952
0.893
0.924
Learned edit distance
0.354
0.712
0.938
0.966
0.907
0.941
Vector-space
0.365
0.380
0.897
0.922
0.903
0.923
Learned vector-space
0.433
0.532
0.924
0.875
0.808
0.913




Table 5: Maximum F-measure for duplicate detection based on
multiple fields
Metric
Restaurant
Cora

Edit distance
0.904
0.793
Learned edit distance
0.922
0.824
Vector space
0.919
0.867
Learned Vector space
0.826
0.803




0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Cora




Recall
Precision




Affine
Learned Affine
Vector Space
Learned Vector space




Figure 9: Duplicate detection results for the Cora dataset based
on author, title, venue, year and pages fields



implementation of a support vector machine as the binary classi-
fier that combines similarity estimates across the different fields to
produce the overall measure of record similarity as shown on Fig.5.
We have compared the performance of learnable and baseline
text similarity metrics for producing the similarity estimates of in-
dividual fields. Table 5 summarizes the results for the Restaurant
and Cora datasets. Again, results in bold font correspond to those
experiments in which differences between using the learned and
unlearned string metrics are significant at the 0.05 level using a 1-
tailed paired t-test. Figures 9 and 10 present the precision-recall
curves for the experiments.
From these results we can conclude that using learnable string
edit distance with affine gaps metrics to compute similarity be-
tween field values makes a positive contribution when similarities
from multiple fields are combined. Thus, better estimates of indi-
vidual field similarities result in a more accurate calculation of the
overall record similarity.
Using the SVM-based vector-space learnable similarity did not
lead to improvements over the original vector space cosine simi-
larity; performance has in fact decreased. Given that results for
field-based duplicate detection with learnable vector-space metric
were mixed, this is not surprising. We conducted additional exper-
iments where the folds were created not by assigning the equiv-
alence classes of duplicate records to folds, but by randomly as-
signing individual instances. This resulted in duplicate pairs cor-
responding to the same object being in both training and test sets
(such experiments were only possible for the Cora and Citeseer
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Restaurant




Recall
Precision




Affine
Learned Affine
Vector space
Learned Vector space




Figure 10: Duplicate detection results for the Restaurant
dataset based on name, address, city and cuisine fields



datasets since there are at most 2 duplicates per equivalence class in
the Restaurant dataset). In several of these experiments the learned
vector-space metrics outperformed the unlearned baseline. This
can be explained by the fact that the training algorithm used by
SVMlight relies on the assumption that the training data comes
from the same distribution as the test data. Separating equivalence
classes into different folds results in different token distributions for
the two sets, and the learned classifier is not suitable for producing
accurate predictions on the test data as a result.
We also ran trials which combined character-based metrics (static
and learnable string edit distance with affine gaps) and vector-space
cosine similarity. These experiments resulted in near-100% preci-
sion and recall, without significant differences between static and
adaptive field-level metrics. This demonstrates that combining char-
acter and token-based distance metrics, such as learned string dis-
tance with affine gaps and cosine similarity, is clearly an advan-
tage of the two-level learning approach implemented in MARLIN.
Current datasets did not allow us to show the benefits of adaptive
metrics over their static prototypes in this scenario, but our initial
results suggest that this can be demonstrated on more challenging
datasets.

4.3.3 Comparison of classifiers for record-level
duplicate detection
Previous work that employed classifiers to combine similarity es-
timates from multiple fields has utilized committees of decision tree
learners [22, 23]. We compared performance of support vector ma-
chines to boosted decision trees for combining similarity estimates
across the database fields to produce overall similarity of records.
We conducted experiments for two settings: some using very lim-
ited training data (30 negative and 30 positive duplicate pair ex-
amples), and using large amounts of training data (using 500 ran-
domly sampled negative pairs and up to 500 positive pairs - fewer
were available for the Restaurant dataset due to the limited num-
ber of duplicates in it). The SVMlight implementation of a support
vector machine with a radial basis function kernel was compared


46

with the WEKA package [26] implementation of alternating deci-
sion trees [8], a state-of-the-art algorithm that combines boosting
and decision tree learning. Unlearned vector-space normalized dot
product was used as the field-level similarity measure. Figs.11 and
12 illustrate the results on the Restaurant and Cora datasets.




0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1




Recall
Precision




Restaurant - ADTree
Restaurant - SVM
Cora - ADTree
Cora - SVM




Figure 11: Duplicate detection results for Restaurant and Cora
datasets using different record-level classifiers on limited train-
ing data




0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1




Recall
Precision




Restaurant - ADTree
Restaurant - SVM
Cora - ADTree
Cora - SVM




Figure 12: Duplicate detection results for Restaurant and
Cora datasets using different record-level classifiers on large
amounts of training data


These results show that support vector machines significantly
outperform boosted decision trees when training data is limited,
which is the most likely scenario for adaptive duplicate detection.
While decision trees are reliable classifiers, obtaining calibrated
confidence scores from them relies on probability estimates based
on training data statistics over the tree nodes [27]. When little train-
ing data is available, such frequency-based estimates are very un-
reliable. As a result, the confidence of the decision tree classifier
is an inaccurate measure of relative record similarity that leads to
poor accuracy in the duplicate detection process.

5. RELATED WORK
The problem of identifying duplicate records in databases was
originally identified by Newcombe [18] as record linkage in the
context of identifying medical records of the same individual from
different time periods. Fellegi and Sunter [7] developed a formal
theory for record linkage and offered statistical methods for esti-
mating matching parameters and error rates. In more recent work
in statistics, Winkler proposed using EM-based methods for obtain-
ing optimal matching rules [25]. That work was highly specialized
for the domain of census records and used hand-tuned similarity
measures.
Hern´andez and Stolfo [10] developed the sorted neighborhood
method for limiting the number of potential duplicate pairs that re-
quire distance computation, while McCallum et. al. proposed the
canopies clustering algorithm [13] for the task of matching scien-
tific citations. Monge and Elkan developed the iterative merging
algorithm based on the union-find data structure [15] and showed
the advantages of using a string distance metric that allows gaps
[14]. Cohen et. al. [3] posed the duplicate detection task as an
optimization problem, proved NP-hardness of solving the problem
optimally, and proposed a nearly linear algorithm for finding a local
optimum using the union-find data structure.
In recent work, Cohen and Richman have proposed an adaptive
framework for duplicate detection that combines multiple similar-
ity metrics [4]. Sarawagi and Bhamidipaty [22] and Tejada et. al.
[23] developed systems that employ committee-based active learn-
ing methods for selecting record pairs that are informative for train-
ing the record-level classifier that combines similarity estimates
from multiple fields across different metrics. In all of these ap-
proaches fixed-cost similarity metrics were used to compare the
database records. We have shown that learnable similarity mea-
sures can be combined with trainable record-level similarity, and
active learning techniques from prior work can be easily extended
to include the distance measures that we proposed.

6. FUTURE WORK
We have proposed a general framework for using learnable string
similarity measures in duplicate detection, and provided two algo-
rithms for character-based and vector-space based text distances.
There are several directions in which this approach can be extended.
The general classification-based framework for computing vector-
space similarity can be improved by modifying the SVM training
algorithm to avoid the overfitting issues that we encountered. The
algorithm based on iterative decomposition of the quadratic opti-
mization problem used by SVMlight needs to be extended to be
robust to differences between distributions of test data and train-
ing data. This task is similar to transduction [24, 12] because it
would require using unlabeled test data in the learning process, but
with the fundamental departure from transduction in using unla-
beled test data from a different distribution. Alternatively, the task
of learning vector-space similarity between pairs of strings can be
formalized as a parameter estimation or an optimization problem,
and investigating statistical or mathematical programming methods
that would incorporate regularization to deal with the distribution
problem is a promising avenue for improvement.
Another area for future work lies in generalizing edit distance
to include macro-operators for inserting and deleting common sub-
strings, e.g. deleting "Street" in address fields. The string distance
model with gaps would be particularly useful for this task, since
it would allow discovering useful deletion sequences by develop-
ing a stochastic model based on the gaps created when computing
minimum-cost alignments. Substructure discovery methods [5]
could also be used to identify useful edit operation sequences that
include different edit operations.

7. CONCLUSIONS
Duplicate detection is an important problem in data cleaning,
and an adaptive approach that learns to identify duplicate records


47

for a specific domain has clear advantages over static methods. Ex-
perimental results demonstrate that trainable similarity measures
are capable of learning the specific notion of similarity that is ap-
propriate for a specific domain. We presented two learnable dis-
tance measures that improve over character-based and vector-space
based metrics and allow specializing them for specific datasets us-
ing labeled examples. We have also shown that support vector ma-
chines can be effectively utilized for some datasets both for string
similarity and record similarity computations, outperforming tradi-
tional methods; we hope to improve on these initial results in our
future work. Our overall framework for duplicate detection inte-
grates previous work on adaptive methods with learnable similarity
measures, leading to improved results.

8. ACKNOWLEDGMENTS
We would like to thank Steve Lawrence for providing us the Cite-
seer datasets, Sheila Tejada for the Restaurant dataset, and William
Cohen for providing the Cora dataset. This research was supported
by the National Science Foundation under grant IIS-0117308 and a
Faculty Fellowship from IBM Corporation.


9. REFERENCES

[1] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information
Retrieval. ACM Press, New York, 1999.
[2] M. Bilenko and R. J. Mooney. Learning to combine trained
distance metrics for duplicate detection in databases.
Technical Report AI 02-296, Artificial Intelligence
Laboratory, University of Texas at Austin, Austin, TX, Feb.
2002.
[3] W. W. Cohen, H. Kautz, and D. McAllester. Hardening soft
information sources. In Proceedings of the Sixth
International Conference on Knowledge Discovery and Data
Mining (KDD-2000), Boston, MA, Aug. 2000.
[4] W. W. Cohen and J. Richman. Learning to match and cluster
large high-dimensional data sets for data integration. In
Proceedings of the Eighth ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining
(KDD-2002), Edmonton, Alberta, 2002.
[5] D. J. Cook and L. B. Holder. Substructure discovery using
minimum description length and background knowledge.
Journal of Artificial Intelligence Research, 1:231­255, 1994.
[6] R. Durbin, S. Eddy, A. Krogh, and G. Mitchison. Biological
Sequence Analysis: Probabilistic Models of Proteins and
Nucleic Acids. Cambridge University Press, 1998.
[7] I. P. Fellegi and A. B. Sunter. A theory for record linkage.
Journal of the American Statistical Association,
64:1183­1210, 1969.
[8] Y. Freund and L. Mason. The alternating decision tree
learning algorithm. In Proceedings of the Sixteenth
International Conference on Machine Learning (ICML-99),
Bled, Slovenia, 1999.
[9] D. Gusfield. Algorithms on Strings, Trees and Sequences.
Cambridge University Press, New York, 1997.
[10] M. A. Hern´andez and S. J. Stolfo. The merge/purge problem
for large databases. In Proceedings of the 1995 ACM
SIGMOD International Conference on Management of Data
(SIGMOD-95), pages 127­138, San Jose, CA, May 1995.
[11] T. Joachims. Making large-scale SVM learning practical. In
B. Sch¨olkopf, C. J. C. Burges, and A. J. Smola, editors,
Advances in Kernel Methods - Support Vector Learning,
pages 169­184. MIT Press, 1999.
[12] T. Joachims. Transductive inference for text classification
using support vector machines. In Proceedings of the
Sixteenth International Conference on Machine Learning
(ICML-99), Bled, Slovenia, June 1999.
[13] A. K. McCallum, K. Nigam, and L. Ungar. Efficient
clustering of high-dimensional data sets with application to
reference matching. In Proceedings of the Sixth International
Conference on Knowledge Discovery and Data Mining
(KDD-2000), pages 169­178, Boston, MA, Aug. 2000.
[14] A. E. Monge and C. Elkan. The field matching problem:
Algorithms and applications. In Proceedings of the Second
International Conference on Knowledge Discovery and Data
Mining (KDD-96), pages 267­270, Portland, OR, Aug. 1996.
[15] A. E. Monge and C. P. Elkan. An efficient
domain-independent algorithm for detecting approximately
duplicate database records. In Proceedings of the SIGMOD
1997 Workshop on Research Issues on Data Mining and
Knowledge Discovery, pages 23­29, Tuscon, AZ, May 1997.
[16] U. Y. Nahm and R. J. Mooney. Using information extraction
to aid the discovery of prediction rules from texts. In
Proceedings of the Sixth International Conference on
Knowledge Discovery and Data Mining (KDD-2000)
Workshop on Text Mining, Boston, MA, Aug. 2000.
[17] S. B. Needleman and C. D. Wunsch. A general method
applicable to the search for similarities in the amino acid
sequences of two proteins. Journal of Molecular Biology,
48:443­453, 1970.
[18] H. B. Newcombe, J. M. Kennedy, S. J. Axford, and A. P.
James. Automatic linkage of vital records. Science,
130:954­959, 1959.
[19] J. C. Platt. Probabilistic outputs for support vector machines
and comparisons to regularized likelihood methods. In A. J.
Smola, P. Bartlett, B. Sch¨olkopf, and D. Schuurmans,
editors, Advances in Large Margin Classifiers, pages
185­208. MIT Press, 1999.
[20] L. R. Rabiner. A tutorial on hidden Markov models and
selected applications in speech recognition. Proceedings of
the IEEE, 77(2):257­286, 1989.
[21] E. S. Ristad and P. N. Yianilos. Learning string edit distance.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 20(5), 1998.
[22] S. Sarawagi and A. Bhamidipaty. Interactive deduplication
using active learning. In Proceedings of the Eighth ACM
SIGKDD International Conference on Knowledge Discovery
and Data Mining (KDD-2002), Edmonton, Alberta, 2002.
[23] S. Tejada, C. A. Knoblock, and S. Minton. Learning
domain-independent string transformation weights for high
accuracy object identification. In Proceedings of the Eighth
ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (KDD-2002), Edmonton,
Alberta, 2002.
[24] V. N. Vapnik. Statistical Learning Theory. Wiley, 1998.
[25] W. E. Winkler. The state of record linkage and current
research problems. Technical report, Statistical Research
Division, U.S. Bureau of the Census, Wachington, DC, 1999.
[26] I. H. Witten and E. Frank. Data Mining: Practical Machine
Learning Tools and Techniques with Java Implementations.
Morgan Kaufmann, San Francisco, 1999.
[27] B. Zadrozny and C. Elkan. Obtaining calibrated probability
estimates from decision trees and naive bayesian classifiers.
In Proceedings of 18th International Conference on Machine
Learning (ICML-2001), Williamstown, MA, 2001.


48

