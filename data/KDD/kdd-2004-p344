The Complexity of Mining Maximal Frequent Itemsets and
Maximal Frequent Patterns

[Extended Abstract]

Guizhen Yang
Department of Computer Science and Engineering
University at Buffalo, The State University of New York
Buffalo, NY 14260-2000
gzyang@cse.buffalo.edu


ABSTRACT
Mining maximal frequent itemsets is one of the most fun-
damental problems in data mining. In this paper we study
the complexity-theoretic aspects of maximal frequent item-
set mining, from the perspective of counting the number of
solutions. We present the first formal proof that the problem
of counting the number of distinct maximal frequent item-
sets in a database of transactions, given an arbitrary sup-
port threshold, is #P-complete, thereby providing strong
theoretical evidence that the problem of mining maximal
frequent itemsets is NP-hard. This result is of particular in-
terest since the associated decision problem of checking the
existence of a maximal frequent itemset is in P.
We also extend our complexity analysis to other similar
data mining problems dealing with complex data structures,
such as sequences, trees, and graphs, which have attracted
intensive research interests in recent years.
Normally, in
these problems a partial order among frequent patterns can
be defined in such a way as to preserve the downward closure
property, with maximal frequent patterns being those with-
out any successor with respect to this partial order. We in-
vestigate several variants of these mining problems in which
the patterns of interest are subsequences, subtrees, or sub-
graphs, and show that the associated problems of count-
ing the number of maximal frequent patterns are all either
#P-complete or #P-hard.
Categories and Subject Descriptors
F.2.2 [Analysis of Algorithms and Problem Complex-
ity]: Nonnumerical Algorithms and Problems
General Terms
Theory
Keywords
data mining, maximal frequent itemset, maximal frequent
pattern, #P-complete, #P-hard



Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD'04, August 22­25, 2004, Seattle, Washington, USA.
Copyright 2004 ACM 1-58113-888-1/04/0008 ...$5.00.
1. INTRODUCTION
Since the introduction of the Apriori algorithm about a
decade ago [2], the field of data mining has flourished into a
research area of significant technological and social impor-
tance, with applications ranging from business intelligence
to security to bioinformatics. However, in spite of the mul-
titude of data mining algorithms developed, not much ef-
fort has been made on the theoretical frontend to study the
inherent complexity nature of data mining problems them-
selves. A thorough investigation of these fundamental prob-
lems is greatly needed since it will not only provide invalu-
able insights into many data mining problems but will also
shed new lights on the characteristics of different data min-
ing algorithms and benchmark datasets.
In this paper we seek to provide a theoretical account
of the computational difficulty of a genre of data mining
problems that deal with maximal frequent patterns. These
problems can be viewed as instances of the theory extraction
problem [10] -- they are mainly concerned with enumerat-
ing all frequent patterns (described using some language)
which satisfy some property and are present in a sufficiently
large number of transactions (records) in a database. Exam-
ples of this sort include frequent itemsets, association rules,
induced subgraphs, etc. Normally, a partial order,
, can
be defined among all frequent patterns in such a way as to
preserve the downward closure property, i.e., given any pat-
terns p1 and p2, if p1
p2 and p2 is frequent, so is p1. Hence
maximal frequent patterns are those frequent patterns that
do not have any successor with respect to this partial order.
Mining maximal frequent patterns has become an important
problem because the set of maximal frequent patterns not
only uniquely defines a theory given an interestingness cri-
terion, but the number of maximal frequent patterns can be
significantly smaller than the number of frequent patterns
as well [10].
We study the complexity of data mining problems from
the perspective of counting the number of solutions. It is
natural to assume that any algorithm which can enumerate
(compute) all (maximal) frequent patterns should be able
to count them as efficiently as well. This counting aspect
reveals the inherent complexity nature of data mining prob-
lems rather deeply -- the expected output is merely a num-
ber instead of a presentation of all solutions; and even an
exponential number only requires a polynomial number of
bits of storage space in binary notation. Therefore, given an




344
Research Track Paper

enumeration problem, its associated counting problem may
have "lower" time and/or space complexity.
We use the notion of #P-completeness as a theoretical
analysis tool to study the complexity of counting problems.
The class #P was first introduced in [22] to include all
counting problems for which any single solution can be com-
puted by a nondeterministic Turing machine in polynomial
time [8]. The notion of #P-completeness is therefore used
to capture the "hardest" problems in #P (see Section 3.2
for details). These #P-complete problems provide natural
candidates for the type of problems that may still remain
intractable even if P=NP [8], since under this computation
model, an "efficient" algorithm for solving a #P-complete
problem would behave as if it could, by magic, guess the ex-
act number of correct solutions and simultaneously validate
all of them in polynomial time.1
Our theoretical investigation begins with the problem of
mining maximal frequent itemsets -- one of the most fun-
damental problems studied in data mining [28, 10, 15, 5,
1, 7, 9]. We present the first formal proof (see Section 4)
that the problem of counting the number of maximal fre-
quent itemsets in a database of transaction, given an arbi-
trary support threshold, is #P-complete, thereby providing
strong theoretical evidence that the problem of mining max-
imal frequent itemsets is NP-hard, i.e., intractable in the
worst case. Since the existence of a maximal frequent item-
set can be checked in polynomial time, this result identifies
the problem of counting the number of maximal frequent
itemsets as one of the few known counting problems whose
associated decision problems are "easy", i.e., belong to P.
Note that number of maximal frequent itemsets can be
exponentially smaller than the number of frequent item-
sets [28, 10]. In contrast to mining frequent itemsets, several
algorithms have been shown to be able to gain computa-
tional efficiency substantially for mining maximal frequent
itemsets [28, 10, 15, 5, 1, 7, 9]. Given that the problem
of counting the number of frequent itemsets has also been
shown to be #P-complete [10], our new complexity result
implies a rather unexpected analogy: the problem of mining
maximal frequent itemsets is of as great worst-case com-
putational complexity as the problem of mining frequent
itemsets.
Having established the #P-completeness of the counting
problem for maximal frequent itemsets, we also extend our
complexity analysis to other similar problems that deal with
complex data structures, such as sequences [3, 25], trees [26,
4, 24], and graphs [12, 13], which have attracted intensive
research interests in recent years.
We investigate several
variants of these mining problems in which the patterns of
interest are subsequences, subtrees, or subgraphs, and show
that their associated problems of counting the number of
maximal frequent patterns are all either #P-complete or
#P-hard (our complexity results are summarized in Table 2).
The rest of this paper is organized as follows. Section 2 in-
troduces the basic concepts and notions to be used through-
out this paper.
In Section 3 we introduce the theory of
#P-completeness. Section 4 presents our formal proof that
the problem of counting the number of maximal frequent
itemsets is #P-complete. The complexity results concerning
other maximal frequent patterns, including subsequences,
subtrees, and subgraphs, are presented Section 5. Finally,

1
All the complexity results presented in this paper should
be interpreted as worst-case time complexity.
we discuss related work in Section 6 and conclude this paper
in Section 7.


2. PRELIMINARIES
In this section we introduce the important concepts and
notations that will be used throughout the paper. First we
describe how to represent databases using bipartite graphs
and binary matrices (see [27] for a more detailed survey).
Then we formalize several notions of itemsets with different
support characteristics. Table 1 summarizes the notations
that will be used in this paper and their meaning.

D a database of transactions
I
an itemset
tid
transaction identifier
|S| the cardinality of a set S
D(I)
all transactions in database D that contain I
fD(I)
the support of I in database D
F(D)
all -frequent itemsets in database D
M(D)
all maximal -frequent itemsets in database D
C(D)
all maximal -occurrent itemsets in database D



Table 1: Summary of Notations and Their Meaning


2.1 Databases and Itemsets
A database comprises a set of transactions. Each transac-
tion has a unique transaction identifier (tid) and contains a
set of items. For simplicity we will normally omit the tid of
a transaction and just list the set of items that it contains.
A set of items is often called an itemset. Let I be an itemset
and t a transaction. We will use the notation, I  t, to
denote that I is a subset of the set of items that t contains.
When the context is clear, we will often directly refer to a
transaction as the set of items that it contains.
Given a set S, we will use the notation, |S|, to denote the
cardinality of S, i.e., the number of elements in S. Let I be
an itemset and D a database of transactions. We will use
the notation, D(I), to represent the set of transactions of D
that are a superset of I, i.e., D(I)
def
= {t | I  t, t  D}.

2.2 Bipartite Graphs and Binary Matrices
A bipartite graph, G, can be represented as a triple, G =
(U, V, E), where U and V are disjoint sets of vertices and
E is the set of edges between vertices in U and V such that
E  U × V .
A bipartite graph G = (U, V, E) is called a bipartite clique
if there is an edge between every pair of vertices in U and V ,
i.e., E = U × V . Usually we will omit the set of edges when
we represent a bipartite clique. Given a bipartite clique, G =
(U, V ), where |U| = m and |V | = n, we will call it a bipartite
(m, n)-clique, or a bipartite (m, )-clique (if the cardinality
of V is of no importance), or a bipartite (, n)-clique (if the
cardinality of U is of no importance).
We will say that a bipartite graph, G = (U , V , E ), ap-
pears in another bipartite graph, G = (U, V, E), if U

U, V
 V,E  E. Of particular interest are those bipar-
tite cliques that appear in a given bipartite graph. We will
say that a bipartite clique, G = (U , V ), is a maximal bi-
partite clique in a given bipartite graph G, if G appears in
G and there exists no other bipartite clique, G = (U ,V
),
in G such that U  U
and V
 V
.



345
Research Track Paper

One can easily establish a one-to-one correspondence be-
tween bipartite graphs and databases of transactions. Given
a database D, its corresponding bipartite graph, denoted
GD = (U,V,E), can be constructed as follows: U comprises
all database transactions in D; V comprises all items ap-
pearing in D; for all u  U, v  V , (u, v)  E iff v  u, i.e.,
transaction u contains item v. Given a a bipartite graph
G, we will use DG to denote its corresponding database of
transactions.
A binary matrix is a matrix in which each entry has value
either 0 or 1. A one-to-one correspondence between binary
matrices and databases of transactions can also be estab-
lished rather straightforwardly.
Given a database D, we
number its transactions as t1, t2, ··· , tm (corresponding to
rows 1 to m of a matrix) and all the items as x1, x2, ··· , xn
(corresponding to columns 1 to n of a matrix). Then D cor-
responds to an m×n matrix, denoted AD, in which its entry
aij has value 1 iff transaction ti contains item xj; otherwise,
its value is 0. Given a binary matrix A, we will use DA to
denote its corresponding database of transactions.

Example 1 Consider a database D that consists of the
following transactions, t1, t2, t3, t4, t5, where t1 = {x1, x2},
t2 = {x1, x2, x3}, t3 = {x1, x2, x3, x4}, t4 = {x3, x4}, t5 =
{x3,x4}. Here x1,x2,x3,x4 denote different items in D. The
corresponding bipartite graph, GD, and binary matrix, AD,
are illustrated in Figures 1 and 2, respectively.
2

 ¡x
1
¢£x
2
¤¥x
3
¦§¦¨x
4



©
t 1

t 2

t 3

t 4

t 5
§§
§§
§§
§§
§§
§§
§§
§§
§§

§§
§§
§§
§§
§§
§§
§§
§§
§§

!§!§!§!§!
!§!§!§!§!
!§!§!§!§!
!§!§!§!§!
!§!§!§!§!
!§!§!§!§!
!§!§!§!§!
!§!§!§!§!
"§"§"§"
"§"§"§"
"§"§"§"
"§"§"§"
"§"§"§"
"§"§"§"
"§"§"§"
"§"§"§"
#§#
#§#
#§#
#§#
#§#
#§#
#§#
#§#
#§#

$§$
$§$
$§$
$§$
$§$
$§$
$§$
$§$
$§$

%§%
%§%
%§%
%§%
%§%
%§%
%§%
%§%
&§&
&§&
&§&
&§&
&§&
&§&
&§&
&§&
'§'§'§'§'§'
'§'§'§'§'§'
'§'§'§'§'§'
'§'§'§'§'§'
'§'§'§'§'§'
'§'§'§'§'§'
'§'§'§'§'§'
'§'§'§'§'§'
(§(§(§(§(
(§(§(§(§(
(§(§(§(§(
(§(§(§(§(
(§(§(§(§(
(§(§(§(§(
(§(§(§(§(
(§(§(§(§(
)§)§)§)§)
)§)§)§)§)
)§)§)§)§)
)§)§)§)§)
)§)§)§)§)
)§)§)§)§)
)§)§)§)§)
)§)§)§)§)
0§0§0§0
0§0§0§0
0§0§0§0
0§0§0§0
0§0§0§0
0§0§0§0
0§0§0§0
0§0§0§0

1§1
1§1
1§1
1§1
1§1
1§1
1§1
1§1
1§1

2§2
2§2
2§2
2§2
2§2
2§2
2§2
2§2
2§2
3§3
3§3
3§3
3§3
3§3
3§3
3§3
3§3
4§4
4§4
4§4
4§4
4§4
4§4
4§4
4§4
5§5§5§5§5§5
5§5§5§5§5§5
5§5§5§5§5§5
5§5§5§5§5§5
5§5§5§5§5§5
5§5§5§5§5§5
5§5§5§5§5§5
5§5§5§5§5§5
6§6§6§6§6
6§6§6§6§6
6§6§6§6§6
6§6§6§6§6
6§6§6§6§6
6§6§6§6§6
6§6§6§6§6
6§6§6§6§6
7§7§7
7§7§7
7§7§7
7§7§7
7§7§7
7§7§7
7§7§7
7§7§7
8§8§8
8§8§8
8§8§8
8§8§8
8§8§8
8§8§8
8§8§8
8§8§8
9§9
9§9
9§9
9§9
9§9
9§9
9§9
9§9
@§@
@§@
@§@
@§@
@§@
@§@
@§@
@§@
A§A§A§A§A
A§A§A§A§A
A§A§A§A§A
A§A§A§A§A
A§A§A§A§A
A§A§A§A§A
A§A§A§A§A
A§A§A§A§A
B§B§B§B§B
B§B§B§B§B
B§B§B§B§B
B§B§B§B§B
B§B§B§B§B
B§B§B§B§B
B§B§B§B§B
B§B§B§B§B
C§C§C
C§C§C
C§C§C
C§C§C
C§C§C
C§C§C
C§C§C
C§C§C
D§D
D§D
D§D
D§D
D§D
D§D
D§D
D§D



Figure 1:
Bipartite Graph Representation of the
Database in Example 1


x1
x2
x3
x4
t1
1
1
0
0
t2
1
1
1
0
t3
1
1
1
1
t4
0
0
1
1
t5
0
0
1
1


Figure 2:
Binary Matrix Representation of the
Database in Example 1

In the sequel, we will use either binary matrices or bipar-
tite graphs to represent databases of transactions.
2.3 Support and Maximality
Classical Data mining problems are usually concerned with
itemsets that frequently occur in a database of transactions.
The number of occurrences of an itemset in a database is
commonly referred to as the support of this itemset, formal-
ized as follows.2
2
The support of an itemset can be also defined as the per-
centage of transactions that are a superset of it. For conve-
nience here we use an integer value to define the support of
an itemset, since it can always be computed by multiplying
the percentage number by the total number of transactions.
Definition 1 (Support) Let I be an itemset and D a
database of transactions. The support of I in D, denoted
fD(I), is the number of transactions of D in which I occurs
as a subset, i.e., fD(I)
def
= |D(I)|.


Lemma 1 Let D be a database of transactions, I and J two
itemsets. If I  J, then D(I)  D(J) and fD(I)  fD(J).

Note that even if two database transactions contain the
same set of items they are still different from each other,
since each transaction has its own unique tid. Therefore,
they will each contribute one count towards the support of
an itemset that they contain.


Definition 2 (-Occurrent Itemset) For   1, we will
say that an itemset I is -occurrent in a database D, if the
support of I in D is , i.e., fD(I) = .


Definition 3 (-Frequent Itemsets) For 1    |D|,
an itemset I is called -frequent in a database D, if fD(I) 
, i.e., the support of I in D is at least .


Lemma 2 Let D be a database of transactions, I and J
two itemsets. If I  J and both I and J are -occurrent
itemsets, then D(I) = D(J).

In the sequel, when we discuss properties of itemsets with
respect to a database D, for simplicity we will usually omit
the database D, especially when D is fixed or its existence
is clear from the context.
Having defined the notion of -frequent itemsets, now we
can formally state the problem of mining frequent itemsets
as follows: Given a database of transactions D and an arbi-
trary integer value  such that 1    |D|, enumerate all
-frequent itemsets in D.
We should point out the difference between -occurrent
and -frequent itemsets. If an itemset is -occurrent, then
its support must be exactly . The support of a -frequent
itemset, however, can be any value greater than or equal
to . Clearly, if an itemset is -frequent, then it must be
-occurrent for some   .


Example 2 Consider again the database D in Example 1.
Its corresponding bipartite graph and binary matrix rep-
resentations are illustrated in Figures 1 and 2, respectively.
One can easily validate the following: {x2, x3} is a 2-occurrent
itemset (D({x2, x3}) = {t2, t3}); {x1, x2} is a 3-occurrent
and 2-frequent itemset (D({x1, x2}) = {t1, t2, t3}).
2

If we consider subset inclusion as defining a partial order
for itemsets, then we can introduce the notions of maximal
-occurrent and maximal -frequent itemsets, as follows.


Definition 4 (Maximal -Occurrent Itemsets) Let
I
be a -occurrent itemset in a database D. We say that I
is a maximal -occurrent itemset in D, if there exists no
itemset J such that J  I and J is -occurrent in D.3

3
A maximal -occurrent itemset is essentially a frequent
closed itemset with support  [23], if  is not less than the
support threshold. This explicit notation will be handy for
our complexity analysis.



346
Research Track Paper

Definition 5 (Maximal -Frequent Itemsets) Let I be
a -frequent itemset in a database D. We say that I is a
maximal -frequent itemset in D, if there exists no itemset
J such that J  I and J is -frequent in D.

Now that we have introduced maximal -frequent item-
sets, we can formally state the problem of mining maximal
frequent itemsets as follows: Given a database of transac-
tions D and an arbitrary integer value  such that 1   
|D|, enumerate all maximal -frequent itemsets in D.
One can easily see that if an itemset I is -frequent, then
any (nonempty) subset J  I is also -frequent. On the
other hand, if J  I is not -frequent, then I cannot be
-frequent either. Note that once all the maximal -frequent
itemsets have been computed, then all the -frequent item-
sets can be directly enumerated from them without having
to read from the database any more. Conceptually the in-
formation about -frequent itemsets can be "summarized"
using maximal -frequent itemsets -- the number of max-
imal -frequent itemsets can be significantly smaller than
the number of -frequent itemsets.
Note that if I is a -occurrent itemset, it does not nec-
essarily mean that any subset J  I is also -occurrent. It
must be true, however, that J is -occurrent for some   .
The notion of maximal occurrent itemsets plays an im-
portant role in our complexity analysis of mining maximal
frequent itemsets. In the following Section 4 we will develop
lemmas to establish several connections between maximal
occurrent and maximal frequent itemsets. The following ex-
ample illustrates the idea of maximal -occurrent and max-
imal -frequent itemsets.


Example 3 Continue with the previous database example
in Example 1. One can easily validate the following: {x2, x3}
is a 2-occurrent itemset but not maximal, since {x1, x2, x3}
is also a 2-occurrent itemset; {x1, x2, x3} is a maximal
2-frequent itemset; {x1, x2} is a maximal 3-occurrent item-
set but not a maximal 2-frequent itemset; {x3, x4} is a max-
imal 3-occurrent and maximal 2-frequent itemset.
2

Let D be a database and GD its corresponding bipartite
graph. In Section 2.2 we show that there is a one-to-one
correspondence between bipartite graphs and databases of
transactions. In fact, there is also a one-to-one correspon-
dence between maximal occurrent itemsets in D and max-
imal bipartite cliques in GD. Their relationship is formally
stated in the following lemma.

Lemma 3 Let D be a database of transactions and GD the
bipartite graph corresponding to D. Then every maximal
-occurrent itemset in D corresponds to a unique maximal
bipartite (, )-clique in GD.

Example 4 Consider the bipartite graph shown in Figure 1
which corresponds to the database in Example 1. Note that
{x1,x2} is a maximal 3-occurrent itemset and corresponds
to the unique bipartite (3, 2)-clique, ({t1, t2, t3}, {x1, x2}),
in Figure 1.
2

3. THEORETICAL FOUNDATIONS
Most data mining problems espouse two different but in
fact closely related perspectives: enumeration of all solutions
and counting the number of solutions. In this section we will
first discuss the counting aspect of the problem of mining
maximal frequent itemsets and then introduce the notion of
#P-completeness as a complexity analysis tool for the class
#P of counting problems.

3.1 Enumeration vs. Counting
The problem of mining maximal frequent itemsets, as for-
mally defined in Section 2.3, is to enumerate all maximal
frequent itemsets whose support is no less than a preset
threshold. A natural question that one may ask is: What
is the (worst-case) computational complexity of enumerating
all maximal frequent itemsets?
Since all the maximal frequent itemsets must be enumer-
ated, clearly the computational cost must be proportional
to at least the number of all maximal frequent itemsets. So
it is natural to ask the following question: Is the number of
maximal frequent itemsets always polynomial in the size of
the database? 4
Unfortunately the answer to the question above turns
out to be "No".
In the following example we will show
a database of transactions with an exponential number of
maximal frequent itemsets at a certain support threshold.


Example 5 Let X = {x1, x2, ··· , x2n
-1
, x2n} denote a set
of 2n items. We will construct a database D with 2n trans-
actions, t1, t2, ··· , t2n
-1
, t2n, as follows: ti = X - {xi} for
all 1  i  2n, i.e., transaction ti comprises all the items
in X except item xi. Now we can claim that the number
of maximal n-frequent itemsets in D is exactly
`2n
n
´.
To
see why, first we can show that for any itemset I  X,
D(I) = {ti |xi  I,xi  X}. It follows that if |I| = k then
fD(I) (the support of I in D) is exactly 2n-k. Therefore any
itemset I must be maximal n-frequent iff |I| = n, since for
any itemset J, if J  I then it must be true that fD(J) < n.
Clearly, there are exactly
`2n
n
´
number of different itemsets
of size n. So the number of maximal n-frequent itemsets is
`2n
n
´.
The size of D is O(n2). Moreover,
`2n
n
´
=
(2n)!
n!·n!
 2n.
Hence the number of maximal n-frequent itemsets in D is
exponential in the size of D.
2

Example 5 above provides a strong indication that no al-
gorithm can efficiently enumerate all maximal frequent item-
sets in the worst case, given an arbitrary support threshold.
The reason is just downright straightforward -- the num-
ber of maximal frequent itemsets may be exponential in the
worst case -- one would just need to spend at least an ex-
ponential amount of time to "print" them out, let alone the
additional cost to "compute" them!
However, the argument above is still not convincing enough.
First, it does not constitute a formal proof that the prob-
lem of mining (enumerating) all maximal frequent itemsets
is "hard". Second, one may, albeit arguably, claim that only
"printing" but not "computing" of all the maximal frequent
itemsets takes an exponential amount of time -- an algo-
rithm smart enough might be able to "compute" and "com-
press" all maximal frequent itemsets using some efficient
data structure in polynomial time. Indeed, such discrepancy
between "printing" and "computing" is not uncommon. For

4
Here we will use the size of its corresponding binary ma-
trix (number of entries) to refer to the size of a database.
Although in practice this is not the most efficient way of
storing data, such generalization does not affect our com-
plexity analysis.



347
Research Track Paper

instance, it takes quadratic time to print out all the suffixes
of a string; but an efficient data structure, the so-called suf-
fix tree, can be constructed in linear time which encodes all
the suffixes of a given string [20].
Note that if an algorithm can enumerate all maximal fre-
quent itemsets then it should be able to count them also.
This counting aspect of data mining problems is important
because in contrast to enumeration, the associated counting
problem might have "lower" complexity. In fact, an expo-
nential number requires only a polynomial number of bits to
store. For instance, the number
`2n
n
´
needs just O(n log2 n)
bits to encode in binary notation. Moreover, arithmetic op-
erations, such as addition, subtraction, multiplication, divi-
sion, etc., only take a polynomial (in the sizes of the two
operands) number of steps to finish.
Therefore, if an al-
gorithm is claimed to be able to "compute" all maximal
frequent itemsets in polynomial time, then it is natural to
assume that it should be able to count them as efficiently as
well; otherwise, such a claim is not justified.
In light of this intrinsic connection between computing
and counting, from now on we will focus on the counting
aspect of data mining problems. First we revise our original
problem definition accordingly as follows: Given a database
of transactions D and an arbitrary integer value  such that
1    |D|, count the number of all maximal -frequent
itemsets in D. In the rest of this paper, we will develop the-
orems to show that the "easier" counting problem above is
in fact computationally difficult, thereby presenting a formal
proof that its associated problem of enumerating (comput-
ing) all solutions is hard.

3.2 The Complexity of Counting
The theory of NP-completeness is mainly concerned with
decision problems asking about the existence of a solution.
On the contrary, whereas enumeration problems require ex-
plicit output of all solutions, counting problems need to cal-
culate the number of solutions only.5 Clearly, if a decision
problem is NP-complete, then its associated enumeration or
counting problem must be NP-hard, because being able to
enumerate all solutions or knowing the number of solutions
is enough to answer the question of whether there is one.
The class #P of counting problems was first introduced
by Valiant to give a complexity-theoretic characterization of
the computational difficulty of counting [22]. Here we follow
the same definitions as in [22].


Definition 6 (Counting Turing Machines) A counting
Turing machine is a standard nondeterministic Turing ma-
chine with an auxiliary output device that (magically) prints
in binary notation on a special tape the number of accept-
ing computations induced by the input. It has (worst-case)
time complexity f(n) if the longest accepting computation
induced by the set of all inputs of size n takes f(n) steps
(when the Turing machine is regarded as a standard nonde-
terministic machine without the auxiliary device).


Definition 7 (#P) A counting problem belongs to #P if
this problem can be solved by a counting Turing machine of
polynomial time complexity.

5
Note that the counting problems we describe here are
termed as enumeration problems in [8]. But we follow the
terminology in [16].
A problem is said to be #P-hard if all problems in #P
reduce to it. Note that the notion of reduction used here is
polynomial time Turing reduction (or simply Turing reduc-
tion; see [8] and [22] for more details). More specifically, a
Turing reduction from one problem  to another problem 
is an algorithm that solves  using a hypothetical oracle for
solving  such that, if this oracle solves  in polynomial
time, then the overall algorithm would be a polynomial-time
algorithm for .
Just as the concept of NP-completeness is introduced for
the "hardest" problems in NP, #P-completeness is used to
capture the notion of the "hardest" problems in #P. For-
mally, we have the following definition.


Definition 8 (#P-Completeness) A counting problem is
called #P-complete if all problems in #P Turing reduce to
it and it belongs to #P.

It is easy to see that #P is the set of counting prob-
lems naturally associated with the decision problems in NP.
Therefore, for NP-complete problems, their associated count-
ing problems are #P-complete6 -- the hardness of count-
ing the number of solutions for such problems originates
from the computational difficulty of searching for just one!
For instance, the problem of counting the number of satis-
fying truth assignments for an arbitrary 3CNF formula is
#P-complete [8].
However, there are very hard counting problems whose as-
sociated decision problems can actually be solved in polyno-
mial time. The first such problem was proved by Valiant [22]
-- the problem of counting the number of perfect matchings
in a bipartite graph is #P-complete. In the following Sec-
tion 4 we will show that the problem of counting the number
of maximal frequent itemsets falls into this same category.
Clearly, if a counting problem is #P-complete or #P-hard,
then its associated problem of enumerating (mining) all so-
lutions must be NP-hard [8, 16].

4. COMPLEXITY ANALYSIS
In this section we will present a formal proof that the
problem of counting the number of maximal frequent item-
sets is #P-complete. First we introduce the new notations
to be used here.
Let D be a database of transactions. We will use the no-
tation F(D) to denote the set of all -frequent itemsets,
M(D) to denote the set of all maximal -frequent item-
sets, and C(D) to denote the set of all maximal -occurrent
itemsets.
Since our focus is on the number of maximal frequent
itemsets, it is important to see how this number changes
with respect to different support thresholds. We will begin
with the number of frequent itemsets.


Lemma 4 If  > , then F(D)  F(D).

From the lemma above, we can immediately infer that if
 > , then |F(D)|  |F(D)|, i.e. the number of frequent
itemsets decreases with increase in support thresholds. How-
ever, this nice antimonotonicity property of frequent item-

6
Strictly speaking, this claim is still a conjecture. But the
associated counting problems of many known NP-complete
problems have been formally proved to be #P-complete.



348
Research Track Paper

sets does not hold for maximal frequent itemsets in general,
as illustrated by the example below.


Example 6 Consider the database D that is shown in Fig-
ure 1. We have the following maximal frequent itemsets at
different support thresholds.

M1(D)
=
{{x1,x2,x3,x4}}
M2(D)
=
{{x1,x2,x3},{x3,x4}}
M3(D)
=
{{x1,x2},{x3,x4}}
M4(D)
=
{{x3}}

So |M1(D)| = 1, |M2(D)| = 2, |M3(D)| = 2, |M4(D)| = 1.
Clearly, the aforementioned antimonotonicity property does
not hold here.
2

From the example above, we can see that maximal fre-
quent itemsets behave rather "randomly" and this adds much
difficulty to our search of a complexity-theoretic characteri-
zation for them. Next we need to establish lemmas to reveal
the connections between maximal frequent and maximal oc-
current itemsets.
Our final formal proof builds on these
lemmas.


Lemma 5 Let I and J be two different maximal -occurrent
itemsets in a database D. Then neither I nor J is a subset
of the other, i.e., I  J and J  I.


Proposition 6 Let I be a maximal -occurrent itemset and
J a maximal -occurrent itemset in a database D. If I  J,
then  > .


Lemma 7 If I is a maximal -frequent itemset in a database
D and fD(I) = , then I is a maximal -occurrent itemset.


Proposition 8 If I is a maximal -occurrent itemset in a
database D, then I is a maximal -frequent itemset in D.


Proposition 9 Let D be a database of transactions. Then
M(D)  C(D) and |M(D)|  |C(D)|.
Furthermore,
M(D) 
S|D|
i=
Ci(D) and |M(D)| 
P|D|
i=
|Ci(D)|.

Note that Proposition 9 above gives an upper bound on
the number of maximal frequent itemsets.
However, the
claim in Proposition 9 does not always hold with equality,
as illustrated by the example below.


Example 7 Consider the database D in Figure 1. We have
the following different categories of itemsets.

M1(D)
=
{{x1,x2,x3,x4}}
M2(D)
=
{{x1,x2,x3},{x3,x4}}
C1(D)
=
{{x1,x2,x3,x4}}
C2(D)
=
{{x1,x2,x3}}
C3(D)
=
{{x1,x2},{x3,x4}}
C4(D)
=
{{x3}}
C5(D)
=


Clearly, |M1(D)| = 1 but
P|D|
i=1
|Ci(D)| = 5; |M2(D)| = 2
but |C2(D)| = 1 and
P|D|
i=2
|Ci(D)| = 4.
2
We will now present our proof that the problem of count-
ing the number of maximal frequent itemsets is #P-complete.
We will reduce the problem of counting the number of max-
imal bipartite cliques in a bipartite graph, which has been
shown to be #P-complete, to the problem of counting the
number of maximal frequent itemsets in a database of trans-
actions.


Theorem 10 ([18]) The problem of counting the number
of maximal bipartite cliques in a given bipartite graph is
#P-complete.7


Corollary 11 Let D be a database of transactions. It is a
#P-complete problem to count the number
P|D|
=1
|C(D)|.8



x1
x2
··· xn
y1
y2
··· ym


WR
D
8
>
>
>
<
>
>
>
:
r1
1
1
···
1
r2
1
1
···
1
...
D
...
...
···
...
rm
1
1
···
1


WS
D
8
>
>
>
<
>
>
>
:
s1
1
1
···
1
0
1
···
1
s2
1
1
···
1
1
0
···
1
...
...
...
···
...
...
sm
1
1
···
1
1
1
···
0


Figure 3: Database Transformation Scheme

Let D be a database of transactions. First we transform D
to a new database WD as follows. Let T = {t1, t2, ··· , tm}
be the set of transactions of D, where m = |D|, and X =
{x1,x2,··· ,xn} the set of all items appearing in D. We will
introduce a set, Y = {y1, y2, ··· , ym}, of m new items into
WD. The new database WD is the union of two databases,
WR
D
= {r1, r2, ··· , rm}, and WS
D
= {s1, s2, ··· , sm}. The
transactions of WR
D
and WS
D
are constructed as follows:
(i) ri = ti  Y for all 1  i  m, i.e., the transactions of
WR
D
are obtained by extending each transaction in T with
the entire set Y of new items; (ii) si = X  (Y - {yi}) for
all 1  i  m, i.e., each transaction si of WS
D
contains all
the items in X and Y except item yi. This transformation
is illustrated schematically in Figure 3. Note that we can
establish a one-to-one correspondence between transactions
in R and T . Clearly, if the size of D is O(d), then the size
of WD is O(d2).


Example 8 The database shown in Figure 4 is transformed
from the database shown in Figure 2.
2


Lemma 12 Let D be a database of transactions, WD =
WR
D
WS
D
the new database transformed from D, X the set
of items appearing in D, Y the set of new items introduced
into WD. Then for all I, J  X and Yk, Yz  Y :
Yk = Yz
iff WS
D
(I  Yk) = WS
D
(J  Yz).

7
This result is not explicitly stated in [18], but follows read-
ily from the results and reductions in [18]. Note that al-
though a similar claim is also made in [14], the proof pre-
sented in [14] is not correct.
8
This is in fact the number of all closed itemsets in D [23].



349
Research Track Paper

x1
x2
x3
x4
y1
y2
y3
y4
y5
r1
1
1
0
0
1
1
1
1
1
r2
1
1
1
0
1
1
1
1
1
r3
1
1
1
1
1
1
1
1
1
r4
0
0
1
1
1
1
1
1
1
r5
0
0
1
1
1
1
1
1
1
s1
1
1
1
1
0
1
1
1
1
s2
1
1
1
1
1
0
1
1
1
s3
1
1
1
1
1
1
0
1
1
s4
1
1
1
1
1
1
1
0
1
s5
1
1
1
1
1
1
1
1
0


Figure 4: The New Database Transformed from the
One in Figure 2


Proposition 13 Let D be a database of transactions, |D| =
m, WD = WR
D
 WS
D
the new database transformed from
D, X the set of items appearing in D, and Y the set of
new items introduced into WD.
If I  X is a maximal
( + k)-occurrent itemset in D, where 1    m, 0 
k  m - , then I  Yk is a maximal ( + m)-occurrent and
maximal ( + m)-frequent itemset in WD, where Yk is an
arbitrary itemset such that Yk  Y and |Yk| = k.


Proposition 14 Let D be a database of transactions, |D| =
m, WD = WR
D
WS
D
the new database transformed from D,
X the set of items appearing in D, Y the set of new items
introduced into WD, U = I  Yk, where I  X, Yk  Y ,
|Yk| = k. If U is a maximal ( + m)-frequent itemset in
WD, where 1    m, then 0  k  m -  and I is a
maximal ( + k)-occurrent itemset in D. Moreover, U is a
maximal ( + m)-occurrent itemset in WD.

Proposition 15 Let D be a database of transactions, |D| =
m, WD the new database transformed from D, and 1   
m. Then U is a maximal ( + m)-frequent itemset in WD
iff U is a maximal ( + m)-occurrent itemset in WD.

Proposition 16 Let D be a database of transactions, |D| =
m, WD the new database transformed from D. Then for all
1    m:


|M
+m
(WD)| =
m-
X
k=0
|C
+k
(D)| ·
m
k
!


Theorem 17 Let D be a database of transactions, |D| =
m.
The problem of counting the number of all maximal
-frequent itemsets in D, where 1    m, is #P-complete.

Proof.
Checking whether an itemset is maximal fre-
quent or not can be done in polynomial time. Therefore,
the problem of counting the number of maximal frequent
itemsets is in #P. We know that the problem of counting
the number
Pm
=1
|C(D)| is #P-complete, by Corollary 11.
We will show how this counting problem can be Turing re-
duced to the problem of counting the number of maximal
frequent itemsets, thereby proving that the latter problem
is #P-hard.
First, we transform the database D into its corresponding
new database WD. We will assume binary matrix represen-
tation for databases. Therefore, if the size of D is O(d),
then the size of WD is O(d2), and the running time of the
transformation algorithm is also O(d2).
Let C = |C(D)|, M = |M
+m
(WD)|, for 1   
m. Then by Proposition 16, we can construct the following
linear equations, represented in matrix notation:

0
B
B
B
B
B
B
B
B
B
@
1
`m
1
´ `m
2
´
···
`
m
m-1
´
0
1
`m
1
´
···
`
m
m-2
´
0
0
1
···
`
m
m-3
´
...

0
0
0
···
1
1
C
C
C
C
C
C
C
C
C
A
·
0
B
B
B
B
B
B
B
B
B
@
C1

C2

C3
...

Cm
1
C
C
C
C
C
C
C
C
C
A
=
0
B
B
B
B
B
B
B
B
B
@
M1

M2

M3
...

Mm
1
C
C
C
C
C
C
C
C
C
A
Clearly, the linear equations above have a unique solution
for (C1, C2, ··· , Cm), given the values of (M1, M2, ··· , Mm).
For all 0  k  m-1,
`m
k
´
 mm and so
`m
k
´
can be stored
using O(m log2 m) bits in binary notation and computed in
time polynomial in m. Let the size of D be O(d). Then
m = O(d) and so all
`m
k
´
can be stored using O(d log2 d) bits
in binary notation and computed in time polynomial in d.
For all 1    m, C = |C(D)| = O(2d). So all C can be
stored using O(d) bits in binary notation. Moreover, the size
of WD is O(d2) and so M = |M
+m
(WD)| = O(2d2) for all
1    m. It follows that all M can be represented using
O(d2) bits in binary notation. Therefore, given the values of
(M1, M2, ··· , Mm), the linear equations above can be solved
and hence the values of (C1, C2, ··· , Cm) can be calculated
in time polynomial in d, the size of D. Note that the size
of WD is O(d2). So if there is a polynomial-time algorithm
for counting the number of maximal frequent itemsets, then
the values of (M1, M2, ··· , Mm) can be computed in time
polynomial in d. Hence the values of (C1, C2, ··· , Cm) and
the number
Pm
=1
|C(D)| =
Pm
=1
C can be computed in
time polynomial in d.
2

5. MAXIMAL FREQUENT PATTERNS
A large number of data mining problems dealing with fre-
quent patterns can be viewed as instances of the theory ex-
traction problem [10].
In general, every transaction in a
database D is considered as a (large) pattern.
A partial
order,
, can be defined on all patterns such that the sup-
port of a pattern p can be formalized as follows: fD(p)
def
=
|{t|p
t, t  D}|.9 A pattern whose support exceeds a user-
specified threshold is called a frequent pattern. Note that
this partial order,
, preserves the downward closure prop-
erty, i.e., given any patterns p1 and p2, if p1
p2 and p2
is frequent, so is p1. We will write p1
p2 if p1
p2 and
p1 = p2. Hence a frequent pattern p is maximal if there is
no frequent pattern q such that p
q.
Many problems of mining maximal frequent patterns fall
into this line of generalization above. For example, in the
problem of mining maximal frequent itemsets, the patterns
are sets of items and the partial order is defined on sub-
set inclusion. In this section, we will extend our complex-
ity analysis to several problems of mining maximal frequent

9
This kind of support is called unweighted support, in which
every database transaction contributes at most one count
to the supported of a pattern.
However, our complexity
results can be easily extended to data mining problems that
use weighted support [24], which takes into account multiple
occurrences of a pattern in a database transaction.



350
Research Track Paper

patterns studied recently in the literature, in which the pat-
terns of interest are subsequences, subtrees, or subgraphs.
In the following, we will just define the data structures used
in these problems and specify the partial orders on patterns.
Support and maximality of patterns will be defined in the
same way as in Section 2.3. Our goal is to show the complex-
ity of the associated counting problems for these maximal
frequent patterns.

5.1 Subsequences
In problems of mining frequent sequences [3, 25], each
database transaction is considered as a sequence (string) in-
stead of a set, in which the order of symbols appearing in
this sequence is important.
Normally the patterns of in-
terest are subsequences. The partial order,
, on any two
sequences, s1 and s2, is defined as follows: s1
s2 iff s1
is a subsequence of s2, i.e., s1 can be obtained from s2 by
removing zero or more symbols from s2. For example, ac
is a subsequence of abc. Our complexity result about min-
ing maximal frequent subsequences is stated in Theorem 18
below.


Theorem 18 Let D be a database of sequences, |D| = m.
The problem of counting the number of maximal -frequent
subsequences in D, where 1    m, is #P-complete.

5.2 Subtrees and Subgraphs
In recent years mining frequent patterns from trees [26,
4, 24] and graphs [12, 13] has attracted a lot of research
interests.
Normally, the patterns of interest are subtrees
or subgraphs.
Note that trees are just a special form of
connected, acyclic graphs. A graph, G = (V, E), consists
of a set of vertices, V , and a set of edges, E  V × V .
Subgraph isomorphism can be viewed as defining a partial
order among graphs. Given two graphs, G1 = (V1, E1) and
G2 = (V2, E2), G1 is called a subgraph of G2, denoted G1
G2, if there is an injective function  : V1  V2 such that
for any (a, b)  E1, ((a), (b))  E2.
Moreover, G1 is
called an induced subgraph of G2 if  satisfies the following
additional condition: for all ((a), (b))  E2, (a, b)  E1.
The complexity results to be presented here apply to either
subgraphs or induced subgraphs. But for simplicity we will
only mention subgraphs.
The definition of subgraph isomorphism can be readily
used to define subtree isomorphism on tree data structures,
even though definitions of trees usually need to take into ac-
count several factors: rooted or unrooted (called free trees);
ordered or unordered (the order of sibling nodes is not im-
portant); labeled (edge-labeled or node-labeled or both) or
unlabeled. Next we present the complexity results on la-
beled trees and graphs, followed by unlabeled trees and
graphs.


Theorem 19 Let D be a database of (rooted) unordered
labeled trees, |D| = m. The problem of counting the number
of maximal -frequent subtrees in D, where 1    m, is
#P-complete.


Theorem 20 Let D be a database of (rooted) ordered la-
beled trees, |D| = m. The problem of counting the number
of maximal -frequent subtrees in D, where 1    m, is
#P-complete.
We should point out that our complexity results can be
readily extended to prove the #P-hardness of counting max-
imal frequent embedded subtrees [26] in a database of la-
beled trees. Moreover, we can also immediately derive the
following corollary for labeled graphs.
Note that Corol-
lary 21 below applies to labeled graphs that are either di-
rected or undirected, ordered or unordered.


Corollary 21 Let D be a database of labeled graphs, |D| =
m. It is #P-hard to count the number of maximal -frequent
subgraphs in D, where 1    m.

We will now extend our complexity results to unlabeled
trees and graphs. First we will state the result for unlabeled
trees. Extending this result to unlabeled graphs is rather
straightforward. To prove the #P-completeness of the prob-
lem of counting the number of maximal frequent unlabeled
subtrees, we will reduce to it the problem of counting the
number of maximal frequent itemsets.
Here the proof is
rather tricky and omitted for want of space.


Theorem 22 Let D be a database of (rooted) unlabeled
trees, |D| = m. The problem of counting the number of
maximal -frequent subtrees in D, where 1    m, is
#P-complete.

It is worth pointing out that the claims in Theorems 19,
20, and 22 still remain valid even if binary trees are supplied
as input. From Theorem 22 we can immediately derive the
following claim about unlabeled graphs.


Corollary 23 Let D be a database of unlabeled graphs,
|D| = m. The problem of counting the number of maximal
-frequent subgraphs in D, where 1    m, is #P-hard.

6. RELATED WORK
Valiant introduced the class #P of counting problems
and proved that counting the number of distinct perfect
matchings in a bipartite graph is #P-complete [22] -- the
first counting problem known to be #P-complete whose
associated decision problem can be solved in polynomial
time. In [18], many counting problems on bipartite graphs,
such as vertex cover, independent set, were proved to be
#P-complete. The #P-completeness of counting the num-
ber of maximal bipartite cliques in a bipartite graph follows
readily from the results in [18], although it was not explic-
itly stated there. A similar claim was also made in [14], but
its proof was not correct. However, in [14] it was shown
that it is NP-complete to decide whether there is a maximal
bipartite (k, )-clique in a bipartite graph. More recently,
Hunt et al. proved the #P-hardness of many graph count-
ing problems when restricted to planar instances [11]. Some
of these results were later extended by Vadhan to even more
restricted bipartite graphs of bounded degree [21].
Many algorithms have been proposed in the literature for
mining maximal frequent itemsets, such as MaxClique [28],
Dualize and Advance [10], Pincer-Search [15], Max-Miner [5],
DepthProject [1], MAFIA [7], and GenMax [9]. These al-
gorithms exploited different heuristics for optimization and
were shown to have different good scaleup characteristics
on certain benchmark datasets. However, theoretical analy-
sis was not the main focus of these works and none of them



351
Research Track Paper

proved that the problem of counting the number of maximal
frequent itemsets is #P-complete.
There is a large body of work in the literature on min-
ing frequent and maximal frequent patterns from complex
data structures, such as sequences [3, 25], trees [26, 4, 24],
and graphs [12, 13]. Our complexity results (summarized
in Table 2) can be easily extended to problems studied in
these works.
Specifically, in [26] the patterns of interest
are embedded subtrees. Our proof of Theorem 19 implies
that it is #P-hard to count the number of maximal fre-
quent embedded subtrees in a database of labeled trees. The
#P-completeness of counting the number of frequent closed
itemsets [23] also readily follows our complexity results here.
The problem of counting the number of frequent item-
sets was first shown to be #P-complete in [10].
In [10]
it was shown that it is NP-complete to decide if there is
a maximal -frequent itemset with at least k items. The
NP-hardness of mining maximal frequent itemsets was also
recently established in [6] by proving the following claim:
given a set of maximal frequent itemsets, it is NP-complete
to decide whether this set can be grown with a new maxi-
mal frequent itemset. These results do not lend themselves
to the #P-completeness of counting the number of maximal
frequent itemsets.
In contrast, our result asserts a much
stronger claim about the hardness of mining maximal fre-
quent itemsets -- it is #P-complete to decide the exact num-
ber of all maximal frequent itemsets -- there is no clear clue
that this problem would belong to NP!
Finally, the work of [27] aimed at providing a lattice-
theoretic framework for mining frequent itemsets and asso-
ciation rules. Interesting work was also recently reported
in [19] on characterization of length distributions of fre-
quent and maximal frequent itemset collections, with a fo-
cus on computing tight bounds for feasible distribution. We
should point out that neither of these two works subsumes
any of the complexity results proved in this paper. More-
over, our results on the complexity of counting maximal fre-
quent itemsets provide theoretical underpinnings for the al-
gorithms proposed in [19] for computing distribution.

7. DISCUSSION AND CONCLUSION
In this paper we study the complexity of mining maxi-
mal frequent patterns, from the perspective of counting the
number of solutions. We present the first formal proof that
the problem of counting the number of maximal frequent
itemsets is #P-complete, thereby providing a complexity-
theoretic explanation for the (worst-case) computational dif-
ficulty of this problem. We also extend our complexity anal-
ysis to other data mining problems dealing with complex
data structures, in which the patterns of interest are max-
imal frequent subsequences, subtrees, or subgraphs.
The
complexity results proved in this paper are summarized in
Table 2. To the best of our knowledge, our work is the first
comprehensive study of the complexity of mining maximal
frequent patterns.
We should point out that there are four different but
closely related computational aspects of data mining prob-
lems:

1. Enumeration Problem (Column 2 of Table 2). Explicit
output of all solutions is expected.

2. Counting Problem (Column 3 of Table 2). The goal is
to compute the number of all solutions.
3. Search Problem (Column 4 of Table 2). Output of only
one solution is desired, if there is any.


4. Decision Problem (Column 5 of Table 2). The primary
concern is about the existence of one solution.

Take as an example the problem of mining maximal frequent
itemsets.
Its associated search problem is to output one
maximal frequent itemset, if there is any, while the decision
problem is to answer the question of whether a maximal
frequent itemset exists.
These four different aspects of data mining problems in
fact exhibit different levels of computational complexity (see
Table 2). For all the problems we study in this paper, their
associated decision problems (whether a maximal frequent
pattern exists) can all be solved in polynomial time (even for
labeled graphs). Their search problems can also be solved in
polynomial time except the search for a maximal frequent
subgraph.
This is due to the computational difficulty of
testing for subgraph isomorphism, which is NP-complete [8].
Nevertheless, one can easily design a deterministic polyno-
mial time algorithm to compute a maximal frequent sub-
graph, given an oracle for solving subgraph isomorphism:
start with a graph with one node and grow it until the sub-
graph isomorphism test fails. This implies that the complex-
ity of searching for a maximal frequent subgraph is FPNP [16].
For the same reason, it is unlikely that the counting prob-
lem for maximal frequent subgraphs would belong to #P;
but we have proved that it is #P-hard. Finally, we should
point out that the NP-hardness of enumeration problems
can be readily derived from the #P-hardness of their asso-
ciated counting problems [8]. Also note that the problem of
mining maximal frequent substrings can be efficiently solved
in polynomial time, utilizing the data structure of general-
ized suffix trees [20] -- this is not really surprising since
substrings do not manifest a combinatorial nature.
The complexity results presented in this paper should be
interpreted as worst-case time complexity only -- the impli-
cation being there is little hope a data mining algorithm can
execute efficiently on any dataset (if the problem is #P-hard
or NP-hard). In recent years many data mining algorithms
have been developed for important applications. Most of
them have been shown to be efficient or even exhibit linear
scaleup property with respective to various test datasets, ei-
ther synthetic or from real applications. A different analysis
tool will be needed to provide a complexity-theoretic expla-
nation for the efficiency of these algorithms and datasets.
Recently interesting work was reported in [19] on charac-
terization of length distributions of frequent and maximal
frequent itemset collections. We believe research along this
line will provide us with good guidance on understanding
the algorithms themselves as well as the datasets tested.
Another important problem is concerned with data min-
ing algorithms that can "adapt" efficiently -- if the size of
the output is polynomial, then the algorithm runs in polyno-
mial time -- the so-called output polynomial algorithms [17].
Recently, in [10], a mildly subexponential algorithm was de-
veloped for mining maximal frequent itemsets.
But cur-
rently it is still an open problem whether an output polyno-
mial algorithm exists for mining maximal frequent itemsets.
Our complexity results do not address this problem and we
believe that different complexity analysis techniques will be
needed.



352
Research Track Paper

maximal frequent patterns
enumeration
counting
search
decision

substrings
P
P
P
P

itemsets
NP-hard
#P-complete
P
P

subsequences
NP-hard
#P-complete
P
P
subtreesa
NP-hard
#P-complete
P
P
subgraphsb
NP-hard
#P-hard
FPNP
P
a
The same complexity results apply to (binary) trees that are either rooted
or unrooted, ordered or unordered, labeled or unlabeled (with or without
duplicate labels).
b
The same complexity results apply to graphs that are either directed or
undirected, labeled or unlabeled (with or without duplicate labels).



Table 2: Summary of Complexity Results


8. ACKNOWLEDGMENT
The author would like to thank Leslie G. Valiant, Alan
Selman, Mitsunori Ogihara, Heikki Mannila, Mohammed
Javeed Zaki, Jian Pei, Yongqiao Xiao, and the anonymous
referees for their helpful comments.

9. REFERENCES
[1] R. C. Agarwal, C. C. Aggarwal, and V. V. V. Prasad.
Depth first generation of long patterns. In KDD, 2000.
[2] R. Agrawal and R. Srikant. Fast algorithms for mining
association rules in large databases. In VLDB, 1994.
[3] R. Agrawal and R. Srikant. Mining sequential
patterns. In ICDE, 1995.
[4] T. Asai, K. Abe, S. Kawasoe, H. Arimura,
H. Satamoto, and S. Arikawa. Efficient substructure
discovery from large semi-structured data. In SDM,
2002.
[5] R. J. Bayardo Jr. Efficiently mining long patterns
from databases. In SIGMOD, 1998.
[6] E. Boros, V. Gurvich, L. Khachiyan, and K. Makino.
On the complexity of generating maximal frequent
and minimal infrequent sets. In STACS, 2002.
[7] D. Burdick, M. Calimlim, and J. Gehrke. MAFIA: A
maximal frequent itemset algorithm for transactional
databases. In ICDE, 2001.
[8] M. R. Garey and D. S. Johnson. Computers and
Intractability: A Guide to the Theory of
NP-Completeness. W. H. Freeman and Company,
1979.
[9] K. Gouda and M. J. Zaki. Efficiently mining maximal
frequent itemsets. In ICDM, 2001.
[10] D. Gunopulos, R. Khardon, H. Mannila, S. Saluja,
H. Toivonen, and R. S. Sharm. Discovering all most
specific sentences. ACM Transactions on Database
Systems (TODS), 28(2):140­174, 2003.
[11] H. B. Hunt III, M. V. Marathe, V. Radhakrishnan,
and R. E. Stearns. The complexity of planar counting
problems. SIAM Journal on Computing,
27(4):1142­1167, 1998.
[12] A. Inokuchi, T. Washio, and H. Motoda. An
apriori-based algorithm for mining frequent
substructures from graph data. In PKDD, 2000.
[13] M. Kuramochi and G. Karypis. Frequent subgraph
discovery. In ICDM, 2001.
[14] S. O. Kuznetsov. Interpretation on graphs and
complexity characteristics of a search for specific
patterns. Nauchno-Tekhnicheskaya Informatsiya,
Seriya 2 (Automatic Documentation and
Mathematical Linguistics), 23(1):23­27, 1989.
[15] D.-I. Lin and Z. M. Kedem. Pincer-Search: An
efficient algorithm for discovering the maximum
frequent set. IEEE Transactions on Knowledge and
Data Engineering (TKDE), 14(3):553­566, 2002.
[16] C. H. Papadimitriou. Computational Complexity.
Addison-Wesley, 1994.
[17] C. H. Papadimitriou. NP-completeness: A
retrospective. In ICALP, 1997.
[18] J. S. Provan and M. O. Ball. The complexity of
counting cuts and of computing the probability that a
graph is connected. SIAM Journal on Computing,
12(4):777­788, 1983.
[19] G. Ramesh, W. Maniatty, and M. J. Zaki. Feasible
itemset distributions in data mining: Theory and
application. In PODS, 2003.
[20] E. Ukkonen. On-line construction of suffix trees.
Algorithmica, 14(3):249­260, 1995.
[21] S. P. Vadhan. The complexity of counting in sparse,
regular, and planar graphs. SIAM Journal on
Computing, 31(2):398­427, 2001.
[22] L. G. Valiant. The complexity of computing the
permanent. Theoretical Computer Science, 8:189­201,
1979.
[23] J. Wang, J. Han, and J. Pei. CLOSET+: Searching
for the best strategies for mining frequent closed
itemsets. In KDD, 2003.
[24] Y. Xiao, J.-F. Yao, Z. Li, and M. H. Dunham.
Efficient data mining for maximal frequent subtrees.
In ICDM, 2003.
[25] M. J. Zaki. SPADE: An efficient algorithm for mining
frequent sequences. Machine Learning, 42(1/2):31­60,
2001.
[26] M. J. Zaki. Efficiently mining frequent trees in a
forest. In KDD, 2002.
[27] M. J. Zaki and M. Ogihara. Theoretical foundations of
association rules. In DMKD, 1998.
[28] M. J. Zaki, S. Parthasarathy, M. Ogihara, and W. Li.
New algorithms for fast discovery of association rules.
In KDD, 1997.




353
Research Track Paper

