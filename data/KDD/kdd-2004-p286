A Bayesian Network Framework for Reject Inference


Andrew Smith
Department of Computer Science
University of California, San Diego
La Jolla, CA 92307
atsmith@cs.ucsd.edu
Charles Elkan
Department of Computer Science
University of California, San Diego
La Jolla, CA 92307
elkan@cs.ucsd.edu



ABSTRACT
Most learning methods assume that the training set is drawn
randomly from the population to which the learned model
is to be applied. However in many applications this as-
sumption is invalid. For example, lending institutions cre-
ate models of who is likely to repay a loan from training
sets consisting of people in their records to whom loans were
given in the past; however, the institution approved loan ap-
plications previously based on who was thought unlikely to
default. Learning from only approved loans yields an incor-
rect model because the training set is a biased sample of
the general population of applicants. The issue of including
rejected samples in the learning process, or alternatively us-
ing rejected samples to adjust a model learned from accepted
samples only, is called reject inference.
The main contribution of this paper is a systematic anal-
ysis of different cases that arise in reject inference, with ex-
planations of which cases arise in various real-world situ-
ations. We use Bayesian networks to formalize each case
as a set of conditional independence relationships and iden-
tify eight cases, including the familiar missing completely at
random (MCAR), missing at random (MAR), and missing
not at random (MNAR) cases. For each case we present an
overview of available learning algorithms. These algorithms
have been published in separate fields of research, including
epidemiology, econometrics, clinical trial evaluation, sociol-
ogy, and credit scoring; our second major contribution is to
describe these algorithms in a common framework.



Categories and Subject Descriptors
G.3 [Probability and Statistics]: statistical computing;
H.2.8 [Database Management]: Database Applications--
data mining; I.2.6 [Artificial Intelligence]: Learning--
parameter learning; I.5.2 [Information Storage and Re-
trieval]: Design Methodology--classifier design and evalu-
ation




Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
KDD'04, August 22­25, 2004, Seattle, Washington, USA.
Copyright 2004 ACM 1-58113-888-1/04/0008 ...$5.00.
General Terms
Algorithms, Economics, Human Factors, Theory.


Keywords
Reject inference, sample selection bias, Heckman estimator,
propensity scores, expectation-maximization, Bayesian net-
works.


1. THE REJECT INFERENCE PROBLEM
In the typical reject inference application, the aspect of
the data that is to be learned (called the outcome) cannot
be observed in some of the samples, called the rejects. These
rejects are usually not randomly drawn from the training set,
but are related in some way to the outcome. Therefore, if
a model is learned from only the data with observable out-
comes (the accepts), the model will have been trained on
samples with biased selection (as opposed to random selec-
tion), since the accepts constitute a skewed sample of the
general population. The reject inference problem is to in-
clude the rejected data in the learning process to avoid this
sample selection bias.
One common instance of reject inference arises in the
problem of loan application approval. When people apply
for a loan, their application is either accepted or rejected, de-
pending on the lender's guess as to how likely the applicant
is to repay the loan. Then the people whose applications
were accepted either eventually repay the loan or default on
the loan (the outcome). We would like to use a mathemat-
ical model to predict how likely a person is to repay the
loan, so we can better decide whom to reject or accept, by
using a database created by a financial institution; however
such databases only have repay/default behavior recorded
for the people whose applications were accepted, since the
rejected people never had a chance to repay or default on
the loan. The accepts clearly constitute a biased sample of
all the applicants, so reject inference should help us develop
an unbiased model.
Another common example is that of medical treatment.
We would like to develop a mathematical model for a par-
ticular treatment that predicts the extent to which it will
help the patient, measured perhaps by the expected lifetime
increase. To create such a model, we would use a database
describing many patients and their responses to the treat-
ment. Any realistic database, however, will be biased by
sample selection, since it only contains patients whom doc-
tors recommended for the treatment; certainly whether or
not a doctor recommends someone for a particular treat-



286
Research Track Paper

ment is related to how much that treatment is expected to
benefit the patient. Reject inference should be used to cre-
ate an unbiased model of how well each patient is likely to
respond to the treatment.
So-called active learning is the situation where a learning
agent chooses which training examples should be labeled, in-
stead of using a randomly sampled training set [7]. Typically
the agent is given a set of unlabeled examples and repeat-
edly requests labels for the members of this set for which
labels are likely to be most informative. Sample selection
bias arises in the context of active learning in two ways.
Most obviously, a training set chosen via active learning is
not a random sample from the whole population. Less obvi-
ously, sample selection bias is also an issue when measuring
the performance (e.g. the accuracy) of a classifier acquired
via active learning. If obtaining labels for examples is ex-
pensive, then we will not have the luxury of having a large
randomly chosen evaluation set of examples with which to
measure performance. We will need to obtain somehow un-
biased performance estimates from biased evaluation sets.
Reject inference problems can have binary outcome vari-
ables, as in the loan application example, or be regression
problems, as in the medical example. Rejection/selection
is usually binary, but in some applications it can be multi-
valued. For example, we can model whether or not to make
a particular investment (a binary selection choice), or how
much money to invest (a multi-valued choice).


2. BAYESIAN NETWORKS
An important part of reject inference lies in the assump-
tions about how the selection mechanism and the outcome
mechanism are related. Bayesian networks provide a nat-
ural tool for representing possible relationships, both be-
cause they have intuitive causal interpretations, and because
they represent knowledge about their variables in a precise
way, in the form of conditional independence relationships.
Bayesian networks cannot encode that the outcome is ob-
servable only when a sample has been selected, but they can
encode the conditional independence relationships between
selection and outcome.
A Bayesian network is a graphical way to represent how
a joint distribution of random variables can be factored. In
general any joint probability distribution may be factored
in the following way:

p(a1,a2,a3,..., an)
= p(a1)p(a2|a1)p(a3|a1,a2)...p(an|a1,a2,a3, ..., an
-1
).

To represent such a distribution over binary variables re-
quires 2n - 1 parameters; however, Bayesian networks en-
code information about which variables are conditionally in-
dependent, leading to a simpler factoring of the joint dis-
tribution, and therefore simpler mathematical models. For
example, consider the following Bayesian network:




c
b
a
This network encodes the fact that b depends only on a and
c depends only on b. In other words, a and c are condition-
ally independent given b. The general factoring of the joint
distribution can now be simplified because p(c|a,b) = p(c|b):

p(a,b,c) = p(a)p(b|a)p(c|a,b) = p(a)p(b|a)p(c|b).

In the case that a, b, and c are binary, representing the joint
distribution factored in this form can be accomplished with
five parameters instead of seven. This reduction in the num-
ber of model parameters is possible whenever the situation
is described by a Bayesian network whose skeleton (i.e. the
graph with the edge directions removed) is not a complete
graph. The following Bayesian network has a skeleton that
is a complete graph:




c
b
a




The joint distribution factoring implied by this graph is
p(a,b,c) = p(a)p(b|a)p(c|a,b); however this factoring is true
of any distribution over three variables, without loss of gen-
erality. This generality can conflict with intuitions about
Bayesian networks. Because the edges on the network are
directed a particular way we might expect the network to be
able to model only particular distributions (i.e. distributions
arising from circumstances with the same causal relation-
ships as the network implies), whereas the factoring shows
that this network is completely general, for all distributions
over three variables [10].
Bayesian networks are good tools for organizing sets of
conditional independence relationships because those sets
correspond to properties of graphs over which the joint dis-
tribution factors. Two variables, A and B, in a probabil-
ity distribution are conditionally independent given a set of
other variables, X, if information cannot flow between their
corresponding vertices in the Bayesian network describing
that distribution. For information to flow between A and
B, there must be an "active path" between them. Clearly
there must be a series of edges (a path) connecting the two,
but for the path to be active, every pair of two consecutive
edges on that path must follow one of three patterns [11]:

... - C - ... where C is not in X
... - C - ... where C is not in X
... - C - ... where C or a descendant of C is in X.

In these patterns C is the vertex between the two edges.
If there is no active path between A and B, then we say
X "d-separates" A and B (written A  B|X). The last
case, in which the two edges point to the same vertex, is
called a v-structure, and unless the two vertices that both
point to C share an edge (in which case we have a so-called
moralized v-structure), conditioning on C or a descendant of
C (a vertex with a directed path from C) allows information
to flow through the path segment [10].




287
Research Track Paper

3. OUTCOME MODELING
In this paper, we assume that some existing model (the
old model) has consistently been used to select samples for a
database. We want to create a mathematical model (the new
model) with this database that will hopefully better predict
the outcome, and therefore be a better tool for future use.
The old model can be either a formal selection model, such
as a logistic regression on a feature vector, or informal, such
as an interview by a loan agent. Both cases are discussed in
later sections.
Bayesian networks are used to represent the relationship
between the selection and outcome processes. As previously
stated, the structure of the network depends on our assump-
tions about conditional independence, but the random vari-
ables corresponding to the vertices of the different graphs
will be the same in all cases.
Following are the definition of each variable, with an ex-
ample in parentheses of what the variable would represent
in the case of loan applications.

· y is the outcome variable. If y is binary, y = 1 if the
outcome was good (loan repaid; the applicant was a
good borrower), otherwise y = 0.

· s is the selection variable (indicating whether a loan
application was accepted). If s is binary, s = 1 when
the data point is selected for observation and y is ob-
servable, otherwise s = 0 and we cannot observe y.

· x1 is a set of observed variables, also called covariates
or features, available for training the new model (credit
history, income level, age, etc.)

· x2 is a set of unobserved variables (for example, un-
quantified traits such as an interviewer's general im-
pression of the applicant's responsibility). These might
have been used in the old model to help with selection,
and might be variables influencing the outcome, but
they are not available for training a new model.

· x is sometimes used to mean x1  x2. This can be
done in a Bayesian network without loss of general-
ity by grouping the x1 and x2 vertices together into
an x vertex, which corresponds to not factoring the
p(x1,x2,...|...) = p(x1,...|x2...)p(x2,...|...) term of the
joint probability.

Our learning task can always be described by the following
Bayesian network, since its skeleton is a complete graph and
therefore the implied factoring of the joint distribution is
completely general:




x2
y




s
x1




Template for alternative reject inference scenarios.

This network is a template for the different cases con-
sidered in this paper; all of the conditional independence
relationships in the next section will follow from subgraphs
of this graph, where we require the solid edges to be present
and the dashed edges are optional. This results in eight dif-
ferent sets of assumptions, the first of which has no optional
edges and the last of which has all the optional edges.
These constraints restrict the set of Bayesian networks
to those with valid semantic interpretations (in terms of
causality), even though those that lack valid causal inter-
pretations may lead to equally useful statistical models. In
general the x-variables are causes, and the outcome and se-
lection variables, y and s, are effects, so there should never
be an edge from y or s to an x variable. In the case of
the selection procedure, this constraint conforms to what is
done in practice: data points are selected for observation
depending on features of that data point. In the case of
the outcome event, this constraint conforms to our intuitive
notions about causality: the outcome for a data point is
influenced by the features of that data point.
We always assume the outcome, y, is dependent both on
the observable variables x1 and on the unobservable vari-
ables x2. The edge from x2 to x1 conforms to our intuitive
notions because observable variables, such as one's credit
history, are influenced by unobservable variables, such as
one's responsibility. This also helps in practice because it is
often the case that the variables used in an old model are
not present to train the new model. For example if an inter-
view is part of the loan application process, the interviewer's
general impression of the applicant can affect the decision
to select the applicant, but it is not recorded in a database
and will not be present for learning a new model.
In most cases there should be no edge between y and s.
Even though there can be a direct influence of s on y, for ex-
ample if s represents selecting someone for treatment and y
represents survival, we do not add this edge into the graph.
In this paper we are not trying to measure the probability
of an outcome conditioned on whether or not an individual
is selected, but instead to obtain an unbiased model of what
the outcome would be for any individual in the general pop-
ulation, if selected. It is important to distinguish [3] between
modeling the average risk difference, which is a function of
P(outcome|treatment) and P(outcome|no treatment), and
modeling only P(outcome|treatment), which is the focus of
this paper.
The reject inference problem can now be defined more
formally. Note that it is actually a learning problem, not
an inference (i.e. reasoning) problem. Our data set contains
samples drawn independently at random from some underly-
ing distribution, p(x1,x2,y,s), where each sample for which
s = 0 is missing the value of y. The goal is to model the
distribution of the outcome y as a function of the observable
variables x1, i.e. to learn p(y|x1).

4. CASES OF CONDITIONAL INDEPEN-
DENCE
The subsections in this section describe different possible
independence relationships between the four variables, and
how these relationships change the reject inference problem.
Each set of conditional independence relationships follows
from a Bayesian network that is a subgraph of the tem-
plate in Section 3. Also provided are real-world situations
in which these cases could arise. Algorithms for learning
under these different assumptions are given in Section 5.




288
Research Track Paper

4.1 Random selection
In this case the following independence relationship holds:

s  y,x1,x2

which implies

p(s|y,x1,x2) = p(s)
p(y,x1,x2|s) = p(y,x1,x2).
This can be represented by a Bayesian network in which s
is not connected to any other random variables.




x2
y




s
x1




Case 1.

This is the most general subgraph (of the template) satisfy-
ing the independence relationships because any probability
distribution with the given independence relationships will
factor over it; a proper subgraph G of this graph will cer-
tainly have the given independence relationship, but a prob-
ability distribution in which the marginal p(x1,x2,y) cannot
be further factored will not factor over G but will factor over
the graph of case 1.
Factoring the joint probability of x1,x2,y, and s once gives
p(x1, x2,y,s) = p(x1,x2,y|s)p(s).
We find the marginal distribution p(x1,x2,y) by summing
over s:

p(x1,x2,y) =
s
p(x1,x2,y,s)

= p(x1,x2,y|s = 1)p(s = 1) + p(x1,x2, y|s = 0)p(s = 0).
Since s is independent of all other variables, we have

p(x1,x2,y|s = 0) = p(x1,x2,y|s = 1).

Making this substitution,

p(x1,x2,y) = p(x1,x2,y|s = 1)p(s = 1)
+ p(x1,x2, y|s = 1)p(s = 0)
= p(x1,x2,y|s = 1)(p(s = 1) + p(s = 0))
= p(x1,x2,y|s = 1)

So the distribution of the selected samples, those for which
s = 1, is the same as the underlying distribution of x1, x2,
and y. Any learner that only uses the selected data to learn
this distribution will be learning an unbiased classifier.
This situation arises in randomized studies, in which sam-
ples are selected for observation completely at random. In
the literature, this case is called missing completely at ran-
dom (MCAR) [6].

4.2 Selectionconditionallyindependentofout-
come
In this case, we allow only the observable features to in-
fluence the selection. Thus the outcome and selection are
conditionally independent:

s  y|x1
which implies the constraints

p(s|x1,y) = p(s|x1)
p(y|x1,s1) = p(y|x1).

This case is less restrictive than case 1 since any distribu-
tion satisfying the unconditional independence relationships
of case 1 will also satisfy the conditional independence re-
lationships of case 2. The most general Bayesian network
that has this property and is a subgraph of the template is




x2
y




s
x1




Case 2.

In this graph, observing x1 d-separates y and s, so the con-
ditional independence relationships are preserved. In this
case, selection may depend on x1, but given x1, y adds no ad-
ditional information about selection, or, equivalently, given
x1, knowing s gives no information about the outcome (for
example, whether or not someone is a bad borrower).
This situation can arise if a formal selection model is used,
where s is some function of the observable variables, x1.
Rather confusingly, in the literature, this case is called miss-
ing at random (MAR) [6].
An important consequence of this conditional indepen-
dence relationship is that the distribution of selected sam-
ples, p(x1, y|s = 1), is related to the underlying distribution
p(x1,y) in the following way:
Lemma 1: Under case 2, p(x1,y) =
p(s=1)
p(s=1|x1)
p(x1,y|s = 1)
if all three probabilities are non-zero.
Proof: Apply Bayes' rule to the right hand side of this equa-
tion and then use the assumed conditional independence re-
lationship:
p(s = 1)
p(s = 1|x1)
p(x1,y|s = 1)


=
p(s = 1)
p(s = 1|x1)
p(s = 1|x1,y)p(x1,y)
p(s = 1)

=
p(s = 1)
p(s = 1|x1)
p(s = 1|x1)p(x1,y)
p(s = 1)
= p(x1,y).

Lemma 1 is applied in Section 5.2 to learn an unbiased
model in this case. Sample weights are created to rebalance
the training set so that the weighted distribution of the se-
lected samples is the same as the (unweighted) distribution
of the general population [16].

4.3 Selection dependent on outcome
In this case, the selection is dependent on the outcome,
but given the outcome, selection is not dependent on the
covariates, observed or unobserved:

s  x|y

or in other words

p(s|x,y) = p(s|y)
p(x|s,y) = p(x|y).



289
Research Track Paper

The most general subgraph that has this property is




x2
y




s
x1




Case 3.

The important feature of this graph is that y d-separates s
and x.
If the variables s and y are binary, this situation corre-
sponds to differences in the base rates of y for the selected
data and the general population. This situation arises most
often when the record-keeping procedure deletes outcome la-
bels depending on the outcome label (also known as censor-
ing). An example in medical studies is estimating expected
survival time from a database in which patients who lived
longer than five years do not have a survival time recorded.
Section 5.3 discusses what may and may not be learned in
this case.
This situation also arises when the biased selection changes
the distribution of y, but the conditional distributions of x
given each possible outcome y are unchanged, because in
the network y d-separates x and s. For example, suppose
we learn to diagnose a disease y based on patients x encoun-
tered at one hospital. At a different hospital, the prevalence
of the disease p(y) may be different, but it is often reasonable
to assume that the characteristics of affected and unaffected
patients, i.e. p(x|y = 1) and p(x|y = 0), are unchanged.
This scenario has been analyzed previously [5].

4.4 Conditional independence with selection
that can be modeled
In this case, the only conditional independence relation-
ship asserts that the unobserved covariates cannot influence
selection:

s  x2|x1,y

or

p(s|x1,x2,y) = p(s|x1,y).

The most general graph that has this property is a com-
bination of the previous two. This creates two possible v-
structures, but both are moralized so there are no uncondi-
tional independence relationships due to the v-structures:




x2
y




s
x1




Case 4.

This situation could arise in practice if a formal selection
model is used to determine s, and then in addition p(y)
changes as discussed in the previous subsection. Learning
under these assumptions is discussed in Section 5.4.
4.5 Conditionally independent selection with
missing features--selection that cannot be
modeled
This case is a generalization of case 2 in which the unob-
served features in x2 may influence selection. This occurs
in practice when a selection decision is made based on un-
recorded information, such as an interviewer's general im-
pression, or numerical features which are not available for
learning the new model. The conditional independence re-
lationship describing this case is


s  y|x1,x2.

However, x2 can never be observed, so it is impossible to
make use of any independence relationships.




x2
y




s
x1




Case 5.


4.6 Outcome conditionally independent selec-
tion with only missing features--unlearn-
able selection
This case is a special case of the previous case. All the
features that influence the selection variable are in x2 and
not x1:




x2
y




s
x1




Case 6.

In this case it is impossible to learn a model of the selection
mechanism. This case rarely arises. Intuitively, if the se-
lection mechanism and the outcome mechanism are related
(as they are in loan applications; loan approval attempts to
predict loan repayment) and the outcome depends in some
way on the available features in x1, then it is reasonable to
expect the selection to depend in some way on x1.
This case could arise if a lending institution is just be-
ginning to use statistical methods in its loan application
procedure. Such an institution would have a training set
consisting entirely of people whose loan applications were
approved solely on the basis of an agent's subjective judg-
ment, and not recordable features.


4.7 Selection that cannot be modeled
This cases features a selection mechanism that is not in-
fluenced by the observable features, x1, but is influenced by



290
Research Track Paper

unobservable features x2 and by the outcome y:




x2
y




s
x1




Case 7.

This scenario arises if the predictive features of the selection
mechanism are not present for training a new model, and in
addition outcome labels are missing in a way that depends
on the value of the outcome.

4.8 Arbitrarily biased selection
This case is the most general: there are no assumptions
about conditional independence relationships. The Bayesian
network representing this case is




x2
y




s
x1




Case 8.

Since this Bayesian network represents a completely general
factoring of the joint distribution, we would be able to use it
to model a situation in which any of the previous conditions
hold. This model should be used in practice when nothing
is known about the selection mechanism.

5. REJECT INFERENCE ALGORITHMS
As stated above, Bayesian networks have no capability to
encode the relationship between the outcome and selection
variables, so our algorithms must learn from a heterogeneous
training set, one in which there exist two different schemas
for data in the training set.

5.1 Learning under case 1
Since the distribution p(y,x1,x2|s = 1) is the same as the
underlying distribution p(y,x1,x2), any classifier that learns
from only the selected samples will learn an unbiased model
of the outcome. However, because this classifier is based on
fewer data points, it will have increased variance.

5.2 Learning under case 2
When we want to predict y based on x, we usually have
the choice of learning p(y|x) or learning p(x,y). The former
is often called discriminative learning, while the latter is
called learning a generative model. Under case 2, these two
types of learning are very different.

Discriminative modeling
Given any particular x, the distribution of y for the selected
data is the same as the distribution of y for the unselected
data, because

p(y|x1,s = 0) = p(y|x1) = p(y|x1,s = 1).
So learning a model of the outcome based only on selected
data provides an unbiased estimate of p(y|x) in the entire
population.
Intuitively the samples with unobserved outcomes can
contribute nothing to the model, since the values of the
variable whose density we are trying to estimate are missing.
This can be shown formally by looking at the contribution of
each sample to the likelihood of the parameters of a model.
Assuming samples are drawn independently, the likeli-
hood of the parameters given the data equals the product
of the probabilities of every sample, given those parameters.
If a value is missing in a particular sample, the probability
of that sample equals the full joint distribution marginalized
with respect to the missing feature. For example if the prob-
ability of some sample i should be p(A = ai,B = bi,C =
ci|) but the value of B is missing, the probability becomes
È
b
p(A = ai,B = b,C = ci|) [1]. It may seem counterin-
tuitive that the likelihood increases if features are missing;
however, if we interpret the likelihood as the goodness-of-fit
of our model, then with less information (due to missing fea-
tures), there is less opportunity to criticize our model and
the likelihood should therefore be greater.
Rejected samples are missing the value of y, so y should
be treated as a missing feature in the conditional likelihood
equation:

L(|X) =
n


j=1
Lj()


where

Lj() =
p(y = i|xj;)
if yi = i if sj=1
È1
i=0
p(y = i|xj;)
if sj = 0.

The sum equals 1 because p(y = 1) = 1 - p(y = 0), so the
contribution to the likelihood of the unselected data is an
uninformative factor of 1.

Generative modeling
If instead of modeling p(y|x) we want to model p(x,y), with-
out loss of generality we can use a mixture model with one
mixture component for the data in which y = 1 and one mix-
ture component for the data in which y = 0. These mixture
components come from the factoring p(x,y) = p(y)p(x|y),
which can be written in the case of binary y as

p(x,y) = p(y = 0)p(x|y = 0) + p(y = 1)p(x|y = 1).
The factors p(y = i) are the mixing proportions, renamed
i, and the conditional distributions p(x|y = i) are modeled
by the mixture components, written p(x|y = i) = pi(x).
Now all samples are modeled as being drawn from the two
component mixture

p(x|y) = op0(x) + 1p1(x).

We only observe which mixture component generated a sam-
ple for those samples with observed outcomes. The contri-
bution to the likelihood for the observed samples is

p(xi,yi) = p(yi)p(xi|y = yi) = yipyi(xi).

As before, the contribution to the likelihood for those sam-
ples with an unobserved outcome is obtained by marginal-
izing with respect to the outcome variable:


p(xi,ymissing) =
y
p(xi,y) =
1


i=0
ipi(x).




291
Research Track Paper

Assuming there are m rejected samples and n accepted sam-
ples, the full likelihood of all data is


L =
m


j=1
´
1


i=0
ipi(xj|i)
µ
m+n


j=m+1
´
1


i=0
zijipi(xj|i)
µ


where the indicator zij equals 1 if yj = i and 0 otherwise.
The log likelihood is


log(L) =
m


j=1
log
´
1


i=0
ipi(xj|i)
µ



+
m+n


j=m+1
1


i=0
zij log ipi(xj|i)


This equation contains a logarithm of sums for the unob-
served samples, which makes an analytic maximum likeli-
hood approach intractable. The EM algorithm is a common
algorithmic approach to this maximization. EM iteratively
optimizes the so-called complete-data log likelihood

log L((t
)
) =
m+n


j=1
1


i=0
z(t
)
ij
log ipi(xj|i)


where z(t
)
ij
is the estimate during iteration t of the probability
that y = i for sample j. First, the E-step uses some initial
estimate (0) of the parameters, based only on observed
data, to estimate the probabilities z(1)
ij
. These probabilities
are then used in the M-step to learn a new set of parameters,
(1), that maximizes the likelihood of the data, including
z(1)
ij
. The E and M steps are iterated until convergence [6].

Reweighting, stratification, and propensity scoring

Reweighting methods used to solve the reject inference prob-
lem, sometimes called inverse probability of treatment weight-
ing (IPTW), weight each selected sample so that the distri-
bution of weighted samples equals the underlying distribu-
tion ignoring selection [14]. These methods take advantage
of Lemma 1.
The IPTW method first learns a select/reject model using
the entire data set. After the model is adjusted to yield
well-calibrated probabilities, sampling weights are created
for each selected sample: P(s = 1)/P(s = 1|x). A model
for P(y|x1) is then learned using the weighted (selected)
samples, ignoring the unselected samples [16].
Stratified analysis (also called banded analysis) is a special
case of reweighting. Like the IPTW method, the rejected
samples are used only to create weights for the accepted
samples. The stratified analysis presented in [4] is an ap-
proximation of the IPTW method. First an accept/reject
model is estimated using the entire data set. The range of
the classifier's output is partitioned into several strata or
bands, usually so they contain similar numbers of samples.
Within band j, the probability of selection is estimated as
the ratio of selected samples in band j to the total number
of samples in band j. This essentially bins the classifier to
estimate the conditional probability of selection given x1.
For a more adaptive binning method, see [15], which also
divides the range of the classifier score into several bands
(typically many more than stratified analysis) and assigns
a probability to each band, estimated from the samples in
that band and its neighbors. This calibration algorithm si-
multaneously determines an appropriate population size for
each band and enforces the monotonicity of the probability
given the score.
Within each band j, all of the accepted samples are given
a weight of 1/p(s = 1|j), which is an estimate of 1/p(s =
1|x). Here j is a function of x defined by a range of scores
determined by the accept/reject model. This is the same
weight used for the IPTW method, except for the constant
factor p(s = 1). Since resampling is done with probability
proportional to each sample's weight, and is not sensitive
to constant factors, stratified analysis is equivalent to the
IPTW method.
The propensity score method is a technique similar to
stratified analysis, except that it is usually used to find an
unbiased estimate of the average effect of some treatment
on the general population, a function of p(y|treatment) and
p(y|no treatment), as opposed to solving the reject inference
problem, which is to learn a per-individual model of the
effect of treatment.
The propensity score method is described here to illus-
trate the similarities to stratified analysis. The propensity
score is the function e(x) = p(s = 1|x), the conditional
probability of selection given x. It is a special case of the
more general balancing score, any function b(x) such that
x  s|b(x). It is shown in [13] that if selection and outcome
are conditionally independent given x (i.e. case 2 applies),
then y  s|e(x); for any particular value of e(x), the dis-
tribution of the outcome variable is independent from the
selection variable. Accepted samples are grouped (banded)
together according to their propensity score [13]. Since the
treatment effect (outcome) and selection are conditionally
independent within one band, the treated population and
the untreated population within the same band may be di-
rectly compared. An unbiased estimate of the average treat-
ment effect is the average of the average treatment effects
in each band, weighted by the number of samples in that
band.
When the outcome is continuous, for example, the in-
crease in white blood cells, the pair matching method may
be used. When one treated sample and one untreated sam-
ple both have the same propensity score e(x), the two are
called a matched pair and the difference in outcome values is
an unbiased estimate of the outcome difference at e(x) [13].

5.3 Learning under cases 3 and 4
In case 3, selection is independent of the covariates, both
observed and unobserved, given the outcome: s  x|y. The
bias only depends on the outcome label. Therefore the only
difference between the distribution of selected samples and
the distribution of the general population is a different prior
for the outcome probability.
Without making further assumptions, it is impossible to
infer the true baseline probability of a specific outcome in the
general population, as can be seen by first applying Bayes'
rule and then using the conditional independence relation-
ship:

p(y = 1|x1) =
p(x1|y = 1)p(y = 1)
p(x1)

=
p(x1|y = 1,s = 1)p(y = 1)
p(x1)
.

The quantity p(x1|y = 1,s = 1) can be estimated from only
observed samples, as can p(x1), but it is impossible to




292
Research Track Paper

estimate p(y = 1) since this could have been arbitrarily al-
tered.
If we learn separate models of the covariates of the good
outcomes p(x1|y = 1) and of the covariates of the bad out-
comes p(x1|y = 0), from the selected samples, and we have
outside information that p(y = 1) = p1, then we can create
an unbiased model of p(y = 1|x1) using Bayes' Rule:

p(y = 1|x1) = p1
p(x1|y = 1)
p(x1|y = 0) + p(x1|y = 1)
.


For further discussion of this case, see [5].
Under case 4, the selection variable depends both on the
observable features and the outcome variable. Without mak-
ing further assumptions about the selection mechanism, it
is impossible to learn an unbiased model to predict y, just
as for case 3.

5.4 Learning under cases 5, 6, 7, and 8
In each of these cases, the selection mechanism can de-
pend, at least in part, on unobservable features. This is
especially relevant when correcting for self-selection bias, an
example of which is estimating something about the general
population from survey results when returning the surveys
is voluntary (and therefore not random). The unobservable
features prevent us from building an accurate model of the
selection mechanism. However, even if we make no condi-
tional independence assumptions we can still estimate an
unbiased model of the outcome if we are willing to assume
a particular functional form of the relationship between the
outcome and selection processes. The usual approach given
this new assumption is the bivariate probit, which assumes
a normal distribution for the outcome and selection vari-
ables. Heckman's two-step estimator, an approximation of
the maximum likelihood estimate of the bivariate probit pa-
rameters, is also explained below.

Probit models

The univariate probit model is used to represent the con-
ditional distribution of a single response variable y given a
vector of features, based on a linear relationship between
the features and a dummy variable y which is not observed
[2]:
yi = xi + .
(1)

Here xi is the vector of features for sample i,  is a vector of
parameters, and is a normally distributed random variable
with zero mean and variance 2. The response yi for sample
i is related to yi by
yi = 1 if yi  0

yi = 0 if yi < 0.

Given this linear relationship, we can write the functional
form of p(y = 1|x):
p(y = 1|x) = p(y > 0|x)
(2)
= p(x + > 0)
= p( > -x)
= 1 - p( < -x)
= 1 - (-x)
= (x)
= (x/).
Here (.) is the cumulative normal distribution function
with variance 2 and mean 0, while (.) is the standard
cumulative normal distribution function. Equation (2) is
known as the probit equation. Given this functional form,
the log likelihood of parameters  given data set X with n
samples is


log L(|X) =
n


i=1
yi log (xi/)+(1-yi)log(1-(xi/)).


There are iterative methods for estimating / given this
model. Note that  and  are not uniquely defined since
they only enter into the model as the ratio / [2].

Bivariate probit models

Bivariate probit is an extension of univariate probit, in which
there are two response variables (our outcome and selection
variables) [6]. For all samples i = 1,2, ..., n

yi = xi +
i


and

si = xi + i.
Here si and yi are unobserved variables. Analogously to
the univariate probit, let the binary s and y equal 1 if the
associated continuous variable is nonnegative, or 0 if it is
negative. The vectors  and  are the coefficients of the
linear models, while
i
and i are the errors of those models
for each sample, with variances 1 and 2 respectively.
We assert the selection rule: for sample i, yi is only ob-
served if si = 1. Assume the errors are bivariate normally
distributed:

i
i
 N(µ,2) , µ =
0
0
, 2 =
21
12
12
22

Each of the three possible types of observation has a different
form for its contribution to the likelihood:

s = 0 : P(s = 0) = 1 - (xi/2)
(3)
s = 1, y = 0 : P(s = 1, y = 0) =
(4)
(xi/2) - (xi/1,xi/2)
s = 1, y = 1 : P(s = 1, y = 1) = (xi/1,xi/2) (5)

Here  is the standard univariate normal cumulative distri-
bution function, as above, and  is the standard bivariate
normal cumulative distribution with correlation  =
12
12
.
Equation (3) holds by the definition of the probit model,
p(s = 1) = (xi/1), and the fact that p(s = 0) =
1 - p(s = 1). Similar reasoning yields Equation (5). Equa-
tion (4) holds because

p(s = 1,y = 0) = p(y = 0|s = 1)p(s = 1)
= (1 - p(y = 1|s = 1))p(s = 1)

= (1 -
p(y = 1,s = 1)
p(s = 1)
)p(s = 1)

= p(s = 1) - p(y = 1,s = 1)

and applying the probit model equations yields (4). These
three expressions can combined into one log likelihood func-



293
Research Track Paper

tion:

log L(/1, /2,|X) =
n
È
i=1
(1 - si) log(1 - (xi/1))

+si(1 - yi) log((xi/1) - (xi/1,xi/2))
+siyi log (xi/1,xi/2)

From this equation we can derive iterative maximum like-
lihood estimators of /1, /2, and . The correlation 
between the errors of the two linear models,
and , indi-
cates how and if the samples were selected in a biased way.
If  is zero there is no correlation, and selection is indepen-
dent from the outcome given the observable features, so we
can use one of the methods for case 2 to estimate an unbi-
ased model. If  is positive, then the unobserved features
do affect selection and the outcome in a way that makes
them positively correlated. Similarly, if  is negative, then
selection is an indicator of a bad outcome [6].
The maximum likelihood estimation of the outcome given
the features is then p(y = 1|x) = (x/1), which is the
probit equation (2). This estimate is asymptotically unbi-
ased in theory, with its performance in practice depending
on the correctness of the parametric assumption stated in
equation (1).

The two step Heckman estimator

The computation of the model identified by the bivariate
probit maximum likelihood equation was until recently pro-
hibitively computationally intensive [12]. For this reason,
Heckman developed a two step estimator to solve the reject
inference problem when the outcome y is continuous [7].
Many problems with binary outcomes have a natural corre-
spondence with problems with a continuous outcome. For
example, the problem of estimating the probability of sur-
vival, a problem with a binary outcome, can be extended to
finding an unbiased estimate of the expected survival time.
In the domain of credit scoring, the problem of estimating
the probability of loan repayment can be cast as estimating
how profitable a customer will be to the lending institution.
For consistency of notation, the outcome of sample i, now
continuous, is denoted yi and is observed in samples for
which si = 1. The Heckman estimator relies on a prop-
erty of the conditional distribution of yi given that si > 0
(i. e. given si = 1, the sample was selected). From [2],
E(yi |si > 0,x) = E(yi |i > -xi)
(6)

= xi +
12
2
(-xi/2)
1 - (-xi/2)
where  is the standard normal density function. The last
term is usually expressed in terms of the function (), known
as the inverse Mills ratio:

(Zi) =
(Zi)
1 - (Zi)
Zi = -xi
2
.

The two step Heckman procedure is as follows [9]:

1. Estimate the parameters /2 describing the proba-
bility of selection given x. This is a simple univariate
probit as in equation (2), and the maximum likelihood
solution can be found by iterative methods. For each
sample, Zi can be estimated, and therefore the inverse
Mills ratio can be estimated as
^
i = (Zi).

2. Equation (6) becomes the linear regression

E(yi |si = 1, x) = xi + 12/2^
i

using xi and
^
i as the regressors. Solve this regression
using ordinary least squares to estimate  and 12/2.

From the second step, we get an estimate of 12/2. Call
this C. Let
^
V
2
i
be the squared residuals from the regression
in the second step, and let I1 be the number of samples for
which s = 1. Now we can estimate 1 as


^
21 =
ÈI
1
i=1
^
V
2
i
I1
-
C
I1
I1


i=1
(^
iZi -
^
2i)


Analogously to the bivariate probit model, the unbiased esti-
mated model of the outcome given the features is E(y|x) =
x.
An interesting similarity between the reweighting methods
of Section 5.2 and the Heckman procedure is that both first
learn a model of the selection mechanism and then use that
model to learn a model of the outcome mechanism.


6. CONCLUSIONS AND FUTURE WORK
The main contribution of this paper is to apply Bayesian
networks to describe the different assumptions one may make
in the course of developing a procedure to learn an unbi-
ased model from a training set with sample selection bias
(i.e. in the course of solving the reject inference problem).
Our framework describes previously published cases as well
as several novel ones. The use of Bayesian networks makes
recognizing which case is applicable easier and more intu-
itive, since conditional independence relationships are easy
to spot in the simple networks involved in reject inference.
For each case, we have provided an overview of the proba-
bilistic learning algorithms that are available, to the extent
to which a model can be learned in each case. In some cases
a provably unbiased model can be learned, while in other
case selection bias is impossible to overcome. In the most
general case, we can only learn an unbiased model if a par-
ticular functional form for the outcome and selection models
is assumed.
Future work includes investigating what algorithms exist
to learn the parameters of Bayesian networks with a het-
erogeneous training set, i.e. a training set that contains ex-
amples with differing patterns of observed and unobserved
variables.
None of the algorithms described above are specifically
Bayesian network training algorithms [8]. An important di-
rection for future work is to investigate how existing Bayesian
network methods perform with a heterogeneous training set,
i.e. a training set that contains examples with differing pat-
terns of observed and unobserved variables. These algo-
rithms can be used in principle to solve the reject inference
problem. A related research direction is to apply structural
learning algorithms to discover which of the cases in Section
4 best describes a given data set.
Alternatively, perhaps algorithms developed specifically
to solve reject inference problems can be extended to learn
the parameters of Bayesian networks given a heterogeneous
training set.



294
Research Track Paper

7. ACKNOWLEDGMENTS
The authors thank Fair Isaac Corporation for funding this
research through California MICRO grant 2003-024. This
research was also supported by a gift from Sun Microsys-
tems.


8. REFERENCES
[1] P. D. Allison. Missing Data. Sage Publications, Inc.,
Thousand Oaks, California, 2002.
[2] T. Amemiya. Advanced Econometrics. Harvard
University Press, Cambridge, Massachusetts, pages
267­359, 1985.
[3] D. A. Cobb-Clark and T. Crossley. Econometrics for
evaluations: An introduction to recent developments.
The Economic Record, 79(247):491­511, 2003.
[4] J. Crook and J. Banasik. Does reject inference really
improve the performance of application scoring
models? Technical Report Working Paper Series No.
02/3, Credit Research Centre, 2002.
[5] C. Elkan. The foundations of cost-sensitive learning.
In IJCAI, pages 973­978, 2001.
[6] A. J. Feelders. An overview of model based reject
inference for credit scoring. Technical report, Utrecht
University, Institute for Information and Computing
Sciences.
http://www.cs.uu.nl/people/ad/mbrejinf.pdf.
[7] Y. Freund, H. Seung, E. Shamir, and N. Tishby.
Information, Prediction, and Query by Committee. In
Advances in Neural Information Processing Systems,
vol. 5, pages 483­490, 1992.
[8] D. Heckerman. A Tutorial on Learning with Bayesian
Networks. Technical report MSR-TR-95-06, Microsoft
Research, (1995).
ftp://ftp.research.microsoft.com/pub/tr/tr-95-06.pdf.
[9] J. J. Heckman. Sample selection bias as a specification
error. Econometrica, 47(1), pages 153­162, 1979.
[10] K. Murphy. Dynamic Bayesian Networks:
Representation, Inference and Learning. PhD thesis,
University of California, Berkeley, 2002.
[11] J. Pearl. Graphical models for probabilistic and causal
reasoning. In D. M. Gabbay and P. Smets, editors,
Handbook of Defeasible Reasoning and Uncertainty
Management Systems, Volume 1: Quantified
Representation of Uncertainty and Imprecision, pages
367­389. Kluwer Academic Publishers, Dordrecht,
1998.
[12] P. A. Puhani. The Heckman correction for sample
selection bias and its critique. Journal of Economic
Surveys, 14(1), 2000.
[13] P. R. Rosenbaum and D. B. Rubin. The central role of
the propensity score in observational studies for causal
effects. Biometrika, 70(1):41­56, 1983.
[14] B. Zadrozny. Learning and Evaluating Classifiers
under Sample Selection Bias. Proceedings of the 21st
International Conference on Machine Learning, 2004.
[15] B. Zadrozny and C. Elkan. Transforming classifier
scores into accurate multiclass probability estimates.
Proceedings of the Eighth International Conference on
Knowledge Discovery and Data Mining, pages
694­699, 2002.
[16] B. Zadrozny, J. Langford, and N. Abe. Cost-sensitive
learning by cost-proportionate example weighting.
IEEE International Conference on Data Mining
(ICDM), pages 435­442, 2003.




295
Research Track Paper

