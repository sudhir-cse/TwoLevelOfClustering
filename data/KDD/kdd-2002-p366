Mining Intrusion Detection Alarms for Actionable
Knowledge


Klaus Julisch
IBM Research
Zurich Research Laboratory
kju @ zurich, ibm .com
Marc Dacier
IBM Research
Zurich Research Laboratory
dac@zurich.ibm.com


ABSTRACT
In response to attacks against enterprise networks, admin-
istrators increasingly deploy intrusion detection systems.
These systems monitor hosts, networks, and other resources
for signs of security violations. The use of intrusion detec-
tion has given rise to another difficult problem, namely the
handling of a generally large number of alarms. In this pa-
per, we mine historical alarms to learn how future alarms
can be handled more efficiently. First, we investigate episode
rules with respect to their suitability in this approach. We
report the difficulties encountered and the unexpected in-
sights gained. In addition, we introduce a new conceptual
clustering technique, and use it in extensive experiments
with real-world data to show that intrusion detection alarms
can be handled efficiently by using previously mined knowl-
edge.


Keywords
Intrusion detection, alarm investigation, data mining, con-
ceptual clustering, episode rules.


1.
INTRODUCTION
Over the past 10 years, the number as well as the severity of
network-based computer attacks have significantly increased
[1]. As a consequence, classic computer security technologies
such as authentication and cryptography have gained in im-
portance. Simultaneously, intrusion detection has emerged
as a new and potent approach to protect computer systems
[2, 13]. In this approach, so-called Intrusion Detection Sys-
tems (IDSs) are used to monitor and analyze the events
occuring in a computer system. IDSs trigger alarms when
they detect signs of security violations. The response to
such security incidents is site-dependent, but typically in-
cludes law suits, firewall reconfigurations, and the fixing of
discovered vulnerabilities.

Practitioners [9, 33] as well as researchers [S, 11, 30] have
observed that IDSs can easily trigger thousands of alarms




Permissionto make digitalor hard copiesof all or part of this workfor
personalor classroomuse is grantedwithoutfee providedthatcopiesare
not made or distributedfor profitor commercialadvantageandthatcopies
bearthisnoticeandthefullcitationonthe firstpage.Tocopyotherwise,to
republish,topostonserversortoredistributeto lists,requirespriorspecific
permissionand/ora fee.
SIGKDD '02 Edmonton,Alberta,Canada
Copyright2002ACM 1-58113-567-X/02/0007 ...$5.00.
per day, up to 99% of which are false positives (i.e. alarms
that were triggered incorrectly by benign events). This flood
of mostly false alarms has made it very difficult to identify
the (hidden) true attacks. For example, the manual inves-
tigation of Marms has been found to be labor-intensive and
error-prone [9, 12, 33]. Tools to automate alarm investiga-
tion are being developed [12, 14, 42], but there is currently
no silver-bullet solution to this problem.

This paper shows that data mining can be used to support
and partially automate the investigation of intrusion detec-
tion alarms. Specifically, we mine historical alarms for ac-
tionable knowledge that enables us to handle future alarms
more efficiently. For example, having discovered patterns of
false positives, we can reduce the future alarm load by filter-
ing out these patterns (but see Section 3.1 for the dangers
of filtering). As it is unclear which data mining technique
is most effective in this learning-based approach, we inves-
tigate two different techniques, namely episode rules and
a conceptual clustering technique. In doing so, we make
the following novel contributions: First, we report the un-
expected insights that episode rules have given us into the
nature of intrusion detection alarms. Second, we explain
why nevertheless, episode rules do not appear to be opti-
mal in the specific environment in which we operate. Third,
we explain why and how we adapted a standard conceptual
clustering technique to the domain of intrusion detection.
The resulting new technique has several desirable proper-
ties, which make it of broader interest. Fourth, we run ex-
tensive experiments with the newly introduced clustering
technique to show that data mining can extract knowledge
that enables efficient alarm handling.

The remainder' of this paper is organized as follows: Section
2 reviews related work. Section 3 introduces our framework
for using data mining to support alarm investigation. Sec-
tion 4 investigates episode rules in this framework. Section
5 describes a new conceptual clustering technique, and Sec-
tion 6 uses it to validate our data-mining-based approach to
alarm investigation. Section 7 offers our conclusions.


1.1
Alarm Model
IDSs trigger alarms to report presumed security violations.
We model alarms as tuples over the Cartesian product DAax
... XDA,, where {Az,... , A~} is the set of alarm attributes
and DA~ is the domain (i.e. the range of possible values) of
attribute Ai. The alarm attributes capture intrinsic alarm
properties, such as the alarm source, the alarm destination,




366

the alarm type (which encodes the observed attack), and the
time-stamp. We denote the Ai value of an alarm a by a.Ai.


2.
RELATED WORK
The idea of using data mining to support alarm investiga-
tion is not new. Manganaris et al. mine association rules
over alarm bursts [33]. Subsequently, alarms that are con-
sistent with these association rules are deemed "normal"
and are discarded. The risk of losing relevant alarms is not
considered in this work, whereas bounding this risk is cen-
tral to our approach. Clifton and Gengo [11] use episode
mining to guide the construction of custom-made filtering
rules. Although Section 4 pursues the same idea, it offers
new insights into the value of this approach. Also related is
our earlier work [30], which introduces the clustering tech-
nique of Section 5. Here, we extend this work in three ways:
We motivate the design decisions that lead to said cluster-
ing technique, we discuss its theoretical properties, and we
evaluate it by means of extensive experiments.

Other related work comes from Barbar£ et al., who use in-
cremental data mining techniques to detect anomalous net-
work traffic patterns in real time [3, 5]. Lee and Stolfo use
data mining for feature construction and training of classi-
fiers that detect intrusions [32]. The goal of these research
projects is to construct IDSs more systematically and to
overcome limitations of existing IDSs. Our work, by con-
trast, aspires to use existing IDSs more efficiently.
There
are many other research projects that also applied data min-
ing to intrusion detection. An overview of these projects
and a general treatment of data mining in computer secu-
rity can be found in a recent book edited by Barbara and
Jajodia [4]. Data mining for fraud detection is investigated
by Fawcett and Provost [15], and by Chan and Stolfo [10].

Alarm correlation systems [12, 14, 40, 42] try to group alarms
so that the alarms of the same group pertain to the same
phenomenon (e.g. the same attack). In that way, they offer
a more condensed view on the security issues raised by an
IDS. The work by Dain and Cunningham [12] is notewor-
thy as it uses data mining techniques to learn correlation
rules from hand-labeled training examples. This approach
assumes that there is a human expert who (implicitly) knows
the correlation rules, so the machine can learn them from
him or her. By contrast, we advocate exploratory data min-
ing techniques that assume no prior knowledge on the side of
the user. More generally, we employ data mining to under-
stand how to handle alarms more efficiently, be it by means
of correlation, filtering, patching of flawed IDS signatures,
blocking of attackers at the firewall, or something else.

In the world of telecommunication networks, Klemettinen
uses association rules and episode rules to support the de-
velopment of alarm correlation systems [31]. Hellerstein and
Ma pursue the same goal by means of visualization, period-
icity analysis, and m-patterns (a variant of association rules
requiring mutual implication) [26]. Garofalakis and Ras-
togi investigate bounded-error lossy compression of network
management events [18]. Note that a priori, it is not clear
how well these techniques work in intrusion detection. Here,
we address this question for episode rules and for a new clus-
tering technique that we derived specifically for intrusion
detection.
3.
TECHNICAL OVERVIEW
This section introduces our framework for using data mining
to support alarm investigation. Moreover, the data used in
the experiments is described.


3.1
Framework for Alarm Investigation
Our data mining philosophy can be described as "learning
from the past to master the future." More precisely, we ap-
ply data mining techniques to historical intrusion detection
alarms to gain new and actionable insights. These insights
are subsequently used to reduce the future alarm load that
the human analyst has to handle. This can be done in at
least two ways: By eliminating alarm root causes so that
no more alarms are triggered, or by writing filtering and
correlation rules that automate alarm processing. Figure 1
illustrates this process.




~
I
Alarm
Data
~,
warehouse
mining




Interpret
Pattems
installfilteringor
patternsI gain
correlationrules
insights



Figure 1: Using data mining for alarm investigation.

Let us first consider how one can eliminate alarm root causes.
In one case we observed a misconfigured secondary DNS
server that did half-hourly DNS zone transfers from its pri-
mary DNS server. The deployed IDS would trigger "DNS
Zone Transfer" alarms because DNS zone transfers can be
used to "spy out" a target network. By correctly setting
up the secondary DNS server, we eliminated the alarm root
cause and all its associated alarms. In another case, we fixed
a broken TCP/IP stack that generated fragmented traffic
and thereby triggered "Fragmented IP" alarms. Similarly,
an attacking machine can be sanitized or shunned at the
firewall, both of which eliminates the alarm root cause.

On occasion, alarm root causes are not under our control or
they are expensive to eliminate. Then, custom-made filter-
ing rules (which automatically discard alarms) or correlation
rules (which intelligently group and summarize alarms) can
be an alternative. The primary problem with filtering and
correlation is that it can destroy valuable information. For
example, filtering can discard important alarms and corre-
lation can group alarms in meaningless ways. Our approach
addresses this problem as it uses data mining as a supporting
technology that enables a human expert to understand why
alarms are triggered and how they should be handled in the
future. Based on his or her understanding, the human ex-
pert can then devise custom-made filtering and correlation
rules that axe safe to use.




367

3.2
Requirements
Note that the framework of Figure 1 does not stipulate any
particular data mining technique. However, to be of value,
a prospective data mining technique should satisfy the fol-
lowing requirements:


Scalability: IDSs can trigger well over a million alarms per
month (cf. the column "Max" of Table 1, which indi-
cates for the year 2001 the maximum number of alarms
per month).

Noise tolerance: Intrusion detection alarms can be very
noisy [6, 38].

Multiple attribute types: Intrusion detection alarms can
contain numerical, categorical, time, and free-text at-
tributes [30]. Ideally, a data mining technique should
support and use all of these attribute types.

Ease of use: The people using the data mining techniques
are security rather than data mining experts. As a con-
sequence, setting parameters should not require exten-
sive tweaking or an overly strong background in data
mining and statistics.

Interpretability ~ relevance of patterns: The data min-
ing step should only generate highly interpretable and
relevant patterns.


To appreciate the importance of the last point ("Interpretabil-
ity & relevance of patterns"), recall that the results of the
data mining step are interpreted and acted upon by a human
expert. This raises the need for highly interpretable and rel-
evant patterns as otherwise, the human cost of learning from
these patterns would become too high. Moreover, the pro-
cess of Figure 1 is iterative and site-specific, which further re-
inforces the interpretability and relevance requirement. The
process is iterative as it has to be repeated roughly once
a month to keep up with changes in the alarm behavior of
IDSs. Such changes occur, for example, as the result of new
attacks, updates to the IDS software, or system reconfigura-
tions. Similarly, the process is site-specific as each site gen-
erally has a very unique alarm mix [36]. As a consequence,
each site must be treated individually.


3.3 A Note on the Experiments
A preliminary remark on intrusion detection terminology
is in order: IDSs are classified into knowledge-based and
behavior-based systems [13]. Knowledge-based systems such
as STAT [27] use knowledge accumulated about attacks to
detect instances of these attacks.
Behavior-based systems
(e.g. IDES [29]) use a reference model of normal behavior
and flag deviations from this model as anomalous and po-
tentially intrusive. Another dichotomy splits IDSs according
to their audit sources. Specifically, host-based IDSs analyze
host-bound audit sources such as operating system audit
trails, system logs, or application logs, whereas network-
based IDSs analyze network packets that are captured from
a network.

The experiments in this paper use alarms from network- and
knowledge-based commercial IDSs that were deployed in op-
erational (i.e. "real-world") environments. We consider it a
Table 1: Overview of IDSs used in experiments.
IDSIType
Location
Min
I
Max
Avg
I
1
A
Intranet
7643
67593
39396
2
A
Intranet
28585
1946200
270907
3
A
DMZ
11545
777713
310672
4
A
DMZ
21445
1302832
358735
5
A
DMZ
2647
115585
22144
6
A
Extranet
82328
719677
196079
I

7
A
Internet
40061
43773
20178
8
A
Internet
10762 I 266845
62289
9
A
Internet
91861
257138
152904

10
B
Intranet
18494
228619
90829
11
B
Intranet
28768
977040
292294
12
B
DMZ
2301
289040
61041
13
B
DMZ
3078
201056
91260
14
B
Internet
14781 1453892
174734
15
B
Internet
248145
1279507
668154
16
B
Internet
7563
634662
168299


strength of our validation that it uses alarms from real-world
environments rather than from simulated or laboratory en-
vironments, which can have significant limitations [36]. We
are not in possession of extensive data collections from host-
or behavior-based IDSs and therefore exclude experiments
with these IDS types. However, our experiments with the
data available for these IDS types gave results comparable
to the ones presented in this paper.

Table 1 introduces the sixteen IDSs we use throughout this
paper. Our selection criteria was to offer a representative
mix of IDSs from different vendors in different operational
environments. The sixteen IDSs are deployed at eleven dif-
ferent companies, and no two IDSs are deployed at the same
geographic site. The "IDS" column contains a numerical
identifier that will be used throughout the paper to refer-
ence the IDSs. The "Type" column indicates the IDS type,
namely "A" or "B", both of which are leading commercial
IDSs. To avoid unintended commercial implications, we do
not reveal the product names or vendors of "A" and "B". For
each IDS, we employ all alarms that were triggered in the
year 2001. The minimum, maximum, and average number
of alarms per month are listed for each IDS in the "Min",
"Max", and "Avg" columns, respectively. Finally, the "Lo-
cation" column indicates where the IDSs are deployed:


Intranet: Denotes an IDS on an internal corporate network
without Internet access.

DMZ: Designates an IDS on a perimeter network that is
protected by a firewall, but offers services to the Inter-
net.

Extranet: Denotes an IDS on a network that is shared be-
tween multiple cooperating companies, but is not ac-
cessible from the Internet.

Internet: Indicates an IDS that is deployed before the ex-
ternal firewall on a direct link to the Internet.


Note the generally large difference between the minimum
and maximum number of alarms per month. This difference




368

reflects changes in the alarm mix over time. Analogously,
the vastly varying alarm loads between IDSs provide intu-
itive evidence of the uniqueness of each site. This illustrates
our earlier point that the alarm investigation process of Fig-
ure 1 has to be applied iteratively and site by site. Finally,
for confidentiality reasons, we cannot provide more detailed
information on the sites where the IDSs are deployed.


4.
EPISODE RULES
Episode rules are a data mining technique that was devel-
oped to find patterns in event sequences [34, 35]. Intuitively,
episode rules are implication rules that predict the occur-
rence of certain alarms based on the occurrence of other
alarms. For example, an episode rule might state that in
50 percent of all cases, an "Authentication Failure" alarm is
followed within 30 seconds by a "Guest Login" alarm.

In network management, researchers have successfully used
episode rules in a framework like ours [31]. Therefore, episode
rules are a natural candidate for the data mining step of
Figure 1. In this section, we report our experience with this
approach. In addition, we summarize the insights we gained
into the nature of intrusion detection alarms.


4.1
Definitions
To formally define episode rules, we need the following ter-
minology [34, 35]: An alarm predicate is a boolean expres-
sion that tests certain alarm properties such as the alarm
type or source.
A serial (parallel) episode is a sequence
(multi-set) a =<Pi>x<_i<, of alarm predicates. Note that
the predicates of a serial episode are ordered, whereas they
have no order in parallel episodes. Given a parallel episode
and an alarm sequence S, a time interval [t~,te] is an
occurrence of a if it contains a distinct alarm a for each
Pi such that Pi(a) holds. For occurrences of serial episodes,
the alarm order must additionally match the predicate order
(i.e. the alarm a satisfying Pi must occur before the alarm
a' satisfying Pi+l). The interval [t~,tel is a minimal occur-
rence of a if there is no proper subinterval of Its,tel that
would also be an occurrence of a. Finally, episode rules are
implication rules of the form

<Px .... ,Pk> ~
<P~ .... ,Pk,...,Pn>
[s,c,W],
(1)

where <Pi>l_<i<k is a sub-episode of <Pi>l<i_<,, and the
two episodes are either both serial or parallel. The param-
eters s, c, and W are called support, confidence, and win-
dow width and their interpretation is the following: Episode
<Pi>l<i<n has s minimal occurrences in sequence S. More-
over, if t~ -t8 < W and Its, t~] is a minimal occurrence of
episode <P~ >l<_i<_k, then there is a c percent probability
for the super-episode <Pi >l<i<n to occur in Its,t, + W].
Variations of the above definitions are described in [34, 35].


4.2
Experience
We have used episode rules for the data mining step in Fig-
ure 1. In our experiments, we have mined the alarms from
our experimental IDSs (cf. Table 1) for serial and parallel
episode rules. The set of admissible alarm predicates was
restricted to predicates of the form P(a) ~ (Aia.Ai = ci),
where a is an alarm, Ai are attributes, and cl are constants.
The episodes and episode rules discovered contained many
interesting patterns, including the following ones:
L
F
A fen B ~ ~C ~c C ~
A 9~_~cD ~secE ~

Target 1




~---~
Target 2
8ource l tt



Target $
A, 8,.., E
: Alarm types.
16h, 2rain, ..., Ssec : Inter-alarm times.



Figure 2: An attack tool being run against three
targets.


· We discovered episodes that were characteristic of at-
tack tools. For example, we repeatedly found episodes
that resulted from attack scenarios like the one in Fig-
ure 2, where a source host triggers the same sequence
of alarms against different target hosts. In general,
scenarios like this result from an attacker trying out
his or her attack tool against different targets.

· We found episode rules where the right-hand side rep-
resented a massive attack, while the left-hand side was
an early indicator of this attack. Thus, the left-hand
side would give early warnings of imminent attacks.

· We discovered alarms that -- for some IDS-specific
reason -- almost always entail other alarms. For ex-
ample, on IDSs of one type, "TCP FIN Host Sweep"
alarms imply "Orphaned FIN Packet" alarms with a
confidence of 100% (but not vice versa).

· We discovered episodes that correspond to legitimate
system operations such as remote file-system mounts
or certain network management tasks.


Clearly, these patterns are of direct relevance to alarm han-
dling. For example, knowing the episodes that correspond
to legitimate system operations, it is easy to filter them out
in the future. Similarly, if an alarm systematically entails
other (redundant) alarms, then one can reduce the overall
alarm load by fusing these alarms into a single, semantically
richer meta-alarm. Finally, episodes that result from attack
tools can be used to detect future attacks in a more reliable
and timely manner.

Nevertheless, episode mining has two important drawbacks
in the framework of Figure 1. First, the attainable degree of
automation is very low. In our experiments, less than one
percent of alarms could be handled automatically thanks to
previously mined episodes and episode rules. The remain-
ing 99% of alarms still had to be investigated manually. The
second drawback is that episode mining tends to produce a
large number of irrelevant or redundant patterns [31]. More-
over, many of these patterns were difficult to interpret in
terms of real-world phenomena. Thus, given a large number
of not always easy to interpret episodes and episodes rules,
locating the truly interesting ones became a time-consuming
activity.




369

All in all, we felt that the benefit of a one-percent reduction
in alarm load did not compensate for the cost of locating the
interesting episodes and episode rules. Therefore, we do not
use episode rules as a data mining technique in our frame-
work.
Despite this negative result, our experiments with
episode rules have been important for two reasons: First,
we have come to appreciate the difficulty of finding a data
mining technique that works well in our framework. As a re-
sult, we have tailored a data mining technique to our needs
(cf. Section 5). Second, we have gained important new in-
sights into the nature of intrusion detection alarms. These
insights are summarized in the following subsection.

4.3
Alarm Characteristics
An important lesson that episode mining has taught us is
that intrusion detection alarms are extremely monotonous
and repetitive. Specifically, we noticed that almost all high-
support episode rules consisted of multiple instances of the
same predicate, i.e. P~ = Pj generally held for all i and j in
equation (1). The monotony of intrusion detection alarms
is illustrated more clearly by the following experiment: Let
us randomly choose an IDSs and a source host that has
triggered alarms at this IDS. This source host might have
triggered many alarms throughout the year 2001, but with
a probability of 96% they were all of the same type! More-
over, the probability for all alarms to hit the same target
port (target host) is 95% (69%). These probabilities were
calculated using the 16 IDSs in Table 1, but we have con-
firmed them (give or take a few percentage points) using
over 90 million alarms from more than 50 different IDSs.

The above observation inspires two ideas for making alarm
investigation more efficient. First, source hosts that display
diverse behavior, e.g. by triggering alarms of many different
types, deserve closer investigation. In fact, hackers gener-
ally have little a priori knowledge about their targets and
therefore resort to trying different reconnaissance and attack
techniques until they are successful or exhausted. In doing
so, hackers tend to trigger diverse alarm streams that involve
many different alarm types and targets.
Given that this
kind of diverse behavior is generally rare, it is a rewarding
heuristic to investigate it more closely when it occurs. Note,
however, that perfectly monotonous behavior (e.g. password
guessing) can still constitute an attack. Therefore, zooming
in on diverse behavior helps in finding real attacks, but not
all attacks are diverse.

The second idea is to automate alarm investigation for the
case where a source host keeps triggering alarms of the same
type against the same target. Given that this case is so fre-
quent, automating it will vastly relieve the human analyst.
Moreover, the dominance of homogeneous and repetitive
alarms suggests that intrusion detection alarms have a nat-
ural clustering tendency. This leads us to the next section.

5.
CONCEPTUAL CLUSTERING
Clustering seeks to group objects into categories (so-called
clusters) so that members of a category are alike, whereas
members of different categories are different [19, 28].
In
most clustering techniques, it is an afterthought to represent
clusters in an intelligible manner that supports understand-
ing and decision making [19, 28]. Conceptual clustering, by
contrast, puts cluster representation in the foreground and
searches for clusters that have "good" representations in a
given description language [16, 37, 39]. Examples of descrip-
tion languages include variants of predicate logic [7, 37] as
well as probabilistic languages that list attribute probabili-
ties [16, 41].

Conceptual clustering has two important advantages in the
framework of Figure 1. First, by deriving intelligible descrip-
tions of clusters: it facilitates cluster interpretation. The im-
portance of this point follows from the "Interpretability &
relevance of patterns" requirement of Section 3.2. Second,
conceptual clustering is particularly good at handling cate-
gorical attributes such as IP addresses, port numbers, and
alarm types. This strength matters as categorical attributes
are known to pose problems for many other clustering tech-
niques [17, 20].

In this paper, we use a variant of the classic Attribute-
Oriented Induction (AOI) technique [21] as our conceptual
clustering tool. AOI was initially introduced as a data sum-
marization technique, but its link to conceptual clustering
was subsequently established [23, 25]. Section 5.1 introduces
the classic AOI algorithm, and Section 5.2 shows why and
how we modified it. The properties of the modified AOI al-
gorithms are discussed in Section 5.3. Our experiments are
presented in Section 6.


S.1
Attribute-Oriented Induction
Attribute-oriented induction operates on relational database
tables and repeatedly replaces attribute values by more ab-
stract values. The more abstract values are taken from user-
defined generalization hierarchies, which, for example, might
state that IP addresses can be generalized to networks, time-
stamps to weekdays, and port numbers to port ranges. Be-
cause of generalization, previously distinct alarms become
identical and can be merged. In this way, huge relational
tables can be condensed into short and highly comprehensi-
ble summary tables.

For a more formal treatment, we extend all alarms by a
new integer-valued pseudo-attribute, the so-called count C.
Thus, we henceforth model alarms as tuples over the Carte-
sian product DA~x...xDA,xDc.
The count attribute is
used by the AOI algorithm for book-keeping, only.
The
alarm attributes Ai are as before. A generalization hierarchy
is a tree-structured/s-a hierarchy that shows how concepts
are organized into more general concepts. Figure 3.a shows
a sample generalization hierarchy for IP addresses. Alarms
whose attributes assume non-leaf concepts such as ~
or
Net-A in Figure 3.a are also called generalized alarms.

Inputs to the AOI algorithm are a relational table "Tover the
attributes {At,... , An, C}, as well as generalization hierar-
chies ~ and generalization thresholds dl for all attributes A~
(i = i,... , n). The first step of the AOI algorithm (cf. Fig-
ure 4) is to assign the value 1 to the count attribute of each
alarm. Subsequently, the main loop (steps 2-8) is iterated:
Step 3 selects an attribute Ai and the steps 4 and 5 replace
the Ai values of all alarms by their parent values in 7/~. By
doing so, previously distinct alarms can become identical.
Two alarms a and a' are identical if a.Ai = a'.Ai holds for
all attributes A~ (but a.C # a'.C is possible). Steps 6 and 7
merge identical alarms into a single one whose count value




370

ANY-IP

My~IPs
Extemal-lPs~

WWW
DNS
Net-A ...Net-Z

ipl
ip2 ip3 ip4 ipA1..,
ipZl...

a) Generalizationhierarchyfor IP addresses.
SrclP I DstlP Count
ipl
] ip4
1000

-ipl- -I-ip/~l'
- - 7"
ipl
] ipB1
1
i
[
i
:
ipl
~ ipZ1
]


ip4
Iip.Bl ~

ipZl |
ip4
1

b) Sampletable.


Figure 3: A generalization hierarchy and sample ta-
ble.



equals the sum of constituent counts. In this way, the count
attribute always reflects the number of original alarms that
are summarized by a given generalized alarm.
Note that
each alarm a represents a cluster of size a.C.
Moreover,
the elements of a cluster a are the original (ungeneralized)
alarms that were merged into a.

One key aspect of the classic AOI algorithm has been left
open, namely, how the attributes Ai are selected in step 3.
The selection criterion is that any attribute Ai that assumes
more than di distinct values in table 7" can be selected.
(Recall that dl, the generalization threshold, is an input
parameter to the algorithm.) The main loop terminates in
step 2 if no such attribute exists.


5.2
Modifications
To summarize, an attribute A~ is generalized until it assumes
at most d~ distinct values (i = 1,...,n).
This strategy
guarantees that the final generalized table contains at most
Hi=x...... dl generalized alarms. This strategy of bounding
the number of distinct attribute values can lead to excessive
generalization, in which too much detail is lost (so-called
over-generalization). This section illustrates the problem of
over-generalization and shows how we modified the classic
AOI algorithm to mitigate it.

Figure 3.b shows a sample table having the alarm attributes
"SrcIP" (the source-IP) and "DstIP" (the destination-IP).
Note that the first tuple in the table represents 1000 oc-
currences of the alarm (ipl ,:i.p4). We use the generaliza-
tion hierarchy of Figure 3.a for both alarm attributes, and
we assume that both generalization thresholds have been
set to 10 (i.e. dl = d2 = 10). Given that both alarm at-
tributes assume 27 distinct values, they are both general-
ized once. This yields a new table whose alarm attributes
still have 27 distinct values. Therefore, both attributes are
generalized again. The resulting table, which contains the
generalized alarms (MyCompany-IPs ,MyCompany-IPs, 1000),
(MyCompany-IPs,External-IPs, 26), and (External-IPs,
MyCompany-IPs.26), is the final result of classic AOI. Note
that this result is (over-)generalized to a point where im-
portant details have been lost. In fact, instead of the above
result we had rather obtained the alarms (ipl,ip4,1000),
(ipl,External-IPs, 26), and
(External-IPs, ip4,26),
which are more specific and informative.
1: [or all alarms a in 7" do a.C := 1;//Init
counts
2: while table 7" is not abstract enough do {
3:
Select an alarm attribute Ai;
4:
for all alarms a in 7" do
//Generalize Ai
5:
a.Ai := father of a.Ai in ~i;
6:
while identical alarms a, a' exist do
//Merge
7:
Set a.C := a.C + a'.C and delete a ' from 7";
8: }

Figure
4: The
classic AOI algorithm.


A major source of over-generalization is "noise". Indeed,
noise forces up the number of distinct attribute values and
thereby controls the generalization process. In the above ex-
ample, there was one main signal (the tuple (ipl, il:gt, 1000)
of Table 3.b) and five percent of "noise" (the remaining 52
tuples).
However, the noise dominated the generalization
process and caused the alarm (ipl,ip4,1000) to be gener-
alized four times, so it became (MyCompaay-IPs ,MyCompany-
IPs,1000).
Noise-induced over-generalization is a serious
problem in intrusion detection (cf. Section 3.2), and it mo-
tivates our first modification of the classic AOI algorithm.


MODIFICATION 1. We abandon the generalization thresh-
olds di as well as the associated strategy of bounding the
number of distinct attribute values. Our new strategy tries
to find generalized alarms that cover "many" of the orig-
ina~ (ungeneralized) alarms.
Formally, we search alarms
a E T that have a count bigger than rain_size (i.e.a.C >
min_size), where rain_size E N is a user-defined constant.
Whenever such an alarm is found, it is removed from table
T and reported to the user. Processing continues with the
table T' := 7" \ a.
[]


Recall that each alarm a represents a cluster of size a.C.
The above modification has two effects: First, by imposing
a minimum cluster size of rain_size, it forces the AOI algo-
rithm to find "large" clusters. Second, by preventing further
generalization of an alarm a that satisfies a.C > min_size,
it tries to avoid over-generalization. The combined effect is
to bias the algorithm towards large clusters that nonethe-
less have specific representations in the form of generalized
alarms. Finally, Modification 1 also raises the need for a new
attribute selection criteria" for step 3 of Figure 4. To coun-
teract over-generalization, we use the following heuristic cri-
teria, which tries to minimize the total number of attribute
generalizations:


MODIFICATION 2. For each alarm attribute Ai, let Fi :=
max{fi(v)l v E DA,} be the maximum of the function

fi(v) := SELECT sum(C) FROM T WHERE A, = v,

which sums the counts C of all alarms a E T with a.Ai = v.
Step 3 of Figure ~ selects an attribute Ai whose Fi value is
minimal, i.e. F~ < Fj must hold for all j.
[]


The motivation for this heuristic is that an alarm a with
a.C > rain_size cannot exist unless Fi > min.size holds
for all attributes Ai. Therefore, we use it as a heuristic to
increase the smallest Fi value by generalizing its correspond-
ing attribute A~. Other heuristics are conceivable, but the
one given here works well in practice (cf. Section 6).




371

To see what we have achieved so far, let us reconsider the
example of Figure 3 and let rain_size equal 20. The alarm
(ipl,ip4,1000) has a count larger than 20, and is immedi-
ately removed from the table and presented to the user. All
remaining alarms have counts of one, so that generalization
starts. Because of F1 = F2 = 26, either of the two attributes
"SrcIP" or "DstIP" can be selected for generalization. With-
out loss of generality, we assume that the attribute "SrcIP"
is chosen and generalized. The resulting alarms still have
counts of one, which is why a second generalization step is
initiated.
Again, we assume that the "SrcIP" is selected
and generalized.
The resulting table contains the alarm
(External-IPs, ip4,26), which is removed and reported to
the user. Finally, the "DstIP" attribute is generalized twice,
the alarm (MyCompany-IPs,External-IPs,26) is reported,
and processing ends.

A problem becomes apparent. Although generalizing the at-
tribute "SrcIP" has allowed us to find the alarm (External-
IPs, ip4,26), it has irrevocably over-generalized the "SrcIP"
of the 26 alarms that remain after (External-IPs, ±p4,26)
was removed.
As a consequence, the last alarm reported
is (MyCompany-IPs,External-IPs,26) instead of the more
specific (±pl,Exeernal-IPs,26). This problem, that a gen-
eralization step can be opportune in the short run while hav-
ing undesirable late effects, motivates the Modification 3.

MODIFICATION 3. After reporting an alarm a 6 7- with
a.C > rain_size, we used to continue processing with table
7"' := 7- \ a. Henceforth, we first undo all generalization
steps in ~'.
This involves replacing all generalized alarms
by their constituent ungeneralized alarms. Then, processing
resumes with the resulting table, in which all counts equal
one.
[]

Now, let us reconsider the above example: Processing is un-
changed up to the point where the alarm (External-IPs, ip4,
26) is removed from the table. Then, Modification 3 kicks in
and resets the "SrcIP" attribute of the remaining 26 alarms
to its original value, namely ipl. Finally, the "DstIP" at-
tribute is generalized twice, the alarm (ip1, External-IPs,
26) is reported, and processing ends.

Our modified version of AOI also supports dynamic general-
ization hierarchies [22], Dynamic generalization hierarchies
are constructed at run-time to fit the data distribution. For
example, instead of a static generalization hierarchy that
imposes concepts such as "morning", "evening", "night",
etc., we dynamically construct generalization hierarchies for
the time attribute. Frequently, this yields much better re-
sults as the temporal characteristics of alarm patterns are
not well-described by static concepts. Similarly, some IDSs
extend their alarms by a free-text attribute that stores the
supposedly intrusive event. To tap the semantic informa-
tion of free-text attributes, we dynamically build generaliza-
tion hierarchies that reflect the is-substring-of relationship
between frequent substrings. Space restrictions preclude a
more detailed discussion of these aspects.

5.3
Discussion
In Section 3.2, we have listed five requirements that a data
mining technique should satisfy to be suitable for our frame-
work. Next, we examine how well the modified AOI algo-
rithm meets these requirements:
Scalability: The excellent scalability of classic AOI [23] is
mostly preserved by our modifications. For instance,
our implementation of the modified algorithm runs on
a 700 MHz Pentium III CPU with 1 GB RAM, and
processes two million alarms in less than four minutes.

Noise tolerance: By design, the modified AOI algorithm
tolerates the noise typically found in intrusion detec-
tion alarms (see the discussion before Modification 1).

Multiple attribute types: Using static and dynamic gen-
eralization hierarchies, AOI can take advantage of a
wide variety of attribute types, including numerical,
categorical, time, and free-text attributes.

Ease of use: The min_size parameter has a very intuitive
interpretation and is the only one to be set.
Some
expertise in the application domain is needed to define
meaningfnl generalization hierarchies. However, once
defined, these hierarchies are generally static.

Interpretability & relevance of patterns: As Section 6
will point out, we found the results of the modified AOI
algorithm to be relevant and easy to interpret.


It is a well-known problem that clustering techniques can
"impose" clustering structures that are not warranted by
the underlying data [19]. Cluster validation addresses this
problem by quantitatively assessing the merits of a derived
clustering structure [19]. Here, we focus on the properties
of the modified AOI algorithm that might prevent or favor
the generation of invalid clusters.

To begin with, the modified AOI algorithm has a favorable
control flow. In fact, beginning with the most apparent clus-
ter, it repeatedly finds clusters and removes them from the
data set. Up to min_size alarms that did not fit well into
any cluster might be left over at the end. This, it has been
argued [24], is more natural than assigning all alarms (noise
and outliers included) to clusters. Another important point
is that a high rain_size threshold can compromise cluster
validity by forcing the algorithm to merge unrelated alarms.
However, the merging of unrelated alarms tends to produce
over-generalized results, which helps to identify the problem.
Then, the algorithm can be re-run with a smaller rain_size
value. Moreow.,r, "drilling .down" into a cluster (i.e. reversely
traversing the merge steps that have produced it) is a prac-
tical way to identify potentially invalid clusters. Finally, the
attribute selection heuristic of Modification 2 can influence
the validity of resulting clusters. We plan to investigate this
influence in our future work.

6.
EXPERIMENTAL RESULTS
This section assesses the modified AOI algorithm with re-
spect to its ability to extract actionable knowledge from in-
trusion detection alarms. Section 6.1 describes our exper-
iments and the results obtained. Section 6.2 provides evi-
dence that one can expect similar results for different data
sets.

6.1
Practical Experience
This section evaluates the modified AOI algorithm in the
framework of Figure 1. To this end, we iterate the follow-
ing experiment with varying parameters: First, we choose




372

a month m in the year 2001 and an IDS I from Table 1.
Then, we use the modified AOI algorithm to analyze all
alarms that were triggered by IDS I in month m. Based
on the results obtained, we manually derive and implement
filtering and correlation rules. We apply these rules to the
alarms triggered by IDS I in month m+ 1, and we calculate
the percentage of alarms that are handled automatically.
This percentage is called the alarm load reduction in month
m + 1. Clearly, a high alarm load reduction is desirable as it
means that the human analyst has to handle fewer alarms.

Throughout our experiments, we found the results of the
modified AOI algorithm to be intuitive and interpretable.
The algorithm returned between eight and thirty-two alarm
clusters per IDS and month.
Interpreting these clusters,
and deriving appropriate filtering and correlation rules took
approximately two hours per IDS-month, but this time de-
creased as we gained more experience. Moreover, when keep-
ing the IDS I fixed, we found a non-negligible overlap be-
tween the alarm clusters of successive months. That further
reduced the cost of the overall process.

To assess the effectiveness of derived filtering and correla-
tion rules, we ran two sets of experiments. In a first set, we
fixed the parameter m to be November 2001, and let the pa-
rameter I run over all IDSs in Table 1 (i.e. I = 1, 2,... , 16).
Figure 5 shows the alarm load reductions attained in month
m + 1 (i.e in December 2001). As is apparent from the fig-
ure, approximately 75% of the December alarms were han-
dled automatically by the rules derived from the November
alarms. In a second set of experiments, we fixed I := 8 and
let m vary. Figure 6 shows for each month the alarm load
reduction achieved by the rules from the previous month.

Note that the curve in Figure 6 has a sharp drop in October.
Based on our investigation, there was a temporary network-
ing problem in October. The IDS confused this problem
with an attack and triggered countless alarms. Clearly, the
rules derived from the September alarms could not antici-
pate this networking problem. As a consequence, they were
ineffective and the alarm load reduction dropped sharply.
Note, however, that the alarm load reduction across IDSs
(cf. Figures 5) and over time (cf. Figure 6) is generally good.

To summarize, we found it intuitive and straightforward to
interpret the output of the modified AOI algorithm. More-
over, we achieved an average alarm load reduction of 75%,
in our experiments. Based on these results, we postulate
that our approach to alarm handling is practical and effec-
tive. The next section presents experimental evidence that
we would have reached the same conclusion if we had chosen
different data sets for the experiments.

6.2
Stability of Results
Note that in the last section, we have strictly adhered to the
process of Figure 1. In particular, we have manually derived
filtering and correlation rules from the data mining results.
These experiments were important, because they assessed
precisely the approach that is advocated in this paper.

Here, we present experiments, where we automatically de-
rive the filtering rules. Everything else is unchanged. To
derive the filtering rules, we use a program that proceeds
in three steps. First, it reads the output of the modified
|':
1
2
$
4
t
I
?
8
9
tO
It
112 13 14 t$
t6

IDS

Figure
5: Alarm load reduction
in Dec 2001.




j°

1,1

Jan FWb Max Apr Mw/ Jun
Jtd ~
d~p Oct Nov Dec

Month

Figure 6: Alarm load reduction for IDS 8.



AOI algorithm. Second, it discards all generalized alarms
that -- according to user-defined generalization thresholds
--
are too general. In that way, generalized alarms that a
human expert might considered incomprehensible and use-
less are excluded from further processing. In the third step,
the remaining generalized alarms are translated one-to-one
into filtering rules. For example, the alarm (ipl,ip4,1000)
of Figure 3.b would be translated into the filtering rule
"if SrclP=ipl and DstlP=ip4 then discard alarm;".

Our new experimental setup is as follows: For each tuple
(I,m) consisting of an IDS I (I = 1,... , 16) and a month
m (m = Jan,... , Nov), we used said program to derive fil-
tering rules from the output of the modified AOI algorithm.
Then, we applied these filtering rules to the alarms that
IDS I triggered in month m + 1. We recorded the resulting
alarm load reductions and calculated for each IDS the aver-
age alarm load reduction over all eleven months. Figure 7
presents the resulting statistics.

Note that the average alarm load reduction in Figure 7 is
around 66%, which is less than the 75% we reported in the
previous section. This reflects the fact that the automati-
cally derived filtering rules tend to be more restrictive than
the manually derived ones. The important point, however,
is that using the alarms from 16 × 11 = 176 IDS-months in
a different experimental setup, we could confirm the overall
effectivenessof our approach to alarm investigation.




373

~I00 F............................................................................................................




"i!
u


|

o
1
2
$
4.
S
S
7
$
g
t0 11 11 t3 14 tS tS

IDS



Figure 7:
Average alarm load reduction over the
year 2001.


7.
CONCLUSION
The use of intrusion detection has created the problem to
investigate a generally large number of alarms. This paper
has shown that data mining can be used to support and
partially automate this investigation process. The approach
pursued is to mine historical alarms for new and actionable
insights. These insights are subsequently used to automate
alarm processing, or to pin down and fix alarm root causes.
The viability of this approach is demonstrated by extensive
experiments with real-world data.

We have seen that not all data mining techniques are suit-
able for the specific environment in which we operate. Specif-
ically, we found that the cost of finding relevant episode rules
outweighs the benefit derived from them. Nonetheless, there
is value in using episode rules as evidenced by the interesting
alarm patterns discovered. Moreover, the results of episode
mining have shown that intrusion detection alarms are very
homogeneous and repetitive. This observation facilitates at-
tack detection. Specifically, we have explained that a source
host triggering a heterogeneous stream of alarms is likely to
be an attacker.

We have also investigated the suitability of attribute-oriented
induction (a conceptual clustering technique) for our pur-
poses. As the classic technique tends to produce too general
results, we have modified it in three ways: First, we have
biased the technique to find large clusters. Second, we have
introduced a new heuristic way of selecting attributes for
generalization. Third, we occasionally undo all generaliza-
tion steps to prevent them from accumulating to the point
where over-generalization occurs. The resulting technique
was shown to work well in our framework. In addition, it
has several desirable properties, which make it of broader
interest.
Our future work will concentrate on objectively
assessing the validity of the clusters derived by the modified
attribute-oriented induction technique.


Acknowledgments
This research was supported by the European IST Project
MAFTIA (IST-1999-11583), which is partially funded by
the European Commission and the Swiss Federal Office for
Education and Science. The views herein are those of the
author and do not necessarily reflect the views of the sup-
porting agencies.
8.
REFERENCES
[1] J. Allen, A. Christie, W. Fithen, J. McHugh, J. Pickel,
and E. Stoner. State of the Practice of Intrusion
Detection Technologies. Technical report, Carnegie
Mellon University, January 2000.
hzzp://www, cerZ. org/archive/pd.f/99tr028, pdf.

[2] R. Bace. Intrusion Detection. Macmillan Technical
Publishing, 2000.

[3] D. BarbarA, J. Couto, S. Jajodia, L. Popyack, and
N. Wu. ADAM: Detecting Intrusions by Data Mining.
In IEEE Workshop on Information Assurance and
Security, 2001.

[4] D. Barbar£ and S. Jajodia, editors. Applications of
Data Mining in Computer Security. Kluwer Academic
Publisher, Boston, 2002.

[5] D. BarbarA, N. Wu, and S. Jajodia. Detecting Novel
Network Intrusions Using Bayes Estimators. In First
SIAM Int'l Conf. on Data Mining (SDM'01), 2001.

[6] S. M. Bellovin. Packets Found on an Internet.
Computer Communications Review, 23(3):26-31, 1993.

[7] G. Bisson. Conceptual Clustering in a First Order
Logic Representation. In lOth European Conf. on
Artificial In.telligenee, pages 458-462, 1992.

[8] E. Bloedorn, B. Hill, A. Christiansen, C. Skorupka,
L. Talboot, and J. Tivel. Data Mining for Improving
Intrusion Detection, 2000. http ://~.miZre.
org/
support/papers/t ech_papers99_00/.

[9] J. Broderick - Editor. IBM Outsourced Solution,
1998. hztp ://~.
inf oworld, com/cgi-bin/
displayTC.pl?/980504sb3-ibm.htm.

[10] P. Chan and S. Stolfo. Toward Scalable Learning with
Non-Uniform Class and Cost Distributions: A Case
Study in Credit Card Fraud Detection. In 4th Int'l
Conf. on Knowledge Discovery and Data Mining,
pages 164-168, 1998.

[11] C. Clifton and G. Gengo. Developing Custom
Intrusion Detection Fi~lters Using Data Mining. In
Military Communications Int'l Symposium
(MILCOM2000), October 2000.

[12] O. Dain and R. K. Cunningham. Fusing
Heterogeneous Alert Streams into Scenarios. In
Barbar£ and Jajodia [4].

[13] H. Debar, M. Dacier, and A. Wespi. A Revised
Taxonomy for Intrusion Detection Systems. Annales
des Tglgcommunications, 55(7-8):361-378, 2000.

[14] H. Debar and A. Wespi. Aggregation and Correlation
of Intrusion-Detection Alerts. In 4th Workshop on
Recent Advances in Intrusion Detection (RAID),
LNCS, pages 85-103. Springer Verlag, 2001.

[15] T. Fawcett and F. Provost. Adaptive Fraud Detection.
Data Mining and Knowledge Discovery, 1:291-316,
1997.




374

[16] D. H. Fisher. Knowledge Acquisition Via Incremental
Conceptual Clustering. Machine Learning, 2:139-172,
1987.

[17] V. Ganti, J. Gehrke, and R. Ramakrishnan. CACTUS

-
Clustering Categorical Data Using Summaries. In
5th ACM SIGKDD Int'l Conf. on Knowledge
Discovery in Databases (SIGKDD), pages 73-83, 1999.

[18] M. Carofalakis and R. Rastogi. Data Mining Meets
Network Management: The Nemesis Project. In ACM
SIGMOD Int'l Workshop on Research Issues in Data
Mining and Knowledge Discovery, May 2001.

[19] A. Gordon. Classification. Chapman and Hall, 1999.

[20] S. Guha, R. Rastogi, and K. Shim. ROCK: A Robust
Clustering Algorithm for Categorical Attributes.
Information Systems, 25(5):345-366, 2000.

[21] J. Han, Y. Cai, and N. Cercone. Data-Driven
Discovery of Quantitative Rules in Relational
Databases. IEEE Transactions on Knowledge and
Data Engineering, 5(1):29-40, 1993.

[22] J. Han and Y. Fu. Dynamic Generation and
Refinement of Concept Hierarchies for Knowledge
Discovery in Databases. In Workshop on Knowledge
Discovery in Databases, pages 157-168, 1994.

[23] J. Han and Y. Fu. Exploration of the Power of
Attribute-Oriented Induction in Data Mining. In
U. M. Fayyad, G. Piatetsky-Shapiro, P. Smyth, and
R. Uthurusamy, editors, Advances in Knowledge
Discovery and Data Mining. AAAI Press/MIT Press,
1996.

[24] P. Hansen, B. Jaumard, and N. Mladenovic. How to
Choose K Entries Among N. DIMACS Series in
Discrete Mathematics and Theoretical Computer
Science, 19:105-116, 1995.

[25] O. Heinonen and H. Mannila. Attribute-Oriented
_Inductionand Conceptual Clustering. Technical
Report Report C-1996-2, University of Helsinki, 1996.

[26] J. L. Hellerstein and S. Ma. Mining Event Data for
Actionable Patterns. In The Computer Measurement
Group, 2000.

[27] K. Ilgun, R. A. Kemmerer, and P. A. Porras. State
Transition Analysis: A Rule-Based Intrusion
Detection System. IEEE Transactions on Software
Engineering, 21(3):181-199, 1995.

[28] A. Jain, M. Murty, and P. Flynn. Data Clustering: A
Review. ACM Computing Surveys, 31(3):264-323,
1999.

[29] H. S. Javitz and A. Valdes. The SRI IDES Statistical
Anomaly Detector. In IEEE Symposium on Security
and Privacy, Oakland, CA. SRI International, May
1991.

[30] K. Julisch. Mining Alarm Clusters to Improve Alarm
Handling Efficiency. In 17th Annual Computer
Security Applications Conference A CSAC), pages
12-21, December 2001.
[31] M. Klemettinen. A Knowledge Discovery Methodology
for Telecommunication Network Alarm Data. PhD
thesis, University of Helsinky (Finland), 1999.

[32] W. Lee and S. J. Stolfo. A Frrameworkfor
Constructing Features and Models for Intrusion
Detection Systems. ACM Transactions on Information
and System Security, 3(4):227-261, 2000.

[33] S. Manganaris, M. Christensen, D. Zerkle, and
K. Hermiz. A Data Mining Analysis of RTID Alarms.
Computer Networks, 34(4), October 2000.

[34] I-I.Mannila and H. Toivonen. Discovering Generalized
Episodes Using Minimal Occurences. In 9nd lnt'l
Conf. on Knowledge Discovery and Data Mining,
pages 146-151, 1996.

[35] H. Mannila, H. Toivonen, and A. I. Verkamo.
Discovery of Frequent Episodes in Event Sequences.
Data Mining and Knowledge Discovery, 1:259-289,
1997.

[36] J. McHugh. The 1998 Lincoln Laboratory IDS
Evaluation - A Critique. In 3th Workshop on Recent
Advances in Intrusion Detection (RAID), LNCS,
pages 145-161. Springer Verlag, 2000.

[37] R. S. Michalski and R. E. Stepp. Automated
Construction of Classifications: Conceptual Clustering
Versus Numerical Taxonomy. IEEE Transactions on
Pattern Analysis and Machine Intelligence,
5(4):396-410, 1983.

[38] V. Paxson. Bro: A System for Detecting Network
Intruders in Real-Time. Computer Networks,
31(23-24):2435-2463, 1999.

[39] L. Pitt and R. E. Reinke. Criteria for Polynomial
Time (Conceptual) Clustering. Machine Learning,
2(4):371-396, 1987.

[40] S. Staniford, J. A. Hoagland, and J. M. McAlerney.
Practical Automated Detection of Stealthy Portscans.
In ACM Computer and Communications Security IDS
Workshop, pages 1-7, 2000.

[41] L. Talavera and J. B6jar. Generality-Based
Conceptual Clustering with Probabilistic Concepts.
IEEE Transactions on Pattern Analysis and Machine
Intelligence, 23(2):196--206,2001.

[42] A. Valdes and K. Skinner. Probabilistic Alert
Correlation. In 4th Workshop on Recent Advances in
Intrusion Detection (RAID), LNCS, pages 54---68.
Springer Verlag, 2001.




375

